(this["webpackJsonpmern-stack-client"]=this["webpackJsonpmern-stack-client"]||[]).push([[107],{140:function(e,a,n){"use strict";n.d(a,"a",(function(){return u}));var t=n(45),l=n(28),r=n(136),i=n(137),s=n(139),o=n(0),c=n.n(o),m=n(138),d=n.n(m),u=(n(59),function(e){function a(e){var n;return Object(t.a)(this,a),(n=Object(r.a)(this,Object(i.a)(a).call(this,e))).highlight=function(){n.ref&&n.ref.current&&d.a.highlightElement(n.ref.current)},n.ref=c.a.createRef(),n}return Object(s.a)(a,e),Object(l.a)(a,[{key:"componentDidMount",value:function(){this.highlight()}},{key:"componentDidUpdate",value:function(){this.highlight()}},{key:"render",value:function(){var e=this.props,a=e.code,n=(e.plugins,e.language);return c.a.createElement("pre",{className:"code-prism"},c.a.createElement("code",{ref:this.ref,className:"language-".concat(n)},a.trim()))}}]),a}(c.a.Component))},141:function(e,a,n){},150:function(e,a,n){"use strict";n.d(a,"a",(function(){return m}));var t=n(0),l=n.n(t),r=n(26),i=n(297),s=n(295),o=n(114),c=Object(o.a)((function(e){return{root:{display:"flex"},paper:{marginRight:e.spacing(2)},line:{textDecoration:"none"}}}));function m(){var e=c();return l.a.createElement("div",{className:e.root},l.a.createElement(s.a,null,l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/introAngular",className:e.line},"AI")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/tensorflow",className:e.line},"Tensorflow")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/tensors",className:e.line},"Tensorboards")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/angCompiler",className:e.line},"Compiler")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/neural",className:e.line},"NeuralKeras")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/activationFunctions",className:e.line},"activationFuncs")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/loss",className:e.line},"Loss")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/gradientNeural",className:e.line},"GradientNeural")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/stochastic",className:e.line},"Stochastic")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/benchmarking",className:e.line},"Benchmarking")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/customer",className:e.line},"Customer")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/regularizationDeep",className:e.line},"Regularization Deep")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/imbalanced",className:e.line},"Imbalanced")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/imbalanced2",className:e.line},"Imbalanced2")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/convolutionals",className:e.line},"Convolutionals")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/data_augmentation",className:e.line},"data Augmentation")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/transfer",className:e.line},"Transfer")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/word_embedding",className:e.line},"Embedding")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/datatypests",className:e.line},"Datatypes")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/typeScript_2",className:e.line},"TS Function")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:"/typeScript_4",className:e.line},"Type Assertion"))),l.a.createElement("div",null))}},466:function(e,a,n){"use strict";n.r(a);var t=n(45),l=n(28),r=n(136),i=n(137),s=n(139),o=n(0),c=n.n(o),m=n(138),d=n.n(m),u=n(120),p=n(57),g=n(296),_=n(5),f=(n(141),n(150)),E=n(140),b={backgroundColor:"#F0F8FF",padding:"1px",fontSize:"16px"},h='\nimport numpy as np\nimport cv2\nimport PIL.Image as Image\nimport os\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\n\nIMAGE_SHAPE = (224, 224)                                      #Make predictions using ready made model (without training).\n\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer("https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", input_shape=IMAGE_SHAPE+(3,))\n])\n\ngold_fish = Image.open("goldfish.jpg").resize(IMAGE_SHAPE)\ngold_fish = np.array(gold_fish)/255.0\n\ngold_fish[np.newaxis, ...]\nresult = classifier.predict(gold_fish[np.newaxis, ...])\n\npredicted_label_index = np.argmax(result)\npredicted_label_index\n\n# tf.keras.utils.get_file(\'ImageNetLabels.txt\',\n#                         \'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt\')\nimage_labels = []\nwith open("ImageNetLabels.txt", "r") as f:\n    image_labels = f.read().splitlines()\nimage_labels[:5]\n\nimage_labels[predicted_label_index]\n'.trim(),w="\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n\ndata_dir\n\nimport pathlib\ndata_dir = pathlib.Path(data_dir)\n\nlist(data_dir.glob('*/*.jpg'))[:5]\nimage_count = len(list(data_dir.glob('*/*.jpg')))\nprint(image_count)\n\nroses = list(data_dir.glob('roses/*'))\nroses[:5]\n\nPIL.Image.open(str(roses[1]))\n\ntulips = list(data_dir.glob('tulips/*'))\nPIL.Image.open(str(tulips[0]))\n".trim(),y="\nflowers_images_dict = {\n  'roses': list(data_dir.glob('roses/*')),\n  'daisy': list(data_dir.glob('daisy/*')),\n  'dandelion': list(data_dir.glob('dandelion/*')),\n  'sunflowers': list(data_dir.glob('sunflowers/*')),\n  'tulips': list(data_dir.glob('tulips/*')),\n}\n\nflowers_labels_dict = {\n  'roses': 0,\n  'daisy': 1,\n  'dandelion': 2,\n  'sunflowers': 3,\n  'tulips': 4,\n}\n\nflowers_images_dict['roses'][:5]\nstr(flowers_images_dict['roses'][0])\n\nimg = cv2.imread(str(flowers_images_dict['roses'][0]))\ncv2.resize(img,(224,224)).shape\nX, y = [], []\n\nfor flower_name, images in flowers_images_dict.items():\n    for image in images:\n        img = cv2.imread(str(image))\n        resized_img = cv2.resize(img,(224,224))\n        X.append(resized_img)\n        y.append(flowers_labels_dict[flower_name])\n        \nX = np.array(X)\ny = np.array(y)\n".trim(),v="\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nX_train_scaled = X_train / 255\nX_test_scaled = X_test / 255\n\n\nX[0].shape                                                #Make prediction using pre-trained model on new flowers dataset.\nIMAGE_SHAPE+(3,)\n\nx0_resized = cv2.resize(X[0], IMAGE_SHAPE)\nx1_resized = cv2.resize(X[1], IMAGE_SHAPE)\nx2_resized = cv2.resize(X[2], IMAGE_SHAPE)\n\nplt.axis('off')\nplt.imshow(X[0])\n\nplt.axis('off')\nplt.imshow(X[1])\n\nplt.axis('off')\nplt.imshow(X[2])\n\npredicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\npredicted = np.argmax(predicted, axis=1)\npredicted\n\nimage_labels[795]\n".trim(),N='\nfeature_extractor_model = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"\n\npretrained_model_without_top_layer = hub.KerasLayer(\n    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n    \nnum_of_flowers = 5\nmodel = tf.keras.Sequential([pretrained_model_without_top_layer, tf.keras.layers.Dense(num_of_flowers)])\n\nmodel.summary()\n\n\nmodel.compile(\n  optimizer="adam",\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=[\'acc\'])\n\nmodel.fit(X_train_scaled, y_train, epochs=5)\n\nmodel.evaluate(X_test_scaled,y_test)\n'.trim(),x=function(e){function a(){return Object(t.a)(this,a),Object(r.a)(this,Object(i.a)(a).apply(this,arguments))}return Object(s.a)(a,e),Object(l.a)(a,[{key:"componentDidMount",value:function(){setTimeout((function(){return d.a.highlightAll()}),0)}},{key:"render",value:function(){var e=this.props.classes;return c.a.createElement(u.a,{container:!0},c.a.createElement(u.a,{item:!0,xs:2},c.a.createElement(p.a,{className:e.paper},c.a.createElement("h4",null,c.a.createElement(f.a,null)))),c.a.createElement(u.a,{item:!0,xs:10},c.a.createElement(p.a,{className:e.paper},c.a.createElement(g.a,null,c.a.createElement("h3",null,"Transfer learning in image classification"),"We will use transfer learning and take pre-trained model from google's Tensorflow Hub and re-train that on flowers dataset.",c.a.createElement("br",null),c.a.createElement("br",null),c.a.createElement("div",{style:b},c.a.createElement(E.a,{code:h,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Load flowers dataset"),c.a.createElement("i",null,"cache_dir indicates where to download data."),c.a.createElement("br",null),c.a.createElement("div",{style:b},c.a.createElement(E.a,{code:w,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Read flowers images from disk into numpy array using opencv"),c.a.createElement("div",{style:b},c.a.createElement(E.a,{code:y,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Train test split"),c.a.createElement("div",{style:b},c.a.createElement(E.a,{code:v,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Now take pre-trained model and retrain it using flowers images"),c.a.createElement("div",{style:b},c.a.createElement(E.a,{code:N,language:"js",plugins:["line-numbers"]}))))))}}]),a}(o.Component);a.default=Object(_.a)((function(e){return{paper:{margin:e.spacing(1),padding:e.spacing(1)},smMargin:{margin:e.spacing(1)},actionDiv:{textAlign:"center"}}}))(x)}}]);
//# sourceMappingURL=107.6a066720.chunk.js.map
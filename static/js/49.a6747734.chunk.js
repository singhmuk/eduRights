(this["webpackJsonpmern-stack-client"]=this["webpackJsonpmern-stack-client"]||[]).push([[49],{140:function(e,n,a){"use strict";a.d(n,"a",(function(){return d}));var t=a(45),l=a(28),r=a(136),s=a(137),i=a(139),o=a(0),c=a.n(o),m=a(138),u=a.n(m),d=(a(59),function(e){function n(e){var a;return Object(t.a)(this,n),(a=Object(r.a)(this,Object(s.a)(n).call(this,e))).highlight=function(){a.ref&&a.ref.current&&u.a.highlightElement(a.ref.current)},a.ref=c.a.createRef(),a}return Object(i.a)(n,e),Object(l.a)(n,[{key:"componentDidMount",value:function(){this.highlight()}},{key:"componentDidUpdate",value:function(){this.highlight()}},{key:"render",value:function(){var e=this.props,n=e.code,a=(e.plugins,e.language);return c.a.createElement("pre",{className:"code-prism"},c.a.createElement("code",{ref:this.ref,className:"language-".concat(a)},n.trim()))}}]),n}(c.a.Component))},141:function(e,n,a){},150:function(e,n,a){"use strict";a.d(n,"a",(function(){return m}));var t=a(0),l=a.n(t),r=a(26),s=a(297),i=a(295),o=a(114),c=Object(o.a)((function(e){return{root:{display:"flex"},paper:{marginRight:e.spacing(2)},line:{textDecoration:"none"}}}));function m(){var e=c();return l.a.createElement("div",{className:e.root},l.a.createElement(i.a,null,l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/introAngular",className:e.line},"AI")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/tensorflow",className:e.line},"Tensorflow")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/tensors",className:e.line},"Tensorboards")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/angCompiler",className:e.line},"Compiler")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/neural",className:e.line},"NeuralKeras")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/activationFunctions",className:e.line},"activationFuncs")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/loss",className:e.line},"Loss")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/gradientNeural",className:e.line},"GradientNeural")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/stochastic",className:e.line},"Stochastic")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/benchmarking",className:e.line},"Benchmarking")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/customer",className:e.line},"Customer")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/regularizationDeep",className:e.line},"Regularization Deep")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/imbalanced",className:e.line},"Imbalanced")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/imbalanced2",className:e.line},"Imbalanced2")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/convolutionals",className:e.line},"Convolutionals")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/data_augmentation",className:e.line},"data Augmentation")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/transfer",className:e.line},"Transfer")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/word_embedding",className:e.line},"Embedding")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/datatypests",className:e.line},"Datatypes")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/typeScript_2",className:e.line},"TS Function")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/typeScript_4",className:e.line},"Type Assertion"))),l.a.createElement("div",null))}},164:function(e,n,a){e.exports=a.p+"static/media/perceptrons.f6ad4ad3.png"},468:function(e,n,a){"use strict";a.r(n);var t=a(45),l=a(28),r=a(136),s=a(137),i=a(139),o=a(0),c=a.n(o),m=a(138),u=a.n(m),d=a(120),p=a(57),f=a(296),g=a(5),E=(a(141),a(150)),b=a(140),h=a(164),v=a.n(h),y={backgroundColor:"#F0F8FF",padding:"1px",fontSize:"16px"},_={height:200,width:500},x="\nimport tensorflow as tf\nimport pandas as pd\n\nCOLUMN_NAMES = [\n        'SepalLength', \n        'SepalWidth',\n        'PetalLength', \n        'PetalWidth', \n        'Species'\n        ]\n\n\ntraining_dataset = pd.read_csv('iris_training.csv', names=COLUMN_NAMES, header=0)                 #Import training dataset\ntrain_x = training_dataset.iloc[:, 0:4]\ntrain_y = training_dataset.iloc[:, 4]\n\ntest_dataset = pd.read_csv('iris_test.csv', names=COLUMN_NAMES, header=0)\ntest_x = test_dataset.iloc[:, 0:4]\ntest_y = test_dataset.iloc[:, 4]".trim(),w="\ntf.executing_eagerly()                                                                            #True\n\nx = [[2.]]\ny = tf.matmul(x,x)\nprint(y)\n".trim(),N="\nx = tf.constant([[1, 2, 3, 4 ,5]])                                        \ny = tf.ones((1,5))                                                       \nz = tf.zeros((1,5))                                                       \nq = tf.range(start=1, limit=6, delta=1)                                   \n\nprint(q)\n".trim(),T="\na=tf.constant(5)                                                          #Rank-0\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0])                                #Vector\nc = tf.constant([[10,20],[30,40],[50,60],[70,80]])                        #Rank-2\nd = tf.constant([[[10,20],[30,40],[50,60],[70,80]]])                      #Rank-3\ne = tf.ones([1,2,3,4,5])                                                  #Rank-3\n".trim(),j="\na = tf.constant([0,1,1,1,2,3,3,3,4,5,6,6])\nb = a.numpy()                                                             #for indexing we need to convert tensor to numpy\nb[2]\n".trim(),S="\nx = tf.constant([1,2,3])\ny = tf.constant(2)\nz = tf.constant([2,2,2])\n\nprint(tf.multiply(x,2))\nprint(x* y)\nprint(x * z)\n\n\n#2\nx = tf.reshape(x,[3,1])\ny = tf.range(1,5)\nprint(x, y)\nprint(tf.multiply(x,y))\n".trim(),k='\n#1 ragged_tensors\nragged_list = [[1, 2, 3],[4, 5],[6]]\nragged_tensor = tf.ragged.constant(ragged_list)\nragged_tensor\n\n\n#2 string_tensor\nstring_tensor = tf.constant(["With this", "code, I am", "creating a String Tensor"])\nstring_tensor\n\n\n#3 sparse_tensor\nsparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [2, 2], [4, 4]], values=[25, 50, 100], dense_shape=[5, 5])\nsparse_tensor\n\nctd = tf.sparse.to_dense(sparse_tensor)                                       #convert sparse tensors to dense\nctd\n'.trim(),z="\nx = tf.constant(2)\ny = tf.constant(5)\nresult = x+y\ntf.print(result)\n\nprint(tf.compat.v1.get_default_graph())                                                       #see generated graph\n\ng = tf.Graph()                                                                                #user define graph\nuserdefault = tf.compat.v1.get_default_graph()                                                #user define default graph\nprint(userdefault)\n".trim(),M="\n#1 constant\nimport tensorflow as tf\n\nx = tf.constant([[1,2],[3,4]])\ny = tf.add(x, 1)\nprint(x * y)\n\nz = np.multiply(x, y)\nprint(a.numpy)\n\n\n#2 Variables \nvar1 = tf.Variable([[1.2,2.1],[3.0,40.]])\nt1 = tf.convert_to_tensor(var1)                        # varriable convert to tensor \nprint(t1)    \n\n\n#3 \nvar1 = tf.Variable([12,30,40,50,60,70,80,90])\n\namax = tf.argmin(var1)\namin = tf.argmax(var1)\nrs = tf.reshape(var1, ([2,4]))\n\n\n#4\nmy_tensor = tf.random.uniform((5,5), 0,4)\nvar1 = tf.Variable(initial_value = my_tensor)                                                 #create variable\nprint(var1)\n\n\n#5\ntf.__version__\nconst = tf.constant(10)\nmat = tf.fill((5,5),10)\nzeros = tf.zeros((5,5))\nones = tf.ones((5,5))\nrandm = tf.random.normal((4,4), mean=0, stddev=1.0)\nrandu = tf.random.uniform((4,4), minval=0, maxval=1)\nmyops = [const, mat, zeros, ones, randu]\nprint(myops)\n\na = tf.constant([[2,3],[4,5]])\na.get_shape()\n\n\n#6\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\ntfph = tf.compat.v1.placeholder(tf.float32, shape=(None, 5))\na = tf.compat.v1.placeholder(tf.float32, name='a')\nb = tf.compat.v1.placeholder(tf.float32, name='b')\nc = tf.add(a, b, name='c')\nwith tf.Session() as sess:\n    sess.run(c, feed_dict={a: 2.1, b: 1.9})\n    print(tfph)\n".trim(),O="\nnp.random.seed(101)\ntf.random.set_seed(101)\nrand_a = np.random.uniform(0, 100, (5,5))\nrand_b = np.random.uniform(0, 100, (5,1))\n\n\n#2\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\na = tf.compat.v1.placeholder(tf.float32)\nb = tf.compat.v1.placeholder(tf.float32)\nadd = a+b\nmul = a*b\n\nwith tf.Session() as sess:\n    result = sess.run(add, feed_dict={a:rand_a, b:rand_b})\n    print(result)\n".trim(),A="\nnf = 1\nndf = 3\n\nbis = tf.Variable(tf.zeros([ndf]))\nwgt = tf.Variable(tf.random.normal([nf, ndf]))\n\n\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nx = tf.compat.v1.placeholder(tf.float32,(None, nf))\n\nxw = tf.matmul(x, wgt)                                                                      #y = mx + b\nz = tf.add(xw, b)\n\naf = tf.sigmoid(z)                                                                          #activation function\n\ninit = tf.compat.v1.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    layer_out = sess.run(af, feed_dict={x:np.random.random([1,nf])})\n\nprint(layer_out)\n".trim(),F='\nimport tensorflow.compat.v1 as tf\n\nnp.random.seed(101)\ntf.random.set_seed(101)\n\n\nx = np.linspace(0, 50, 50)                                                    # Generating random linear data\ny = np.linspace(0, 50, 50)\n  \nx += np.random.uniform(-4, 4, 50)                                             # Adding noise to the random linear data\ny += np.random.uniform(-4, 4, 50)\n  \nn = len(x) # Number of data points\n\nplt.scatter(x, y)\nplt.xlabel(\'x\')\nplt.xlabel(\'y\')\nplt.title("Training Data")\nplt.show()\n\n\ntf.disable_v2_behavior()\n\nX = tf.compat.v1.placeholder("float")\nY = tf.compat.v1.placeholder("float")\n\nW = tf.Variable(np.random.randn(), name = "W")\nb = tf.Variable(np.random.randn(), name = "b")\n\nlearning_rate = 0.01\ntraining_epochs = 1000\n\n\nwith tf.Session() as sess:                                                # Starting the Tensorflow Session\n    sess.run(init)                                                        # Initializing the Variables\n      \n    for epoch in range(training_epochs):\n        for (_x, _y) in zip(x, y):\n            sess.run(optimizer, feed_dict = {X : _x, Y : _y})             # Feeding each data point into the optimizer\n          \n        \n        if (epoch + 1) % 50 == 0:                                         # Displaying the result after every 50 epochs\n            c = sess.run(cost, feed_dict = {X : x, Y : y})                # Calculating the cost a every epoch\n            print((epoch + 1), c, sess.run(W), sess.run(b))\n    \n    training_cost = sess.run(cost, feed_dict ={X: x, Y: y})               # Storing values to be used outside the Session\n    weight = sess.run(W)\n    bias = sess.run(b)\n'.trim(),D=function(e){function n(){return Object(t.a)(this,n),Object(r.a)(this,Object(s.a)(n).apply(this,arguments))}return Object(i.a)(n,e),Object(l.a)(n,[{key:"componentDidMount",value:function(){setTimeout((function(){return u.a.highlightAll()}),0)}},{key:"render",value:function(){var e=this.props.classes;return c.a.createElement(d.a,{container:!0},c.a.createElement(d.a,{item:!0,xs:2},c.a.createElement(p.a,{className:e.paper},c.a.createElement("h4",null,c.a.createElement(E.a,null)))),c.a.createElement(d.a,{item:!0,xs:10},c.a.createElement(p.a,{className:e.paper},c.a.createElement(f.a,null,c.a.createElement("h3",null,"TensorFlow"),"TensorFlow designed to implement ML and DL concepts in the easiest manner.",c.a.createElement("br",null),c.a.createElement("br",null),"TensorFlow uses for numerical computation and large-scale ML. TensorFlow bundles together a slew of ML and DL (neural networking) models algorithms and makes them useful by way of a common metaphor.",c.a.createElement("br",null),c.a.createElement("br",null),c.a.createElement("b",null,"important features of TensorFlow:"),c.a.createElement("ul",null,c.a.createElement("li",null,"Defines, optimizes and calculates mathematical expressions easily with the help of multi-dimensional arrays (tensors)."),c.a.createElement("li",null,"Support of deep neural networks and ML techniques."),c.a.createElement("li",null,"It includes a high scalable feature of computation with various data sets."),c.a.createElement("li",null,"Uses GPU computing, automating management. It also includes a unique feature of optimization of same memory and the data used.")),c.a.createElement("br",null),c.a.createElement("h3",null,"Eager Execution"),"Eager execution is an imperative, define-by-run interface where operations are executed immediately as they are called from Python. This makes it easier to get started with TensorFlow, and can make research and development more intuitive.",c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:w,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Tensors"),"Tensors are TensorFlow\u2019s multi-dimensional arrays with uniform type. They are very similar to NumPy arrays, and immutable.",c.a.createElement("br",null),c.a.createElement("br",null),c.a.createElement("b",null,"Creating Tensor Objects:"),c.a.createElement("ul",null,c.a.createElement("li",null,c.a.createElement("b",null,"tf.constant(): ")),c.a.createElement("li",null,c.a.createElement("b",null,"tf.ones(): "),"Only consisting of 1s."),c.a.createElement("li",null,c.a.createElement("b",null,"tf.zeros(): "),"Only consisting of 0s."),c.a.createElement("li",null,c.a.createElement("b",null,"tf.range(): "),"To create Tensor objects.")),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:N,language:"js",plugins:["line-numbers"]})),c.a.createElement("i",null,c.a.createElement("b",null,"N: "),"tf.ones and tf.zeros accepts the shape as the required argument since their element values are pre-determined."),c.a.createElement("br",null),c.a.createElement("h3",null,"Rank System and Dimension"),c.a.createElement("ul",null,c.a.createElement("li",null,c.a.createElement("b",null,"Rank-0 (Scalar) Tensor: "),"A tensor containing a single value and no axes."),c.a.createElement("li",null,c.a.createElement("b",null,"Rank-1 (Vector) Tensor: "),"A tensor containing a list of values in a single axis."),c.a.createElement("li",null,c.a.createElement("b",null,"Rank-2 Tensor: "),"A tensor containing 2-axes."),c.a.createElement("li",null,c.a.createElement("b",null,"Rank-3 Tensor: "),"A tensor containing 3-axes."),c.a.createElement("li",null,c.a.createElement("b",null,"Rank-4 Tensor: "),"4th dimension is space.")),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:T,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Operations with Tensors"),c.a.createElement("ul",null,c.a.createElement("li",null,"Indexing"),c.a.createElement("li",null,"Addition"),c.a.createElement("li",null,"Element-wise Multiplication"),c.a.createElement("li",null,"Matrix Multiplication"),c.a.createElement("li",null,"Finding the Maximum/ Minimum"),c.a.createElement("li",null,"Finding the Index of the Max Element"),c.a.createElement("li",null,"Computing Softmax Value")),c.a.createElement("i",null,"Commas (,) are used to reach deeper levels."),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:j,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Broadcasting with Tensor"),c.a.createElement("ul",null,c.a.createElement("li",null,"Broadcasting concept is borrowed from Numpy broadcasting."),c.a.createElement("li",null,"Broadcasting is about bringing the tensors of different dimensions/ shape to the compatible shape such that arithmetic operations can be performed on them."),c.a.createElement("li",null,"In broadcasting, the smaller array is found, the new axes are added as per the larger array and data is added appropriately to the transformed array.")),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:S,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Special Types of Tensors"),"We tend to generate Tensors in a rectangular shape and store numerical values as elements. However, TensorFlow also supports irregular, or specialized, Tensor types, which are:",c.a.createElement("ul",null,c.a.createElement("li",null,c.a.createElement("b",null,"Ragged Tensors: "),"Are tensors with different numbers of elements along the size axis."),c.a.createElement("li",null,c.a.createElement("b",null,"String Tensors: "),"Are stores string objects. We can build a String Tensor just as you create a regular Tensor object. But, we pass string objects as elements instead of numerical objects."),c.a.createElement("li",null,c.a.createElement("b",null,"Sparse Tensors: "),"Are rectangular Tensors for sparse data. When we have holes (Null values) in our data, Sparse Tensors are to-go objects.")),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:k,language:"js",plugins:["line-numbers"]})),c.a.createElement("h3",null,"Variables & Placeholders"),"Two way to initialize varriabble.",c.a.createElement("ul",null,c.a.createElement("li",null,c.a.createElement("b",null,"constant: "),"initialize constant variable."),c.a.createElement("li",null,c.a.createElement("b",null,"Variable: "))),c.a.createElement("br",null),c.a.createElement("b",null,"Methods:"),c.a.createElement("ul",null,c.a.createElement("li",null,c.a.createElement("b",null,"argmin(): "),"Show smallest value index number."),c.a.createElement("li",null,c.a.createElement("b",null,"argmax(): "),"Show large value index number.")),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:M,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Import training dataset"),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:x,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Tensorflow Graph"),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:z,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Perceptron"),"Perceptron is an algorithm that, given an inputs features, outputs either 1 or 0.",c.a.createElement("br",null),c.a.createElement("img",{src:v.a,alt:"Theata",className:"responsive2",style:_}),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:O,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Neural Network"),c.a.createElement("ul",null,c.a.createElement("li",null,"Neural networks, a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data."),c.a.createElement("li",null,"DL, a powerful set of techniques for learning in neural networks."),c.a.createElement("li",null,"Neural networks and DL currently provide the best solutions to many problems in image recognition, speech recognition, and natural language processing.")),c.a.createElement("br",null),c.a.createElement("br",null),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:A,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Regression"),c.a.createElement("div",{style:y},c.a.createElement(b.a,{code:F,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null)))))}}]),n}(o.Component);n.default=Object(g.a)((function(e){return{paper:{margin:e.spacing(1),padding:e.spacing(1)},smMargin:{margin:e.spacing(1)},actionDiv:{textAlign:"center"}}}))(D)}}]);
//# sourceMappingURL=49.a6747734.chunk.js.map
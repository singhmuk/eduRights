{"version":3,"sources":["components/ReactJs/prismCode.js","components/ml/sidebar.js","components/ml/deepMl/adaboost.js"],"names":["PrismCode","props","highlight","ref","current","Prism","highlightElement","React","createRef","this","code","language","plugins","className","trim","Component","useStyles","makeStyles","theme","root","display","paper","marginRight","spacing","line","textDecoration","Sidebar","classes","to","titles","backgroundColor","padding","fontSize","stack","testings","performance","Adaboots","setTimeout","highlightAll","container","item","xs","style","withStyles","margin","smMargin","actionDiv","textAlign"],"mappings":"mPAIqBA,G,kBACnB,WAAYC,GAAQ,IAAD,8BACjB,4CAAMA,KAYRC,UAAY,WACN,EAAKC,KAAO,EAAKA,IAAIC,SACvBC,IAAMC,iBAAiB,EAAKH,IAAIC,UAblC,EAAKD,IAAMI,IAAMC,YAFA,E,iFAMjBC,KAAKP,c,2CAILO,KAAKP,c,+BASG,IAAD,EAC6BO,KAAKR,MAAjCS,EADD,EACCA,KAAeC,GADhB,EACOC,QADP,EACgBD,UACvB,OACE,yBAAKE,UAAU,cACb,0BAAMV,IAAKM,KAAKN,IAAKU,UAAS,mBAAcF,IACzCD,EAAKI,a,GAzBuBP,IAAMQ,a,uDCJ7C,yFAMMC,EAAYC,aAAW,SAACC,GAAD,MAAY,CACvCC,KAAM,CACJC,QAAS,QAEXC,MAAO,CACLC,YAAaJ,EAAMK,QAAQ,IAE7BC,KAAM,CACJC,eAAgB,YAIL,SAASC,IACtB,IAAMC,EAAUX,IAEhB,OACE,yBAAKH,UAAWc,EAAQR,MACtB,kBAAC,IAAD,KACE,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMS,GAAG,UAAUf,UAAWc,EAAQH,MAAtC,WACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,oBAAoBf,UAAWc,EAAQH,MAAhD,qBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,YAAYf,UAAWc,EAAQH,MAAxC,YAEV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,mBAAmBf,UAAWc,EAAQH,MAA/C,oBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,eAAef,UAAWc,EAAQH,MAA3C,gBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,YAAYf,UAAWc,EAAQH,MAAxC,aACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,eAAef,UAAWc,EAAQH,MAA3C,iBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,cAAcf,UAAWc,EAAQH,MAA1C,eACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,SAASf,UAAWc,EAAQH,MAArC,QAEV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,qBAAqBf,UAAWc,EAAQH,MAAjD,uBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,eAAef,UAAWc,EAAQH,MAA3C,wBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,OAAOf,UAAWc,EAAQH,MAAnC,QACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,OAAOf,UAAWc,EAAQH,MAAnC,QACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,mBAAmBf,UAAWc,EAAQH,MAA/C,WACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,YAAYf,UAAWc,EAAQH,MAAxC,gBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,gBAAgBf,UAAWc,EAAQH,MAA5C,kBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,gBAAgBf,UAAWc,EAAQH,MAA5C,kBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,SAASf,UAAWc,EAAQH,MAArC,QAEV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,WAAWf,UAAWc,EAAQH,MAAvC,UACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,UAAUf,UAAWc,EAAQH,MAAtC,WACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,WAAWf,UAAWc,EAAQH,MAAvC,eACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,sBAAsBf,UAAWc,EAAQH,MAAlD,iBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,cAAcf,UAAWc,EAAQH,MAA1C,UACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,aAAaf,UAAWc,EAAQH,MAAzC,WACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,WAAWf,UAAWc,EAAQH,MAAvC,YACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,cAAcf,UAAWc,EAAQH,MAA1C,eACV,6BA9BF,gBAiCE,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,aAAaf,UAAWc,EAAQH,MAAzC,eAEZ,iC,qLCjDAK,EAAS,CAAEC,gBAAiB,UAAWC,QAAS,MAAOC,SAAU,QAgBjEC,EAAQ,mwFA+EZnB,OAEIoB,EAAW,4pBAuBXpB,OAEAqB,EAAc,8LAMlBrB,OAKIsB,E,4LAEFC,YAAW,kBAAMhC,IAAMiC,iBAAgB,K,+BAE/B,IACAX,EAAYlB,KAAKR,MAAjB0B,QACR,OACE,kBAAC,IAAD,CAAMY,WAAS,GACb,kBAAC,IAAD,CAAMC,MAAI,EAACC,GAAI,GACb,kBAAC,IAAD,CAAO5B,UAAWc,EAAQN,OACxB,4BAAI,kBAAC,IAAD,SAGR,kBAAC,IAAD,CAAMmB,MAAI,EAACC,GAAI,IACb,kBAAC,IAAD,CAAO5B,UAAWc,EAAQN,OACxB,kBAAC,IAAD,KACE,8CACA,4BACE,4BAAI,6CACJ,4BAAI,qDAAJ,yFACA,6BACA,4BAAI,8DACJ,4BACE,mDACA,uEACA,iDACA,8CACA,wEACA,0EACA,yDACA,kDACA,qFAIJ,6BAEA,4DACA,4BACE,uEACA,oDACA,kOAEA,4GAAiF,8CAAjF,KACA,gJACA,oHACA,0EACA,4GACA,uEACA,mGAEF,6BACA,6BAEA,6DACA,4BACE,yFACA,wIACA,0EACA,qIACA,wFACA,8HAEF,6BAEA,yBAAKqB,MAAOb,GACV,kBAAC,IAAD,CACEnB,KAAMyB,EACNxB,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,yBAAK8B,MAAOb,GACV,kBAAC,IAAD,CACEnB,KAAMuB,EACNtB,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,uCACA,yBAAK8B,MAAOb,GACV,kBAAC,IAAD,CACEnB,KAAMwB,EACNvB,SAAS,KACTC,QAAS,CAAC,2B,GAxFLG,aAuHP4B,uBA1PD,SAAAzB,GAAK,MAAK,CACvBG,MAAO,CACLuB,OAAQ1B,EAAMK,QAAQ,GACtBQ,QAASb,EAAMK,QAAQ,IAEzBsB,SAAU,CACRD,OAAQ1B,EAAMK,QAAQ,IAExBuB,UAAW,CACTC,UAAW,aAiPCJ,CAAmBP","file":"static/js/181.42055342.chunk.js","sourcesContent":["import React from \"react\"\nimport Prism from \"prismjs\"\nimport '../dashboard/blog/styles.css'\n\nexport default class PrismCode extends React.Component {\n  constructor(props) {\n    super(props)\n    this.ref = React.createRef()\n  }\n\n  componentDidMount() {\n    this.highlight()\n  }\n\n  componentDidUpdate() {\n    this.highlight()\n  }\n\n  highlight = () => {\n    if (this.ref && this.ref.current) {\n      Prism.highlightElement(this.ref.current)\n    }\n  }\n\n  render() {\n    const { code, plugins, language } = this.props\n    return (\n      <pre className=\"code-prism\">\n        <code ref={this.ref} className={`language-${language}`}>\n          {code.trim()}\n        </code>\n      </pre>\n    )\n  }\n}","import React from 'react';\nimport { Link } from 'react-router-dom';\nimport MenuItem from '@material-ui/core/MenuItem';\nimport MenuList from '@material-ui/core/MenuList';\nimport { makeStyles } from '@material-ui/core/styles';\n\nconst useStyles = makeStyles((theme) => ({\n  root: {\n    display: 'flex',\n  },\n  paper: {\n    marginRight: theme.spacing(2),\n  },\n  line: {\n    textDecoration: 'none'\n  }\n}));\n\nexport default function Sidebar() {\n  const classes = useStyles();\n\n  return (\n    <div className={classes.root}>\n      <MenuList>\n        <MenuItem><Link to='/infoMl' className={classes.line}>InfoMl</Link></MenuItem>\n        <MenuItem><Link to='/gredient_decents' className={classes.line}>Gredient Decents</Link></MenuItem>\n        <MenuItem><Link to='/training' className={classes.line}>Traning</Link></MenuItem>\n\n        <MenuItem><Link to='/regularizations' className={classes.line}>Regularizations</Link></MenuItem>\n        <MenuItem><Link to='/featuresEng' className={classes.line}>FeaturesEng</Link></MenuItem>\n        <MenuItem><Link to='/adaboost' className={classes.line}>Adaboots</Link></MenuItem>\n        <MenuItem><Link to='/greedSearch' className={classes.line}>Greed Search</Link></MenuItem>\n        <MenuItem><Link to='/perceptron' className={classes.line}>Perceptron</Link></MenuItem>\n        <MenuItem><Link to='/pcaPy' className={classes.line}>PCA</Link></MenuItem>\n\n        <MenuItem><Link to='/leanearRegression' className={classes.line}>Leanear Regression</Link></MenuItem>\n        <MenuItem><Link to='/logisticReg' className={classes.line}>Logistic Regression</Link></MenuItem>\n        <MenuItem><Link to='/lda' className={classes.line}>Lda</Link></MenuItem>\n        <MenuItem><Link to='/knn' className={classes.line}>Knn</Link></MenuItem>\n        <MenuItem><Link to='/k_meanClustring' className={classes.line}>K_Mean</Link></MenuItem>\n        <MenuItem><Link to='/naiveBar' className={classes.line}>Naive Bayes</Link></MenuItem>\n        <MenuItem><Link to='/randomForest' className={classes.line}>Random Forest</Link></MenuItem>\n        <MenuItem><Link to='/decisiontree' className={classes.line}>Decision Tree</Link></MenuItem>\n        <MenuItem><Link to='/svmPy' className={classes.line}>SVM</Link></MenuItem>\n\n        <MenuItem><Link to='/numpyPy' className={classes.line}>Numpy</Link></MenuItem>\n        <MenuItem><Link to='/pandas' className={classes.line}>Pandas</Link></MenuItem>\n        <MenuItem><Link to='/bagging' className={classes.line}>Matplotlib</Link></MenuItem>\n        <MenuItem><Link to='/logisticRegrations' className={classes.line}>Scikit Learn</Link></MenuItem>\n        <MenuItem><Link to='/regrations' className={classes.line}>SciPy</Link></MenuItem>\n        <MenuItem><Link to='/libraries' className={classes.line}>OpenCV</Link></MenuItem>\n        <MenuItem><Link to='/capture' className={classes.line}>Capture</Link></MenuItem>\n        <MenuItem><Link to='/joinImages' className={classes.line}>JoinImages</Link></MenuItem>\n        <br />\n\n        Deep Learning\n        <MenuItem><Link to='/superwise' className={classes.line}>Superwise</Link></MenuItem>\n      </MenuList>\n      <div>\n      </div>\n    </div>\n  );\n}\n","import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst stack = `\nimport numpy as np\n\n# Decision stump used as weak classifier\nclass DecisionStump:\n    def __init__(self):\n        self.polarity = 1\n        self.feature_idx = None\n        self.threshold = None\n        self.alpha = None\n\n    def predict(self, X):\n        n_samples = X.shape[0]\n        X_column = X[:, self.feature_idx]\n        predictions = np.ones(n_samples)\n        if self.polarity == 1:\n            predictions[X_column < self.threshold] = -1\n        else:\n            predictions[X_column > self.threshold] = -1\n\n        return predictions\n\n\nclass Adaboost:\n    def __init__(self, n_clf=5):\n        self.n_clf = n_clf\n        self.clfs = []\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n\n        w = np.full(n_samples, (1 / n_samples))                          # Initialize weights to 1/N\n\n        self.clfs = []\n        \n        for _ in range(self.n_clf):                                      # Iterate through classifiers\n            clf = DecisionStump()\n            min_error = float(\"inf\")\n\n            for feature_i in range(n_features):                          # greedy search to find best threshold and feature\n                X_column = X[:, feature_i]\n                thresholds = np.unique(X_column)\n\n                for threshold in thresholds:\n                    p = 1                                                # predict with polarity 1\n                    predictions = np.ones(n_samples)\n                    predictions[X_column < threshold] = -1\n\n                    misclassified = w[y != predictions]                  # Error = sum of weights of misclassified samples\n                    error = sum(misclassified)\n\n                    if error > 0.5:\n                        error = 1 - error\n                        p = -1\n\n                    if error < min_error:                               # store the best configuration\n                        clf.polarity = p\n                        clf.threshold = threshold\n                        clf.feature_idx = feature_i\n                        min_error = error\n\n            # calculate alpha\n            EPS = 1e-10\n            clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS))\n\n            predictions = clf.predict(X)                                         # calculate predictions and update weights\n\n            w *= np.exp(-clf.alpha * y * predictions)\n            # Normalize to one\n            w /= np.sum(w)\n\n            self.clfs.append(clf)                                               # Save classifier\n\n    def predict(self, X):\n        clf_preds = [clf.alpha * clf.predict(X) for clf in self.clfs]\n        y_pred = np.sum(clf_preds, axis=0)\n        y_pred = np.sign(y_pred)\n\n        return y_pred\n`.trim();\n\nconst testings = `\nif __name__ == \"__main__\":\n    from sklearn import datasets\n    from sklearn.model_selection import train_test_split\n\n    def accuracy(y_true, y_pred):\n        accuracy = np.sum(y_true == y_pred) / len(y_true)   \n        return accuracy\n\n    data = datasets.load_breast_cancer()\n    X, y = data.data, data.target\n\n    y[y == 0] = -1\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n\n    # Adaboost classification with 5 weak classifiers\n    clf = Adaboost(n_clf=5)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n\n    acc = accuracy(y_test, y_pred)\n    print(\"Accuracy:\", acc)\n    `.trim();\n\nconst performance = `\nPerformance of stump = 1/2 * log(1-Total Error) / Total Error\n\nNew weights = old weight * e(+-Performanse)\n    where, + for Misclassification\n           - for Right classification\n`.trim();\n\n// const stack = ``.trim();\n\n\nclass Adaboots extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Boosting Types</h3>\n              <ul>\n                <li><b>1. Adaboost: </b></li>\n                <li><b>2. Gradient Boosting: </b>Instead of Weights updation, here gradient (residuals, loss) is passed in next model.</li>\n                <br />\n                <li><b>3. Extream Gradient Boosting: </b></li>\n                <ul>\n                  <li>Much similar to GB.</li>\n                  <li>2nd order Derivatives of Loss function.</li>\n                  <li>High Performance.</li>\n                  <li>Fast training.</li>\n                  <li>Advanced L1 and L2 Loass Regularization.</li>\n                  <li>Parallel and Distributed computing (DMLC).</li>\n                  <li>It handle missing values.</li>\n                  <li>Cache Optimisation</li>\n                  <li>It has many hyperparameters. reg_alpha, reg_lambda.</li>\n                </ul>\n              </ul>\n\n              <br />\n\n              <h3>Adaboost (Adaptive boosting)</h3>\n              <ul>\n                <li>Used for Classification and Regression.</li>\n                <li>Sequencial boosting.</li>\n                <li>AdaBoost is one of the first boosting algorithms to be adapted in solving practices. Adaboost helps you combine\n                  multiple “weak classifiers” into a single “strong classifier”.</li>\n                <li>The weak learners in AdaBoost are decision trees with a single split, called <b>decision stumps</b>.</li>\n                <li>AdaBoost works by putting more weight on difficult to classify instances and less on those already handled well.</li>\n                <li>Weight increase for misclassification and weight decreses for right classifications.</li>\n                <li>Used to exploit dependency between models.</li>\n                <li>Stagewise additive MultiModeling using Multiclass Exponential Loss Function.</li>\n                <li>Can handle missing values and outliner.</li>\n                <li>Can handles mixed predictors as well (Quantitive and Qualitative).</li>\n              </ul>\n              <br />\n              <br />\n\n              <b>Steps for Adaboost Algoritham:</b>\n              <ul>\n                <li>1. Initialize the weights as 1/n to every n observations.</li>\n                <li>2. Select the 1 Feature according to Lowest Gini/Highest information Gain and calculate the total error.</li>\n                <li>3. Calculate the Performance of the stump.</li>\n                <li>4. Calculate the new weights for each misclassification(increase) and right classification(decrease).</li>\n                <li>5. Normalize the new weights so that sum of weight is 1.</li>\n                <li>6. Repeat from step 2 to till configured number of estimators reacfied the accuracy achieved.</li>\n              </ul>\n              <br />\n\n              <div style={titles}>\n                <PrismCode\n                  code={performance}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <div style={titles}>\n                <PrismCode\n                  code={stack}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Testing</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={testings}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              {/* <br />\n\n              <h3></h3>\n              <div style={titles}>\n                <PrismCode\n                  code={stack}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3></h3>\n              <div style={titles}>\n                <PrismCode\n                  code={stack}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div> */}\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\nexport default (withStyles(styles)(Adaboots));\n"],"sourceRoot":""}
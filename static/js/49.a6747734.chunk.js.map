{"version":3,"sources":["components/ReactJs/prismCode.js","components/angularjs/sidebar.js","assets/ML/perceptrons.png","components/angularjs/deepAngularjs/tensorflow.js"],"names":["PrismCode","props","highlight","ref","current","Prism","highlightElement","React","createRef","this","code","language","plugins","className","trim","Component","useStyles","makeStyles","theme","root","display","paper","marginRight","spacing","line","textDecoration","Sidebar","classes","to","module","exports","titles","backgroundColor","padding","fontSize","redesign","height","width","tensorlow","eager","tensorObj","rankDim","indexings","broadcasting","specialTen","graphs","variables","perceptropn","neuralsnet","regressions","TensorFlows","setTimeout","highlightAll","container","item","xs","style","src","NeuralKeras","alt","withStyles","margin","smMargin","actionDiv","textAlign"],"mappings":"kPAIqBA,G,kBACnB,WAAYC,GAAQ,IAAD,8BACjB,4CAAMA,KAYRC,UAAY,WACN,EAAKC,KAAO,EAAKA,IAAIC,SACvBC,IAAMC,iBAAiB,EAAKH,IAAIC,UAblC,EAAKD,IAAMI,IAAMC,YAFA,E,iFAMjBC,KAAKP,c,2CAILO,KAAKP,c,+BASG,IAAD,EAC6BO,KAAKR,MAAjCS,EADD,EACCA,KAAeC,GADhB,EACOC,QADP,EACgBD,UACvB,OACE,yBAAKE,UAAU,cACb,0BAAMV,IAAKM,KAAKN,IAAKU,UAAS,mBAAcF,IACzCD,EAAKI,a,GAzBuBP,IAAMQ,a,uDCJ7C,yFAMMC,EAAYC,aAAW,SAACC,GAAD,MAAY,CACvCC,KAAM,CACJC,QAAS,QAEXC,MAAO,CACLC,YAAaJ,EAAMK,QAAQ,IAE7BC,KAAM,CACJC,eAAgB,YAIL,SAASC,IACtB,IAAMC,EAAUX,IAEhB,OACE,yBAAKH,UAAWc,EAAQR,MACtB,kBAAC,IAAD,KACE,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMS,GAAG,gBAAgBf,UAAWc,EAAQH,MAA5C,OACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,cAAcf,UAAWc,EAAQH,MAA1C,eACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,WAAWf,UAAWc,EAAQH,MAAvC,iBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,eAAef,UAAWc,EAAQH,MAA3C,aACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,UAAUf,UAAWc,EAAQH,MAAtC,gBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,uBAAuBf,UAAWc,EAAQH,MAAnD,oBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,QAAQf,UAAWc,EAAQH,MAApC,SACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,kBAAkBf,UAAWc,EAAQH,MAA9C,mBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,cAAcf,UAAWc,EAAQH,MAA1C,eACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,gBAAgBf,UAAWc,EAAQH,MAA5C,iBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,YAAYf,UAAWc,EAAQH,MAAxC,aACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,sBAAsBf,UAAWc,EAAQH,MAAlD,wBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,cAAcf,UAAWc,EAAQH,MAA1C,eACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,eAAef,UAAWc,EAAQH,MAA3C,gBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,kBAAkBf,UAAWc,EAAQH,MAA9C,mBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,qBAAqBf,UAAWc,EAAQH,MAAjD,sBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,YAAYf,UAAWc,EAAQH,MAAxC,aACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,kBAAkBf,UAAWc,EAAQH,MAA9C,cACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,eAAef,UAAWc,EAAQH,MAA3C,cACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,gBAAgBf,UAAWc,EAAQH,MAA5C,gBACV,kBAAC,IAAD,KAAU,kBAAC,IAAD,CAAMI,GAAG,gBAAgBf,UAAWc,EAAQH,MAA5C,oBAEZ,iC,oBC9CNK,EAAOC,QAAU,IAA0B,yC,uMCWrCC,EAAS,CAAEC,gBAAiB,UAAWC,QAAS,MAAOC,SAAU,QAEjEC,EAAW,CACfC,OAAQ,IACRC,MAAO,KAgBHC,EAAY,uiBAmBgBxB,OAE5ByB,EAAQ,0JAMZzB,OAEI0B,EAAY,gUAOhB1B,OAEI2B,EAAU,oaAMd3B,OAEI4B,EAAY,mLAIhB5B,OAEI6B,EAAe,6NAenB7B,OAEI8B,EAAa,ygBAkBjB9B,OAEI+B,EAAS,qcAWb/B,OAEIgC,EAAY,qyCA0DhBhC,OAEIiC,EAAc,uaAmBlBjC,OAEIkC,EAAa,spBAwBjBlC,OAEImC,EAAc,uqDAiDlBnC,OAGIoC,E,4LAEFC,YAAW,kBAAM9C,IAAM+C,iBAAgB,K,+BAE/B,IACAzB,EAAYlB,KAAKR,MAAjB0B,QACR,OACE,kBAAC,IAAD,CAAM0B,WAAS,GACb,kBAAC,IAAD,CAAMC,MAAI,EAACC,GAAI,GACb,kBAAC,IAAD,CAAO1C,UAAWc,EAAQN,OACxB,4BAAI,kBAAC,IAAD,SAGR,kBAAC,IAAD,CAAMiC,MAAI,EAACC,GAAI,IACb,kBAAC,IAAD,CAAO1C,UAAWc,EAAQN,OACxB,kBAAC,IAAD,KACE,0CADF,6EAGE,6BACA,6BAJF,yMAQE,6BACA,6BAEA,gEACA,4BACE,sJAEA,kFACA,0GACA,+JAGF,6BAEA,+CAtBF,iPAyBE,yBAAKmC,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAM6B,EACN5B,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,uCAlCF,kIAoCE,6BACA,6BACA,uDACA,4BACE,4BAAI,+CACJ,4BAAI,0CAAJ,0BACA,4BAAI,2CAAJ,0BACA,4BAAI,2CAAJ,8BAEF,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAM8B,EACN7B,SAAS,KACTC,QAAS,CAAC,mBAGd,2BAAG,kCAAH,kHACA,6BAEA,yDACA,4BACE,4BAAI,uDAAJ,mDACA,4BAAI,uDAAJ,0DACA,4BAAI,8CAAJ,+BACA,4BAAI,8CAAJ,+BACA,4BAAI,8CAAJ,4BAEF,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAM+B,EACN9B,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,uDACA,4BACE,wCACA,wCACA,2DACA,qDACA,4DACA,oEACA,wDAEF,0EACA,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAMgC,EACN/B,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,wDACA,4BACE,yFACA,2LAEA,sLAIF,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAMiC,EACNhC,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,wDA9GF,mLAiHE,4BACE,4BAAI,+CAAJ,uEACA,4BAAI,+CAAJ,6KAEA,4BAAI,+CAAJ,6HAGF,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAMkC,EACNjC,SAAS,KACTC,QAAS,CAAC,mBAId,wDAhIF,oCAkIE,4BACE,4BAAI,yCAAJ,iCACA,4BAAI,2CAEN,6BACA,uCACA,4BACE,4BAAI,yCAAJ,qCACA,4BAAI,yCAAJ,mCAEF,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAMoC,EACNnC,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,uDACA,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAM4B,EACN3B,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,gDACA,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAMmC,EACNlC,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,0CAzKF,oFA2KE,6BACA,yBAAK6C,IAAKC,IAAaC,IAAI,SAAS9C,UAAU,cAAc2C,MAAOrB,IACnE,yBAAKqB,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAMqC,EACNpC,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,8CACA,4BACE,kKACA,iGACA,wLAGF,6BACA,6BAEA,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAMsC,EACNrC,SAAS,KACTC,QAAS,CAAC,mBAGd,6BAEA,0CACA,yBAAK4C,MAAOzB,GACV,kBAAC,IAAD,CACErB,KAAMuC,EACNtC,SAAS,KACTC,QAAS,CAAC,mBAGd,qC,GAhOYG,aA0OV6C,uBA5fD,SAAA1C,GAAK,MAAK,CACvBG,MAAO,CACLwC,OAAQ3C,EAAMK,QAAQ,GACtBU,QAASf,EAAMK,QAAQ,IAEzBuC,SAAU,CACRD,OAAQ3C,EAAMK,QAAQ,IAExBwC,UAAW,CACTC,UAAW,aAmfCJ,CAAmBV","file":"static/js/49.a6747734.chunk.js","sourcesContent":["import React from \"react\"\nimport Prism from \"prismjs\"\nimport '../dashboard/blog/styles.css'\n\nexport default class PrismCode extends React.Component {\n  constructor(props) {\n    super(props)\n    this.ref = React.createRef()\n  }\n\n  componentDidMount() {\n    this.highlight()\n  }\n\n  componentDidUpdate() {\n    this.highlight()\n  }\n\n  highlight = () => {\n    if (this.ref && this.ref.current) {\n      Prism.highlightElement(this.ref.current)\n    }\n  }\n\n  render() {\n    const { code, plugins, language } = this.props\n    return (\n      <pre className=\"code-prism\">\n        <code ref={this.ref} className={`language-${language}`}>\n          {code.trim()}\n        </code>\n      </pre>\n    )\n  }\n}","import React from 'react';\nimport { Link } from 'react-router-dom';\nimport MenuItem from '@material-ui/core/MenuItem';\nimport MenuList from '@material-ui/core/MenuList';\nimport { makeStyles } from '@material-ui/core/styles';\n\nconst useStyles = makeStyles((theme) => ({\n  root: {\n    display: 'flex',\n  },\n  paper: {\n    marginRight: theme.spacing(2),\n  },\n  line: {\n    textDecoration: 'none'\n  }\n}));\n\nexport default function Sidebar() {\n  const classes = useStyles();\n\n  return (\n    <div className={classes.root}>\n      <MenuList>\n        <MenuItem><Link to='/introAngular' className={classes.line}>AI</Link></MenuItem>\n        <MenuItem><Link to='/tensorflow' className={classes.line}>Tensorflow</Link></MenuItem>\n        <MenuItem><Link to='/tensors' className={classes.line}>Tensorboards</Link></MenuItem>\n        <MenuItem><Link to='/angCompiler' className={classes.line}>Compiler</Link></MenuItem>\n        <MenuItem><Link to='/neural' className={classes.line}>NeuralKeras</Link></MenuItem>\n        <MenuItem><Link to='/activationFunctions' className={classes.line}>activationFuncs</Link></MenuItem>\n        <MenuItem><Link to='/loss' className={classes.line}>Loss</Link></MenuItem>\n        <MenuItem><Link to='/gradientNeural' className={classes.line}>GradientNeural</Link></MenuItem>\n        <MenuItem><Link to='/stochastic' className={classes.line}>Stochastic</Link></MenuItem>\n        <MenuItem><Link to='/benchmarking' className={classes.line}>Benchmarking</Link></MenuItem>\n        <MenuItem><Link to='/customer' className={classes.line}>Customer</Link></MenuItem>\n        <MenuItem><Link to='/regularizationDeep' className={classes.line}>Regularization Deep</Link></MenuItem>\n        <MenuItem><Link to='/imbalanced' className={classes.line}>Imbalanced</Link></MenuItem>\n        <MenuItem><Link to='/imbalanced2' className={classes.line}>Imbalanced2</Link></MenuItem>\n        <MenuItem><Link to='/convolutionals' className={classes.line}>Convolutionals</Link></MenuItem>\n        <MenuItem><Link to='/data_augmentation' className={classes.line}>data Augmentation</Link></MenuItem>\n        <MenuItem><Link to='/transfer' className={classes.line}>Transfer</Link></MenuItem>\n        <MenuItem><Link to='/word_embedding' className={classes.line}>Embedding</Link></MenuItem>\n        <MenuItem><Link to='/datatypests' className={classes.line}>Datatypes</Link></MenuItem>\n        <MenuItem><Link to='/typeScript_2' className={classes.line}>TS Function</Link></MenuItem>\n        <MenuItem><Link to='/typeScript_4' className={classes.line}>Type Assertion</Link></MenuItem>\n      </MenuList>\n      <div>\n      </div>\n    </div>\n  );\n}\n\n","module.exports = __webpack_public_path__ + \"static/media/perceptrons.f6ad4ad3.png\";","import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\nimport NeuralKeras from '../../../assets/ML/perceptrons.png'\n\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst redesign = {\n  height: 200,\n  width: 500\n}\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\nconst tensorlow = `\nimport tensorflow as tf\nimport pandas as pd\n\nCOLUMN_NAMES = [\n        'SepalLength', \n        'SepalWidth',\n        'PetalLength', \n        'PetalWidth', \n        'Species'\n        ]\n\n\ntraining_dataset = pd.read_csv('iris_training.csv', names=COLUMN_NAMES, header=0)                 #Import training dataset\ntrain_x = training_dataset.iloc[:, 0:4]\ntrain_y = training_dataset.iloc[:, 4]\n\ntest_dataset = pd.read_csv('iris_test.csv', names=COLUMN_NAMES, header=0)\ntest_x = test_dataset.iloc[:, 0:4]\ntest_y = test_dataset.iloc[:, 4]`.trim();\n\nconst eager = `\ntf.executing_eagerly()                                                                            #True\n\nx = [[2.]]\ny = tf.matmul(x,x)\nprint(y)\n`.trim();\n\nconst tensorObj = `\nx = tf.constant([[1, 2, 3, 4 ,5]])                                        \ny = tf.ones((1,5))                                                       \nz = tf.zeros((1,5))                                                       \nq = tf.range(start=1, limit=6, delta=1)                                   \n\nprint(q)\n`.trim();\n\nconst rankDim = `\na=tf.constant(5)                                                          #Rank-0\nb = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0])                                #Vector\nc = tf.constant([[10,20],[30,40],[50,60],[70,80]])                        #Rank-2\nd = tf.constant([[[10,20],[30,40],[50,60],[70,80]]])                      #Rank-3\ne = tf.ones([1,2,3,4,5])                                                  #Rank-3\n`.trim();\n\nconst indexings = `\na = tf.constant([0,1,1,1,2,3,3,3,4,5,6,6])\nb = a.numpy()                                                             #for indexing we need to convert tensor to numpy\nb[2]\n`.trim();\n\nconst broadcasting = `\nx = tf.constant([1,2,3])\ny = tf.constant(2)\nz = tf.constant([2,2,2])\n\nprint(tf.multiply(x,2))\nprint(x* y)\nprint(x * z)\n\n\n#2\nx = tf.reshape(x,[3,1])\ny = tf.range(1,5)\nprint(x, y)\nprint(tf.multiply(x,y))\n`.trim();\n\nconst specialTen = `\n#1 ragged_tensors\nragged_list = [[1, 2, 3],[4, 5],[6]]\nragged_tensor = tf.ragged.constant(ragged_list)\nragged_tensor\n\n\n#2 string_tensor\nstring_tensor = tf.constant([\"With this\", \"code, I am\", \"creating a String Tensor\"])\nstring_tensor\n\n\n#3 sparse_tensor\nsparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [2, 2], [4, 4]], values=[25, 50, 100], dense_shape=[5, 5])\nsparse_tensor\n\nctd = tf.sparse.to_dense(sparse_tensor)                                       #convert sparse tensors to dense\nctd\n`.trim();\n\nconst graphs = `\nx = tf.constant(2)\ny = tf.constant(5)\nresult = x+y\ntf.print(result)\n\nprint(tf.compat.v1.get_default_graph())                                                       #see generated graph\n\ng = tf.Graph()                                                                                #user define graph\nuserdefault = tf.compat.v1.get_default_graph()                                                #user define default graph\nprint(userdefault)\n`.trim();\n\nconst variables = `\n#1 constant\nimport tensorflow as tf\n\nx = tf.constant([[1,2],[3,4]])\ny = tf.add(x, 1)\nprint(x * y)\n\nz = np.multiply(x, y)\nprint(a.numpy)\n\n\n#2 Variables \nvar1 = tf.Variable([[1.2,2.1],[3.0,40.]])\nt1 = tf.convert_to_tensor(var1)                        # varriable convert to tensor \nprint(t1)    \n\n\n#3 \nvar1 = tf.Variable([12,30,40,50,60,70,80,90])\n\namax = tf.argmin(var1)\namin = tf.argmax(var1)\nrs = tf.reshape(var1, ([2,4]))\n\n\n#4\nmy_tensor = tf.random.uniform((5,5), 0,4)\nvar1 = tf.Variable(initial_value = my_tensor)                                                 #create variable\nprint(var1)\n\n\n#5\ntf.__version__\nconst = tf.constant(10)\nmat = tf.fill((5,5),10)\nzeros = tf.zeros((5,5))\nones = tf.ones((5,5))\nrandm = tf.random.normal((4,4), mean=0, stddev=1.0)\nrandu = tf.random.uniform((4,4), minval=0, maxval=1)\nmyops = [const, mat, zeros, ones, randu]\nprint(myops)\n\na = tf.constant([[2,3],[4,5]])\na.get_shape()\n\n\n#6\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\ntfph = tf.compat.v1.placeholder(tf.float32, shape=(None, 5))\na = tf.compat.v1.placeholder(tf.float32, name='a')\nb = tf.compat.v1.placeholder(tf.float32, name='b')\nc = tf.add(a, b, name='c')\nwith tf.Session() as sess:\n    sess.run(c, feed_dict={a: 2.1, b: 1.9})\n    print(tfph)\n`.trim();\n\nconst perceptropn = `\nnp.random.seed(101)\ntf.random.set_seed(101)\nrand_a = np.random.uniform(0, 100, (5,5))\nrand_b = np.random.uniform(0, 100, (5,1))\n\n\n#2\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\na = tf.compat.v1.placeholder(tf.float32)\nb = tf.compat.v1.placeholder(tf.float32)\nadd = a+b\nmul = a*b\n\nwith tf.Session() as sess:\n    result = sess.run(add, feed_dict={a:rand_a, b:rand_b})\n    print(result)\n`.trim();\n\nconst neuralsnet = `\nnf = 1\nndf = 3\n\nbis = tf.Variable(tf.zeros([ndf]))\nwgt = tf.Variable(tf.random.normal([nf, ndf]))\n\n\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nx = tf.compat.v1.placeholder(tf.float32,(None, nf))\n\nxw = tf.matmul(x, wgt)                                                                      #y = mx + b\nz = tf.add(xw, b)\n\naf = tf.sigmoid(z)                                                                          #activation function\n\ninit = tf.compat.v1.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    layer_out = sess.run(af, feed_dict={x:np.random.random([1,nf])})\n\nprint(layer_out)\n`.trim();\n\nconst regressions = `\nimport tensorflow.compat.v1 as tf\n\nnp.random.seed(101)\ntf.random.set_seed(101)\n\n\nx = np.linspace(0, 50, 50)                                                    # Generating random linear data\ny = np.linspace(0, 50, 50)\n  \nx += np.random.uniform(-4, 4, 50)                                             # Adding noise to the random linear data\ny += np.random.uniform(-4, 4, 50)\n  \nn = len(x) # Number of data points\n\nplt.scatter(x, y)\nplt.xlabel('x')\nplt.xlabel('y')\nplt.title(\"Training Data\")\nplt.show()\n\n\ntf.disable_v2_behavior()\n\nX = tf.compat.v1.placeholder(\"float\")\nY = tf.compat.v1.placeholder(\"float\")\n\nW = tf.Variable(np.random.randn(), name = \"W\")\nb = tf.Variable(np.random.randn(), name = \"b\")\n\nlearning_rate = 0.01\ntraining_epochs = 1000\n\n\nwith tf.Session() as sess:                                                # Starting the Tensorflow Session\n    sess.run(init)                                                        # Initializing the Variables\n      \n    for epoch in range(training_epochs):\n        for (_x, _y) in zip(x, y):\n            sess.run(optimizer, feed_dict = {X : _x, Y : _y})             # Feeding each data point into the optimizer\n          \n        \n        if (epoch + 1) % 50 == 0:                                         # Displaying the result after every 50 epochs\n            c = sess.run(cost, feed_dict = {X : x, Y : y})                # Calculating the cost a every epoch\n            print((epoch + 1), c, sess.run(W), sess.run(b))\n    \n    training_cost = sess.run(cost, feed_dict ={X: x, Y: y})               # Storing values to be used outside the Session\n    weight = sess.run(W)\n    bias = sess.run(b)\n`.trim();\n\n\nclass TensorFlows extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>TensorFlow</h3>\n              TensorFlow designed to implement ML and DL concepts in the easiest manner.\n              <br />\n              <br />\n              TensorFlow uses for numerical computation and large-scale ML. TensorFlow bundles\n              together a slew of ML and DL (neural networking) models algorithms and makes them\n              useful by way of a common metaphor.\n              <br />\n              <br />\n\n              <b>important features of TensorFlow:</b>\n              <ul>\n                <li>Defines, optimizes and calculates mathematical expressions easily with the help of\n                  multi-dimensional arrays (tensors).</li>\n                <li>Support of deep neural networks and ML techniques.</li>\n                <li>It includes a high scalable feature of computation with various data sets.</li>\n                <li>Uses GPU computing, automating management. It also includes a unique feature of optimization of same\n                  memory and the data used.</li>\n              </ul>\n              <br />\n\n              <h3>Eager Execution</h3>\n              Eager execution is an imperative, define-by-run interface where operations are executed immediately as they are called from Python.\n              This makes it easier to get started with TensorFlow, and can make research and development more intuitive.\n              <div style={titles}>\n                <PrismCode\n                  code={eager}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Tensors</h3>\n              Tensors are TensorFlow’s multi-dimensional arrays with uniform type. They are very similar to NumPy arrays, and immutable.\n              <br />\n              <br />\n              <b>Creating Tensor Objects:</b>\n              <ul>\n                <li><b>tf.constant(): </b></li>\n                <li><b>tf.ones(): </b>Only consisting of 1s.</li>\n                <li><b>tf.zeros(): </b>Only consisting of 0s.</li>\n                <li><b>tf.range(): </b>To create Tensor objects.</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={tensorObj}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <i><b>N: </b>tf.ones and tf.zeros accepts the shape as the required argument since their element values are pre-determined.</i>\n              <br />\n\n              <h3>Rank System and Dimension</h3>\n              <ul>\n                <li><b>Rank-0 (Scalar) Tensor: </b>A tensor containing a single value and no axes.</li>\n                <li><b>Rank-1 (Vector) Tensor: </b>A tensor containing a list of values in a single axis.</li>\n                <li><b>Rank-2 Tensor: </b>A tensor containing 2-axes.</li>\n                <li><b>Rank-3 Tensor: </b>A tensor containing 3-axes.</li>\n                <li><b>Rank-4 Tensor: </b>4th dimension is space.</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={rankDim}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Operations with Tensors</h3>\n              <ul>\n                <li>Indexing</li>\n                <li>Addition</li>\n                <li>Element-wise Multiplication</li>\n                <li>Matrix Multiplication</li>\n                <li>Finding the Maximum/ Minimum</li>\n                <li>Finding the Index of the Max Element</li>\n                <li>Computing Softmax Value</li>\n              </ul>\n              <i>Commas (,) are used to reach deeper levels.</i>\n              <div style={titles}>\n                <PrismCode\n                  code={indexings}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Broadcasting with Tensor</h3>\n              <ul>\n                <li>Broadcasting concept is borrowed from Numpy broadcasting.</li>\n                <li>Broadcasting is about bringing the tensors of different dimensions/ shape to the compatible shape such that arithmetic operations\n                  can be performed on them.</li>\n                <li>In broadcasting, the smaller array is found, the new axes are added as per the larger array and data is added appropriately to\n                  the transformed array.</li>\n              </ul>\n\n              <div style={titles}>\n                <PrismCode\n                  code={broadcasting}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Special Types of Tensors</h3>\n              We tend to generate Tensors in a rectangular shape and store numerical values as elements. However, TensorFlow also supports irregular, or specialized,\n              Tensor types, which are:\n              <ul>\n                <li><b>Ragged Tensors: </b>Are tensors with different numbers of elements along the size axis.</li>\n                <li><b>String Tensors: </b>Are stores string objects. We can build a String Tensor just as you create\n                  a regular Tensor object. But, we pass string objects as elements instead of numerical objects.</li>\n                <li><b>Sparse Tensors: </b>Are rectangular Tensors for sparse data. When we have holes (Null values) in our data, Sparse Tensors\n                  are to-go objects.</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={specialTen}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n\n              <h3>Variables & Placeholders</h3>\n              Two way to initialize varriabble.\n              <ul>\n                <li><b>constant: </b>initialize constant variable.</li>\n                <li><b>Variable: </b></li>\n              </ul>\n              <br />\n              <b>Methods:</b>\n              <ul>\n                <li><b>argmin(): </b>Show smallest value index number.</li>\n                <li><b>argmax(): </b>Show large value index number.</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={variables}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Import training dataset</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={tensorlow}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Tensorflow Graph</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={graphs}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Perceptron</h3>\n              Perceptron is an algorithm that, given an inputs features, outputs either 1 or 0.\n              <br />\n              <img src={NeuralKeras} alt=\"Theata\" className=\"responsive2\" style={redesign} />\n              <div style={titles}>\n                <PrismCode\n                  code={perceptropn}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Neural Network</h3>\n              <ul>\n                <li>Neural networks, a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data.</li>\n                <li>DL, a powerful set of techniques for learning in neural networks.</li>\n                <li>Neural networks and DL currently provide the best solutions to many problems in image recognition, speech recognition,\n                  and natural language processing.</li>\n              </ul>\n              <br />\n              <br />\n\n              <div style={titles}>\n                <PrismCode\n                  code={neuralsnet}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Regression</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={regressions}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\n\nexport default (withStyles(styles)(TensorFlows));\n"],"sourceRoot":""}
(this["webpackJsonpmern-stack-client"]=this["webpackJsonpmern-stack-client"]||[]).push([[186],{140:function(e,a,n){"use strict";n.d(a,"a",(function(){return y}));var r=n(45),t=n(28),i=n(136),c=n(137),l=n(139),s=n(0),m=n.n(s),o=n(138),g=n.n(o),y=(n(59),function(e){function a(e){var n;return Object(r.a)(this,a),(n=Object(i.a)(this,Object(c.a)(a).call(this,e))).highlight=function(){n.ref&&n.ref.current&&g.a.highlightElement(n.ref.current)},n.ref=m.a.createRef(),n}return Object(l.a)(a,e),Object(t.a)(a,[{key:"componentDidMount",value:function(){this.highlight()}},{key:"componentDidUpdate",value:function(){this.highlight()}},{key:"render",value:function(){var e=this.props,a=e.code,n=(e.plugins,e.language);return m.a.createElement("pre",{className:"code-prism"},m.a.createElement("code",{ref:this.ref,className:"language-".concat(n)},a.trim()))}}]),a}(m.a.Component))},141:function(e,a,n){},146:function(e,a,n){"use strict";n.d(a,"a",(function(){return o}));var r=n(0),t=n.n(r),i=n(26),c=n(297),l=n(295),s=n(114),m=Object(s.a)((function(e){return{root:{display:"flex"},paper:{marginRight:e.spacing(2)},line:{textDecoration:"none"}}}));function o(){var e=m();return t.a.createElement("div",{className:e.root},t.a.createElement(l.a,null,t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/infoMl",className:e.line},"InfoMl")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/gredient_decents",className:e.line},"Gredient Decents")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/training",className:e.line},"Traning")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/regularizations",className:e.line},"Regularizations")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/featuresEng",className:e.line},"FeaturesEng")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/adaboost",className:e.line},"Adaboots")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/greedSearch",className:e.line},"Greed Search")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/perceptron",className:e.line},"Perceptron")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/pcaPy",className:e.line},"PCA")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/leanearRegression",className:e.line},"Leanear Regression")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/logisticReg",className:e.line},"Logistic Regression")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/lda",className:e.line},"Lda")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/knn",className:e.line},"Knn")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/k_meanClustring",className:e.line},"K_Mean")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/naiveBar",className:e.line},"Naive Bayes")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/randomForest",className:e.line},"Random Forest")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/decisiontree",className:e.line},"Decision Tree")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/svmPy",className:e.line},"SVM")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/numpyPy",className:e.line},"Numpy")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/pandas",className:e.line},"Pandas")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/bagging",className:e.line},"Matplotlib")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/logisticRegrations",className:e.line},"Scikit Learn")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/regrations",className:e.line},"SciPy")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/libraries",className:e.line},"OpenCV")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/capture",className:e.line},"Capture")),t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/joinImages",className:e.line},"JoinImages")),t.a.createElement("br",null),"Deep Learning",t.a.createElement(c.a,null,t.a.createElement(i.b,{to:"/superwise",className:e.line},"Superwise"))),t.a.createElement("div",null))}},508:function(e,a,n){"use strict";n.r(a);var r=n(45),t=n(28),i=n(136),c=n(137),l=n(139),s=n(0),m=n.n(s),o=n(138),g=n.n(o),y=n(120),p=n(57),u=n(296),h=n(5),v=(n(141),n(146)),A=n(140),x={backgroundColor:"#F0F8FF",padding:"1px",fontSize:"16px"},E='\nimport cv2\nimport numpy as np\n\nimg = cv2.imread("D:PythonMachin_LearningopenCVResourcesimgs.jpg")\n\nimgHor = np.hstack((img, img))\n\ncv2.imshow("Horizontal", imgHor)\n\ncv2.waitKey(0)\n'.trim(),b="import cv2\nimport numpy as np\n\n\ndef stackImages(scale,imgArray):\n    rows = len(imgArray)\n    cols = len(imgArray[0])\n    rowsAvailable = isinstance(imgArray[0], list)\n    width = imgArray[0][0].shape[1]\n    height = imgArray[0][0].shape[0]\n    if rowsAvailable:\n        for x in range ( 0, rows):\n            for y in range(0, cols):\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n                else:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \n                                        None, scale, scale)\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n        imageBlank = np.zeros((height, width, 3), np.uint8)\n        hor = [imageBlank]*rows\n        hor_con = [imageBlank]*rows\n        for x in range(0, rows):\n            hor[x] = np.hstack(imgArray[x])\n        ver = np.vstack(hor)\n    else:\n        for x in range(0, rows):\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n            else:\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n        hor= np.hstack(imgArray)\n        ver = hor\n    return ver\n\nimg = cv2.imread('D:PythonMachin_LearningopenCVResourcesimgs.jpg')\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n\nimgStack = stackImages(0.5,([img,imgGray,img],[img,img,img]))\n\n\ncv2.imshow(\"ImageStack\",imgStack)\n\ncv2.waitKey(0)\n".trim(),f='\nimport cv2\nimport numpy as np\n\ndef empty(a):\n    pass\n\ndef stackImages(scale,imgArray):\n    rows = len(imgArray)\n    cols = len(imgArray[0])\n    rowsAvailable = isinstance(imgArray[0], list)\n    width = imgArray[0][0].shape[1]\n    height = imgArray[0][0].shape[0]\n    if rowsAvailable:\n        for x in range ( 0, rows):\n            for y in range(0, cols):\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n                else:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \n                                                None, scale, scale)\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n        imageBlank = np.zeros((height, width, 3), np.uint8)\n        hor = [imageBlank]*rows\n        hor_con = [imageBlank]*rows\n        for x in range(0, rows):\n            hor[x] = np.hstack(imgArray[x])\n        ver = np.vstack(hor)\n    else:\n        for x in range(0, rows):\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n            else:\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n        hor= np.hstack(imgArray)\n        ver = hor\n    return ver\n\n\n\npath = \'D:PythonMachin_LearningopenCVResourcesimgs.jpg\'\ncv2.namedWindow("TrackBars")\ncv2.resizeWindow("TrackBars",640,240)\ncv2.createTrackbar("Hue Min","TrackBars",0,179,empty)\ncv2.createTrackbar("Hue Max","TrackBars",19,179,empty)\ncv2.createTrackbar("Sat Min","TrackBars",110,255,empty)\ncv2.createTrackbar("Sat Max","TrackBars",240,255,empty)\ncv2.createTrackbar("Val Min","TrackBars",153,255,empty)\ncv2.createTrackbar("Val Max","TrackBars",255,255,empty)\n\nwhile True:\n    img = cv2.imread(path)\n    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n    h_min = cv2.getTrackbarPos("Hue Min","TrackBars")\n    h_max = cv2.getTrackbarPos("Hue Max", "TrackBars")\n    s_min = cv2.getTrackbarPos("Sat Min", "TrackBars")\n    s_max = cv2.getTrackbarPos("Sat Max", "TrackBars")\n    v_min = cv2.getTrackbarPos("Val Min", "TrackBars")\n    v_max = cv2.getTrackbarPos("Val Max", "TrackBars")\n    print(h_min,h_max,s_min,s_max,v_min,v_max)\n    lower = np.array([h_min,s_min,v_min])\n    upper = np.array([h_max,s_max,v_max])\n    mask = cv2.inRange(imgHSV,lower,upper)\n    imgResult = cv2.bitwise_and(img,img,mask=mask)\n\n\n    # cv2.imshow("Original",img)\n    # cv2.imshow("HSV",imgHSV)\n    # cv2.imshow("Mask", mask)\n    # cv2.imshow("Result", imgResult)\n\n    imgStack = stackImages(0.6,([img,imgHSV],[mask,imgResult]))\n    cv2.imshow("Stacked Images", imgStack)\n\n    cv2.waitKey(1)\n'.trim(),k='\nimport cv2\nimport numpy as np\n\ndef stackImages(scale,imgArray):\n    rows = len(imgArray)\n    cols = len(imgArray[0])\n    rowsAvailable = isinstance(imgArray[0], list)\n    width = imgArray[0][0].shape[1]\n    height = imgArray[0][0].shape[0]\n    if rowsAvailable:\n        for x in range ( 0, rows):\n            for y in range(0, cols):\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n                else:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \n                                     None, scale, scale)\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n        imageBlank = np.zeros((height, width, 3), np.uint8)\n        hor = [imageBlank]*rows\n        hor_con = [imageBlank]*rows\n        for x in range(0, rows):\n            hor[x] = np.hstack(imgArray[x])\n        ver = np.vstack(hor)\n    else:\n        for x in range(0, rows):\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n            else:\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n        hor= np.hstack(imgArray)\n        ver = hor\n    return ver\n\ndef getContours(img):\n    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    for cnt in contours:\n        area = cv2.contourArea(cnt)\n        print(area)\n        if area>500:\n            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n            peri = cv2.arcLength(cnt,True)\n            #print(peri)\n            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n            print(len(approx))\n            objCor = len(approx)\n            x, y, w, h = cv2.boundingRect(approx)\n\n            if objCor ==3: objectType ="Tri"\n            elif objCor == 4:\n                aspRatio = w/float(h)\n                if aspRatio >0.98 and aspRatio <1.03: objectType= "Square"\n                else:objectType="Rectangle"\n            elif objCor>4: objectType= "Circles"\n            else:objectType="None"\n\n\n\n            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\n            cv2.putText(imgContour,objectType,\n                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,\n                        (0,0,0),2)\n\n\n\n\npath = \'D:PythonMachin_LearningopenCVResourcesimgs.jpg\'\nimg = cv2.imread(path)\nimgContour = img.copy()\n\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nimgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\nimgCanny = cv2.Canny(imgBlur,50,50)\ngetContours(imgCanny)\n\nimgBlank = np.zeros_like(img)\nimgStack = stackImages(0.8,([img,imgGray,imgBlur],\n                            [imgCanny,imgContour,imgBlank]))\n\ncv2.imshow("Stack", imgStack)\n\ncv2.waitKey(0)\nimport cv2\n\nfaceCascade= cv2.CascadeClassifier("Resources/haarcascade_frontalface_default.xml")\nimg = cv2.imread(\'D:PythonMachin_LearningopenCVResourcesimgs.jpg\')\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n\nfaces = faceCascade.detectMultiScale(imgGray,1.1,4)\n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n\n\ncv2.imshow("Result", img)\ncv2.waitKey(0)\n'.trim(),d=function(e){function a(){return Object(r.a)(this,a),Object(i.a)(this,Object(c.a)(a).apply(this,arguments))}return Object(l.a)(a,e),Object(t.a)(a,[{key:"componentDidMount",value:function(){setTimeout((function(){return g.a.highlightAll()}),0)}},{key:"render",value:function(){var e=this.props.classes;return m.a.createElement(y.a,{container:!0},m.a.createElement(y.a,{item:!0,xs:2},m.a.createElement(p.a,{className:e.paper},m.a.createElement("h4",null,m.a.createElement(v.a,null)))),m.a.createElement(y.a,{item:!0,xs:10},m.a.createElement(p.a,{className:e.paper},m.a.createElement(u.a,null,m.a.createElement("h3",null,"Joining images:"),m.a.createElement("div",{style:x},m.a.createElement(A.a,{code:E,language:"js",plugins:["line-numbers"]})),m.a.createElement("br",null),m.a.createElement("br",null),m.a.createElement("h3",null,"Joining Multiple Images to Display:"),m.a.createElement("div",{style:x},m.a.createElement(A.a,{code:b,language:"js",plugins:["line-numbers"]})),m.a.createElement("br",null),m.a.createElement("br",null),m.a.createElement("h3",null,"Color Detection:"),m.a.createElement("div",{style:x},m.a.createElement(A.a,{code:f,language:"js",plugins:["line-numbers"]})),m.a.createElement("br",null),m.a.createElement("br",null),m.a.createElement("h3",null,"Contour/Shape Detection"),m.a.createElement("div",{style:x},m.a.createElement(A.a,{code:k,language:"js",plugins:["line-numbers"]}))))))}}]),a}(s.Component);a.default=Object(h.a)((function(e){return{paper:{margin:e.spacing(1),padding:e.spacing(1)},smMargin:{margin:e.spacing(1)},actionDiv:{textAlign:"center"}}}))(d)}}]);
//# sourceMappingURL=186.509e4d09.chunk.js.map
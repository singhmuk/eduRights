(this["webpackJsonpmern-stack-client"]=this["webpackJsonpmern-stack-client"]||[]).push([[46],{140:function(e,a,n){"use strict";n.d(a,"a",(function(){return d}));var t=n(45),l=n(28),r=n(136),s=n(137),i=n(139),o=n(0),c=n.n(o),m=n(138),u=n.n(m),d=(n(59),function(e){function a(e){var n;return Object(t.a)(this,a),(n=Object(r.a)(this,Object(s.a)(a).call(this,e))).highlight=function(){n.ref&&n.ref.current&&u.a.highlightElement(n.ref.current)},n.ref=c.a.createRef(),n}return Object(i.a)(a,e),Object(l.a)(a,[{key:"componentDidMount",value:function(){this.highlight()}},{key:"componentDidUpdate",value:function(){this.highlight()}},{key:"render",value:function(){var e=this.props,a=e.code,n=(e.plugins,e.language);return c.a.createElement("pre",{className:"code-prism"},c.a.createElement("code",{ref:this.ref,className:"language-".concat(n)},a.trim()))}}]),a}(c.a.Component))},141:function(e,a,n){},150:function(e,a,n){"use strict";n.d(a,"a",(function(){return m}));var t=n(0),l=n.n(t),r=n(26),s=n(297),i=n(295),o=n(114),c=Object(o.a)((function(e){return{root:{display:"flex"},paper:{marginRight:e.spacing(2)},line:{textDecoration:"none"}}}));function m(){var e=c();return l.a.createElement("div",{className:e.root},l.a.createElement(i.a,null,l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/introAngular",className:e.line},"AI")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/tensorflow",className:e.line},"Tensorflow")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/tensors",className:e.line},"Tensorboards")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/angCompiler",className:e.line},"Compiler")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/neural",className:e.line},"NeuralKeras")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/activationFunctions",className:e.line},"activationFuncs")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/loss",className:e.line},"Loss")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/gradientNeural",className:e.line},"GradientNeural")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/stochastic",className:e.line},"Stochastic")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/benchmarking",className:e.line},"Benchmarking")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/customer",className:e.line},"Customer")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/regularizationDeep",className:e.line},"Regularization Deep")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/imbalanced",className:e.line},"Imbalanced")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/imbalanced2",className:e.line},"Imbalanced2")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/convolutionals",className:e.line},"Convolutionals")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/data_augmentation",className:e.line},"data Augmentation")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/transfer",className:e.line},"Transfer")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/word_embedding",className:e.line},"Embedding")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/datatypests",className:e.line},"Datatypes")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/typeScript_2",className:e.line},"TS Function")),l.a.createElement(s.a,null,l.a.createElement(r.b,{to:"/typeScript_4",className:e.line},"Type Assertion"))),l.a.createElement("div",null))}},210:function(e,a,n){e.exports=n.p+"static/media/daisy2.4cc88bac.JPG"},465:function(e,a,n){"use strict";n.r(a);var t=n(45),l=n(28),r=n(136),s=n(137),i=n(139),o=n(0),c=n.n(o),m=n(138),u=n.n(m),d=n(120),g=n(57),p=n(296),E=n(5),_=(n(141),n(150)),f=n(140),b=n(210),y=n.n(b),h={backgroundColor:"#F0F8FF",padding:"1px",fontSize:"16px"},v={height:200,width:500},N="\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\ndata_dir\n\nimport pathlib\ndata_dir = pathlib.Path(data_dir)\n\nlist(data_dir.glob('*/*.jpg'))[:5]\n\nimage_count = len(list(data_dir.glob('*/*.jpg')))\n\nroses = list(data_dir.glob('roses/*'))\nroses[:5]\n\nPIL.Image.open(str(roses[1]))\n\ntulips = list(data_dir.glob('tulips/*'))\nPIL.Image.open(str(tulips[0]))\n".trim(),w="\nflowers_images_dict = {\n  'roses': list(data_dir.glob('roses/*')),\n  'daisy': list(data_dir.glob('daisy/*')),\n  'dandelion': list(data_dir.glob('dandelion/*')),\n  'sunflowers': list(data_dir.glob('sunflowers/*')),\n  'tulips': list(data_dir.glob('tulips/*')),\n}\n\n\nflowers_labels_dict = {\n  'roses': 0,\n  'daisy': 1,\n  'dandelion': 2,\n  'sunflowers': 3,\n  'tulips': 4,\n}\n\nflowers_images_dict['roses'][:5]\n\nstr(flowers_images_dict['roses'][0])\nimg = cv2.imread(str(flowers_images_dict['roses'][0]))\n\ncv2.resize(img,(180,180)).shape\nX, y = [], []\n\nfor flower_name, images in flowers_images_dict.items():\n    for image in images:\n        img = cv2.imread(str(image))\n        resized_img = cv2.resize(img,(180,180))\n        X.append(resized_img)\n        y.append(flowers_labels_dict[flower_name])\n        \n        \nX = np.array(X)\ny = np.array(y)\n".trim(),D="\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nX_train_scaled = X_train / 255                                                            #Preprocessing: scale images.\nX_test_scaled = X_test / 255\n".trim(),x="\nnum_classes = 5\n\nmodel = Sequential([\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n              \nmodel.fit(X_train_scaled, y_train, epochs=30) \nmodel.evaluate(X_test_scaled,y_test) \n\npredictions = model.predict(X_test_scaled)\nscore = tf.nn.softmax(predictions[0])\nnp.argmax(score)\n\ny_test[0]\n".trim(),j="\ndata_augmentation = keras.Sequential(\n  [\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)\n\n\nplt.axis('off')                                                                                   #Original Image.\nplt.imshow(X[0])                     \n".trim(),C="\nplt.axis('off')\nplt.imshow(data_augmentation(X)[0].numpy().astype(\"uint8\"))\n\nnum_classes = 5\n\nmodel = Sequential([\n  data_augmentation,\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n              \nmodel.fit(X_train_scaled, y_train, epochs=30)  \nmodel.evaluate(X_test_scaled,y_test)\n".trim(),k=function(e){function a(){return Object(t.a)(this,a),Object(r.a)(this,Object(s.a)(a).apply(this,arguments))}return Object(i.a)(a,e),Object(l.a)(a,[{key:"componentDidMount",value:function(){setTimeout((function(){return u.a.highlightAll()}),0)}},{key:"render",value:function(){var e=this.props.classes;return c.a.createElement(d.a,{container:!0},c.a.createElement(d.a,{item:!0,xs:2},c.a.createElement(g.a,{className:e.paper},c.a.createElement("h4",null,c.a.createElement(_.a,null)))),c.a.createElement(d.a,{item:!0,xs:10},c.a.createElement(g.a,{className:e.paper},c.a.createElement(p.a,null,c.a.createElement("h3",null,"Data Augmentation To Address Overfitting In Flower Classification CNN"),"Data augmentation is a process of generating new training samples from current training dataset using transformations such as zoom, rotations, change in contrast etc.",c.a.createElement("br",null),c.a.createElement("i",null,"We build a CNN to classify flower images. Also see how our model overfits and overfitting can be addressed using data augmentation."),c.a.createElement("br",null),c.a.createElement("br",null),c.a.createElement("b",null,"4 new training samples are generated from original sample using different transformations."),c.a.createElement("br",null),c.a.createElement("br",null),c.a.createElement("img",{src:y.a,alt:"Theata",className:"responsive2",style:v}),c.a.createElement("br",null),c.a.createElement("br",null),c.a.createElement("b",null,"Load flowers dataset."),c.a.createElement("br",null),c.a.createElement("div",{style:h},c.a.createElement(f.a,{code:N,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Read flowers images from disk into numpy array using opencv."),c.a.createElement("div",{style:h},c.a.createElement(f.a,{code:w,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Train test split"),c.a.createElement("div",{style:h},c.a.createElement(f.a,{code:D,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Build convolutional neural network and train it."),c.a.createElement("div",{style:h},c.a.createElement(f.a,{code:x,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Improve Test Accuracy Using Data Augmentation"),c.a.createElement("div",{style:h},c.a.createElement(f.a,{code:j,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("h3",null,"Newly generated training sample using data augmentation"),c.a.createElement("div",{style:h},c.a.createElement(f.a,{code:C,language:"js",plugins:["line-numbers"]})),c.a.createElement("br",null),c.a.createElement("i",null,"By using data augmentation and drop out layer the accuracy of test set predictions is increased to 73.74%.")))))}}]),a}(o.Component);a.default=Object(E.a)((function(e){return{paper:{margin:e.spacing(1),padding:e.spacing(1)},smMargin:{margin:e.spacing(1)},actionDiv:{textAlign:"center"}}}))(k)}}]);
//# sourceMappingURL=46.cee9bd3c.chunk.js.map
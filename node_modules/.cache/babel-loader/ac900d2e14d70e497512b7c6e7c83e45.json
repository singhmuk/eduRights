{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var images=\"\\nimport cv2\\nimport numpy as np\\n\\nimg = cv2.imread(\\\"D:PythonMachin_LearningopenCVResourcesimgs.jpg\\\")\\n\\nimgHor = np.hstack((img, img))\\n\\ncv2.imshow(\\\"Horizontal\\\", imgHor)\\n\\ncv2.waitKey(0)\\n\".trim();var images_2=\"import cv2\\nimport numpy as np\\n\\n\\ndef stackImages(scale,imgArray):\\n    rows = len(imgArray)\\n    cols = len(imgArray[0])\\n    rowsAvailable = isinstance(imgArray[0], list)\\n    width = imgArray[0][0].shape[1]\\n    height = imgArray[0][0].shape[0]\\n    if rowsAvailable:\\n        for x in range ( 0, rows):\\n            for y in range(0, cols):\\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\\n                else:\\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \\n                                        None, scale, scale)\\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\\n        imageBlank = np.zeros((height, width, 3), np.uint8)\\n        hor = [imageBlank]*rows\\n        hor_con = [imageBlank]*rows\\n        for x in range(0, rows):\\n            hor[x] = np.hstack(imgArray[x])\\n        ver = np.vstack(hor)\\n    else:\\n        for x in range(0, rows):\\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\\n            else:\\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\\n        hor= np.hstack(imgArray)\\n        ver = hor\\n    return ver\\n\\nimg = cv2.imread('D:PythonMachin_LearningopenCVResourcesimgs.jpg')\\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\\n\\nimgStack = stackImages(0.5,([img,imgGray,img],[img,img,img]))\\n\\n\\ncv2.imshow(\\\"ImageStack\\\",imgStack)\\n\\ncv2.waitKey(0)\\n\".trim();var detection=\"\\nimport cv2\\nimport numpy as np\\n\\ndef empty(a):\\n    pass\\n\\ndef stackImages(scale,imgArray):\\n    rows = len(imgArray)\\n    cols = len(imgArray[0])\\n    rowsAvailable = isinstance(imgArray[0], list)\\n    width = imgArray[0][0].shape[1]\\n    height = imgArray[0][0].shape[0]\\n    if rowsAvailable:\\n        for x in range ( 0, rows):\\n            for y in range(0, cols):\\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\\n                else:\\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \\n                                                None, scale, scale)\\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\\n        imageBlank = np.zeros((height, width, 3), np.uint8)\\n        hor = [imageBlank]*rows\\n        hor_con = [imageBlank]*rows\\n        for x in range(0, rows):\\n            hor[x] = np.hstack(imgArray[x])\\n        ver = np.vstack(hor)\\n    else:\\n        for x in range(0, rows):\\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\\n            else:\\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\\n        hor= np.hstack(imgArray)\\n        ver = hor\\n    return ver\\n\\n\\n\\npath = 'D:PythonMachin_LearningopenCVResourcesimgs.jpg'\\ncv2.namedWindow(\\\"TrackBars\\\")\\ncv2.resizeWindow(\\\"TrackBars\\\",640,240)\\ncv2.createTrackbar(\\\"Hue Min\\\",\\\"TrackBars\\\",0,179,empty)\\ncv2.createTrackbar(\\\"Hue Max\\\",\\\"TrackBars\\\",19,179,empty)\\ncv2.createTrackbar(\\\"Sat Min\\\",\\\"TrackBars\\\",110,255,empty)\\ncv2.createTrackbar(\\\"Sat Max\\\",\\\"TrackBars\\\",240,255,empty)\\ncv2.createTrackbar(\\\"Val Min\\\",\\\"TrackBars\\\",153,255,empty)\\ncv2.createTrackbar(\\\"Val Max\\\",\\\"TrackBars\\\",255,255,empty)\\n\\nwhile True:\\n    img = cv2.imread(path)\\n    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\\n    h_min = cv2.getTrackbarPos(\\\"Hue Min\\\",\\\"TrackBars\\\")\\n    h_max = cv2.getTrackbarPos(\\\"Hue Max\\\", \\\"TrackBars\\\")\\n    s_min = cv2.getTrackbarPos(\\\"Sat Min\\\", \\\"TrackBars\\\")\\n    s_max = cv2.getTrackbarPos(\\\"Sat Max\\\", \\\"TrackBars\\\")\\n    v_min = cv2.getTrackbarPos(\\\"Val Min\\\", \\\"TrackBars\\\")\\n    v_max = cv2.getTrackbarPos(\\\"Val Max\\\", \\\"TrackBars\\\")\\n    print(h_min,h_max,s_min,s_max,v_min,v_max)\\n    lower = np.array([h_min,s_min,v_min])\\n    upper = np.array([h_max,s_max,v_max])\\n    mask = cv2.inRange(imgHSV,lower,upper)\\n    imgResult = cv2.bitwise_and(img,img,mask=mask)\\n\\n\\n    # cv2.imshow(\\\"Original\\\",img)\\n    # cv2.imshow(\\\"HSV\\\",imgHSV)\\n    # cv2.imshow(\\\"Mask\\\", mask)\\n    # cv2.imshow(\\\"Result\\\", imgResult)\\n\\n    imgStack = stackImages(0.6,([img,imgHSV],[mask,imgResult]))\\n    cv2.imshow(\\\"Stacked Images\\\", imgStack)\\n\\n    cv2.waitKey(1)\\n\".trim();var shape=\"\\nimport cv2\\nimport numpy as np\\n\\ndef stackImages(scale,imgArray):\\n    rows = len(imgArray)\\n    cols = len(imgArray[0])\\n    rowsAvailable = isinstance(imgArray[0], list)\\n    width = imgArray[0][0].shape[1]\\n    height = imgArray[0][0].shape[0]\\n    if rowsAvailable:\\n        for x in range ( 0, rows):\\n            for y in range(0, cols):\\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\\n                else:\\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \\n                                     None, scale, scale)\\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\\n        imageBlank = np.zeros((height, width, 3), np.uint8)\\n        hor = [imageBlank]*rows\\n        hor_con = [imageBlank]*rows\\n        for x in range(0, rows):\\n            hor[x] = np.hstack(imgArray[x])\\n        ver = np.vstack(hor)\\n    else:\\n        for x in range(0, rows):\\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\\n            else:\\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\\n        hor= np.hstack(imgArray)\\n        ver = hor\\n    return ver\\n\\ndef getContours(img):\\n    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\\n    for cnt in contours:\\n        area = cv2.contourArea(cnt)\\n        print(area)\\n        if area>500:\\n            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\\n            peri = cv2.arcLength(cnt,True)\\n            #print(peri)\\n            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\\n            print(len(approx))\\n            objCor = len(approx)\\n            x, y, w, h = cv2.boundingRect(approx)\\n\\n            if objCor ==3: objectType =\\\"Tri\\\"\\n            elif objCor == 4:\\n                aspRatio = w/float(h)\\n                if aspRatio >0.98 and aspRatio <1.03: objectType= \\\"Square\\\"\\n                else:objectType=\\\"Rectangle\\\"\\n            elif objCor>4: objectType= \\\"Circles\\\"\\n            else:objectType=\\\"None\\\"\\n\\n\\n\\n            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\\n            cv2.putText(imgContour,objectType,\\n                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,\\n                        (0,0,0),2)\\n\\n\\n\\n\\npath = 'D:PythonMachin_LearningopenCVResourcesimgs.jpg'\\nimg = cv2.imread(path)\\nimgContour = img.copy()\\n\\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\\nimgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\\nimgCanny = cv2.Canny(imgBlur,50,50)\\ngetContours(imgCanny)\\n\\nimgBlank = np.zeros_like(img)\\nimgStack = stackImages(0.8,([img,imgGray,imgBlur],\\n                            [imgCanny,imgContour,imgBlank]))\\n\\ncv2.imshow(\\\"Stack\\\", imgStack)\\n\\ncv2.waitKey(0)\\nimport cv2\\n\\nfaceCascade= cv2.CascadeClassifier(\\\"Resources/haarcascade_frontalface_default.xml\\\")\\nimg = cv2.imread('D:PythonMachin_LearningopenCVResourcesimgs.jpg')\\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\\n\\nfaces = faceCascade.detectMultiScale(imgGray,1.1,4)\\n\\nfor (x,y,w,h) in faces:\\n    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\\n\\n\\ncv2.imshow(\\\"Result\\\", img)\\ncv2.waitKey(0)\\n\".trim();var JoinImages=/*#__PURE__*/function(_Component){_inherits(JoinImages,_Component);function JoinImages(){_classCallCheck(this,JoinImages);return _possibleConstructorReturn(this,_getPrototypeOf(JoinImages).apply(this,arguments));}_createClass(JoinImages,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"Joining images:\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:images,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Joining Multiple Images to Display:\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:images_2,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Color Detection:\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:detection,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Contour/Shape Detection\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:shape,language:\"js\",plugins:[\"line-numbers\"]}))))));}}]);return JoinImages;}(Component);export default withStyles(styles)(JoinImages);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/ml/deepMl/joinImages.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","titles","backgroundColor","padding","fontSize","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","images","trim","images_2","detection","shape","JoinImages","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAGA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACrBC,KAAK,CAAE,CACHC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADL,CAEHN,OAAO,CAAEG,KAAK,CAACG,OAAN,CAAc,CAAd,CAFN,CADc,CAKrBC,QAAQ,CAAE,CACNF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADF,CALW,CAQrBE,SAAS,CAAE,CACPC,SAAS,CAAE,QADJ,CARU,CAAL,EAApB,CAcA,GAAMC,CAAAA,MAAM,CAAG,uMAWbC,IAXa,EAAf,CAaA,GAAMC,CAAAA,QAAQ,CAAG,kyDA6CfD,IA7Ce,EAAjB,CA+CA,GAAME,CAAAA,SAAS,CAAG,4gGA4EhBF,IA5EgB,EAAlB,CA8EA,GAAMG,CAAAA,KAAK,CAAG,m+GAkGZH,IAlGY,EAAd,C,GAqGMI,CAAAA,U,0SACkB,CAChBC,UAAU,CAAC,iBAAMzB,CAAAA,KAAK,CAAC0B,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACH,C,uCACQ,IACGC,CAAAA,OADH,CACe,KAAKC,KADpB,CACGD,OADH,CAEL,MACI,qBAAC,IAAD,EAAM,SAAS,KAAf,EACI,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACI,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAACd,KAA1B,EACI,8BAAI,oBAAC,OAAD,MAAJ,CADJ,CADJ,CADJ,CAMI,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACI,oBAAC,KAAD,EAAO,SAAS,CAAEc,OAAO,CAACd,KAA1B,EACI,oBAAC,IAAD,MACI,gDADJ,CAEI,2BAAK,KAAK,CAAEN,MAAZ,EACI,oBAAC,SAAD,EACI,IAAI,CAAEY,MADV,CAEI,QAAQ,CAAC,IAFb,CAGI,OAAO,CAAE,CAAC,cAAD,CAHb,EADJ,CAFJ,CASI,8BATJ,CAUI,8BAVJ,CAWI,oEAXJ,CAYI,2BAAK,KAAK,CAAEZ,MAAZ,EACI,oBAAC,SAAD,EACI,IAAI,CAAEc,QADV,CAEI,QAAQ,CAAC,IAFb,CAGI,OAAO,CAAE,CAAC,cAAD,CAHb,EADJ,CAZJ,CAmBI,8BAnBJ,CAoBI,8BApBJ,CAqBI,iDArBJ,CAsBI,2BAAK,KAAK,CAAEd,MAAZ,EACI,oBAAC,SAAD,EACI,IAAI,CAAEe,SADV,CAEI,QAAQ,CAAC,IAFb,CAGI,OAAO,CAAE,CAAC,cAAD,CAHb,EADJ,CAtBJ,CA6BI,8BA7BJ,CA8BI,8BA9BJ,CA+BI,wDA/BJ,CAgCI,2BAAK,KAAK,CAAEf,MAAZ,EACI,oBAAC,SAAD,EACI,IAAI,CAAEgB,KADV,CAEI,QAAQ,CAAC,IAFb,CAGI,OAAO,CAAE,CAAC,cAAD,CAHb,EADJ,CAhCJ,CADJ,CADJ,CANJ,CADJ,CAqDH,C,wBA3DoBxB,S,EA8DzB,cAAgBI,CAAAA,UAAU,CAACQ,MAAD,CAAV,CAAmBa,UAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst styles = theme => ({\n    paper: {\n        margin: theme.spacing(1),\n        padding: theme.spacing(1)\n    },\n    smMargin: {\n        margin: theme.spacing(1)\n    },\n    actionDiv: {\n        textAlign: \"center\"\n    }\n})\n\n\nconst images = `\nimport cv2\nimport numpy as np\n\nimg = cv2.imread(\"D:\\Python\\Machin_Learning\\openCV\\Resources\\imgs.jpg\")\n\nimgHor = np.hstack((img, img))\n\ncv2.imshow(\"Horizontal\", imgHor)\n\ncv2.waitKey(0)\n`.trim()\n\nconst images_2 = `import cv2\nimport numpy as np\n\n\ndef stackImages(scale,imgArray):\n    rows = len(imgArray)\n    cols = len(imgArray[0])\n    rowsAvailable = isinstance(imgArray[0], list)\n    width = imgArray[0][0].shape[1]\n    height = imgArray[0][0].shape[0]\n    if rowsAvailable:\n        for x in range ( 0, rows):\n            for y in range(0, cols):\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n                else:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \n                                        None, scale, scale)\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n        imageBlank = np.zeros((height, width, 3), np.uint8)\n        hor = [imageBlank]*rows\n        hor_con = [imageBlank]*rows\n        for x in range(0, rows):\n            hor[x] = np.hstack(imgArray[x])\n        ver = np.vstack(hor)\n    else:\n        for x in range(0, rows):\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n            else:\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n        hor= np.hstack(imgArray)\n        ver = hor\n    return ver\n\nimg = cv2.imread('D:\\Python\\Machin_Learning\\openCV\\Resources\\imgs.jpg')\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n\nimgStack = stackImages(0.5,([img,imgGray,img],[img,img,img]))\n\n\ncv2.imshow(\"ImageStack\",imgStack)\n\ncv2.waitKey(0)\n`.trim()\n\nconst detection = `\nimport cv2\nimport numpy as np\n\ndef empty(a):\n    pass\n\ndef stackImages(scale,imgArray):\n    rows = len(imgArray)\n    cols = len(imgArray[0])\n    rowsAvailable = isinstance(imgArray[0], list)\n    width = imgArray[0][0].shape[1]\n    height = imgArray[0][0].shape[0]\n    if rowsAvailable:\n        for x in range ( 0, rows):\n            for y in range(0, cols):\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n                else:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \n                                                None, scale, scale)\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n        imageBlank = np.zeros((height, width, 3), np.uint8)\n        hor = [imageBlank]*rows\n        hor_con = [imageBlank]*rows\n        for x in range(0, rows):\n            hor[x] = np.hstack(imgArray[x])\n        ver = np.vstack(hor)\n    else:\n        for x in range(0, rows):\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n            else:\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n        hor= np.hstack(imgArray)\n        ver = hor\n    return ver\n\n\n\npath = 'D:\\Python\\Machin_Learning\\openCV\\Resources\\imgs.jpg'\ncv2.namedWindow(\"TrackBars\")\ncv2.resizeWindow(\"TrackBars\",640,240)\ncv2.createTrackbar(\"Hue Min\",\"TrackBars\",0,179,empty)\ncv2.createTrackbar(\"Hue Max\",\"TrackBars\",19,179,empty)\ncv2.createTrackbar(\"Sat Min\",\"TrackBars\",110,255,empty)\ncv2.createTrackbar(\"Sat Max\",\"TrackBars\",240,255,empty)\ncv2.createTrackbar(\"Val Min\",\"TrackBars\",153,255,empty)\ncv2.createTrackbar(\"Val Max\",\"TrackBars\",255,255,empty)\n\nwhile True:\n    img = cv2.imread(path)\n    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n    h_min = cv2.getTrackbarPos(\"Hue Min\",\"TrackBars\")\n    h_max = cv2.getTrackbarPos(\"Hue Max\", \"TrackBars\")\n    s_min = cv2.getTrackbarPos(\"Sat Min\", \"TrackBars\")\n    s_max = cv2.getTrackbarPos(\"Sat Max\", \"TrackBars\")\n    v_min = cv2.getTrackbarPos(\"Val Min\", \"TrackBars\")\n    v_max = cv2.getTrackbarPos(\"Val Max\", \"TrackBars\")\n    print(h_min,h_max,s_min,s_max,v_min,v_max)\n    lower = np.array([h_min,s_min,v_min])\n    upper = np.array([h_max,s_max,v_max])\n    mask = cv2.inRange(imgHSV,lower,upper)\n    imgResult = cv2.bitwise_and(img,img,mask=mask)\n\n\n    # cv2.imshow(\"Original\",img)\n    # cv2.imshow(\"HSV\",imgHSV)\n    # cv2.imshow(\"Mask\", mask)\n    # cv2.imshow(\"Result\", imgResult)\n\n    imgStack = stackImages(0.6,([img,imgHSV],[mask,imgResult]))\n    cv2.imshow(\"Stacked Images\", imgStack)\n\n    cv2.waitKey(1)\n`.trim()\n\nconst shape = `\nimport cv2\nimport numpy as np\n\ndef stackImages(scale,imgArray):\n    rows = len(imgArray)\n    cols = len(imgArray[0])\n    rowsAvailable = isinstance(imgArray[0], list)\n    width = imgArray[0][0].shape[1]\n    height = imgArray[0][0].shape[0]\n    if rowsAvailable:\n        for x in range ( 0, rows):\n            for y in range(0, cols):\n                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n                else:\n                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), \n                                     None, scale, scale)\n                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n        imageBlank = np.zeros((height, width, 3), np.uint8)\n        hor = [imageBlank]*rows\n        hor_con = [imageBlank]*rows\n        for x in range(0, rows):\n            hor[x] = np.hstack(imgArray[x])\n        ver = np.vstack(hor)\n    else:\n        for x in range(0, rows):\n            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n            else:\n                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n        hor= np.hstack(imgArray)\n        ver = hor\n    return ver\n\ndef getContours(img):\n    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    for cnt in contours:\n        area = cv2.contourArea(cnt)\n        print(area)\n        if area>500:\n            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n            peri = cv2.arcLength(cnt,True)\n            #print(peri)\n            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n            print(len(approx))\n            objCor = len(approx)\n            x, y, w, h = cv2.boundingRect(approx)\n\n            if objCor ==3: objectType =\"Tri\"\n            elif objCor == 4:\n                aspRatio = w/float(h)\n                if aspRatio >0.98 and aspRatio <1.03: objectType= \"Square\"\n                else:objectType=\"Rectangle\"\n            elif objCor>4: objectType= \"Circles\"\n            else:objectType=\"None\"\n\n\n\n            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\n            cv2.putText(imgContour,objectType,\n                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,\n                        (0,0,0),2)\n\n\n\n\npath = 'D:\\Python\\Machin_Learning\\openCV\\Resources\\imgs.jpg'\nimg = cv2.imread(path)\nimgContour = img.copy()\n\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nimgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\nimgCanny = cv2.Canny(imgBlur,50,50)\ngetContours(imgCanny)\n\nimgBlank = np.zeros_like(img)\nimgStack = stackImages(0.8,([img,imgGray,imgBlur],\n                            [imgCanny,imgContour,imgBlank]))\n\ncv2.imshow(\"Stack\", imgStack)\n\ncv2.waitKey(0)\nimport cv2\n\nfaceCascade= cv2.CascadeClassifier(\"Resources/haarcascade_frontalface_default.xml\")\nimg = cv2.imread('D:\\Python\\Machin_Learning\\openCV\\Resources\\imgs.jpg')\nimgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n\nfaces = faceCascade.detectMultiScale(imgGray,1.1,4)\n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n\n\ncv2.imshow(\"Result\", img)\ncv2.waitKey(0)\n`.trim()\n\n\nclass JoinImages extends Component {\n    componentDidMount() {\n        setTimeout(() => Prism.highlightAll(), 0)\n    }\n    render() {\n        const { classes } = this.props;\n        return (\n            <Grid container>\n                <Grid item xs={2}>\n                    <Paper className={classes.paper}>\n                        <h4><Sidebar /></h4>\n                    </Paper>\n                </Grid>\n                <Grid item xs={10}>\n                    <Paper className={classes.paper}>\n                        <List>\n                            <h3>Joining images:</h3>\n                            <div style={titles}>\n                                <PrismCode\n                                    code={images}\n                                    language=\"js\"\n                                    plugins={[\"line-numbers\"]}\n                                />\n                            </div>\n                            <br />\n                            <br />\n                            <h3>Joining Multiple Images to Display:</h3>\n                            <div style={titles}>\n                                <PrismCode\n                                    code={images_2}\n                                    language=\"js\"\n                                    plugins={[\"line-numbers\"]}\n                                />\n                            </div>\n                            <br />\n                            <br />\n                            <h3>Color Detection:</h3>\n                            <div style={titles}>\n                                <PrismCode\n                                    code={detection}\n                                    language=\"js\"\n                                    plugins={[\"line-numbers\"]}\n                                />\n                            </div>\n                            <br />\n                            <br />\n                            <h3>Contour/Shape Detection</h3>\n                            <div style={titles}>\n                                <PrismCode\n                                    code={shape}\n                                    language=\"js\"\n                                    plugins={[\"line-numbers\"]}\n                                />\n                            </div>\n                        </List>\n                    </Paper>\n                </Grid>\n            </Grid>\n        )\n    }\n}\n\nexport default (withStyles(styles)(JoinImages));\n"]},"metadata":{},"sourceType":"module"}
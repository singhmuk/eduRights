{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';import Gradients from'../../../assets/AI/nn.png';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var redesign={height:200,width:500};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var childsFile=\"\\nimport numpy as np\\nimport pandas as pd\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nfrom sklearn.model_selection import train_test_split\\nfrom matplotlib import pyplot as plt\\n%matplotlib inline\\n\\ndf = pd.read_csv(\\\"insurance_data.csv\\\")\\n\\nX_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2, \\n    random_state=25)\\n\\n\\n#Preprocessing: Scale the data so both age and affordibility are in same scaling range.\\nX_train_scaled = X_train.copy()\\nX_train_scaled['age'] = X_train_scaled['age'] / 100\\n\\nX_test_scaled = X_test.copy()\\nX_test_scaled['age'] = X_test_scaled['age'] / 100\\n\".trim();var keras=\"\\nmodel = keras.Sequential([\\n  keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\\n])\\n\\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\\nmodel.fit(X_train_scaled, y_train, epochs=5000)\\n\\nmodel.evaluate(X_test_scaled,y_test)                                            #Evaluate the model on test set.\\nmodel.predict(X_test_scaled)\\n\\ny_test\\n\".trim();var weights=\"\\nimport math\\n\\ncoef, intercept = model.get_weights()\\n\\ndef sigmoid(x):\\n    return 1 / (1 + math.exp(-x))\\nsigmoid(18)\\n\\nX_test\\n\".trim();var prediction=\"\\ndef prediction_function(age, affordibility):\\n    weighted_sum = coef[0]*age + coef[1]*affordibility + intercept\\n    return sigmoid(weighted_sum)\\n\\nprediction_function(.47, 1)\\nprediction_function(.18, 1)\\n\".trim();var descent=\"\\ndef sigmoid_numpy(X):\\n   return 1/(1+np.exp(-X))\\n\\nsigmoid_numpy(np.array([12,0,1]))\\n\\ndef log_loss(y_true, y_predicted):\\n    epsilon = 1e-15\\n    y_predicted_new = [max(i,epsilon) for i in y_predicted]\\n    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\\n    y_predicted_new = np.array(y_predicted_new)\\n    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))\\n\".trim();var implementse=\"\\ndef gradient_descent(age, affordability, y_true, epochs, loss_thresold):\\n    w1 = w2 = 1\\n    bias = 0\\n    rate = 0.5\\n    n = len(age)\\n    for i in range(epochs):\\n        weighted_sum = w1 * age + w2 * affordability + bias\\n        y_predicted = sigmoid_numpy(weighted_sum)\\n        loss = log_loss(y_true, y_predicted)\\n\\n        w1d = (1/n)*np.dot(np.transpose(age),(y_predicted-y_true)) \\n        w2d = (1/n)*np.dot(np.transpose(affordability),(y_predicted-y_true)) \\n\\n        bias_d = np.mean(y_predicted-y_true)\\n        w1 = w1 - rate * w1d\\n        w2 = w2 - rate * w2d\\n        bias = bias - rate * bias_d\\n\\n        print (f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\\n\\n        if loss<=loss_thresold:\\n            break\\n\\n    return w1, w2, bias\\n    \\ngradient_descent(X_train_scaled['age'],X_train_scaled['affordibility'],y_train,1000, 0.4631)\\n\\ncoef, intercept\\n\".trim();var GradientNeural=/*#__PURE__*/function(_Component){_inherits(GradientNeural,_Component);function GradientNeural(){_classCallCheck(this,GradientNeural);return _possibleConstructorReturn(this,_getPrototypeOf(GradientNeural).apply(this,arguments));}_createClass(GradientNeural,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"Implement Gradient Descent For Neural Network (or Logistic Regression)\"),\"An optimization algorithm used to train machine learning models by minimizing errors between predicted and actual results.\",React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Predicting if a person would buy life insurnace based on his age using logistic regression\"),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:childsFile,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Model Building: First build a model in keras/tensorflow and see what weights and bias values it comes up with. We will than try to reproduce same weights and bias in our plain python implementation of gradient descent. Below is the architecture of our simple neural network\"),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"img\",{src:Gradients,alt:\"Theata\",className:\"responsive2\",style:redesign}),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:keras,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Now get the value of weights and bias from the model\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:weights,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Instead of model.predict, write our own prediction function that uses w1,w2 and bias.\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:prediction,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Now we start implementing gradient descent in plain python. Again the goal is to come up with same w1, w2 and bias that keras model calculated. We want to show how keras/tensorflow would have computed these values internally using gradient descent\"),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"i\",null,\"First write couple of helper routines such as sigmoid and log_loss.\"),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:descent,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"All right now comes the time to implement our final gradient descent function\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:implementse,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"i\",null,\"This shows that in the end we were able to come up with same value of w1,w2 and bias using a plain python implementation of gradient descent function.\")))));}}]);return GradientNeural;}(Component);export default withStyles(styles)(GradientNeural);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/angularjs/deepAngularjs/gradientNeural.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","Gradients","titles","backgroundColor","padding","fontSize","redesign","height","width","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","childsFile","trim","keras","weights","prediction","descent","implementse","GradientNeural","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAEA,MAAOC,CAAAA,SAAP,KAAsB,2BAAtB,CAEA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,QAAQ,CAAG,CACfC,MAAM,CAAE,GADO,CAEfC,KAAK,CAAE,GAFQ,CAAjB,CAKA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACvBC,KAAK,CAAE,CACLC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH,CAELT,OAAO,CAAEM,KAAK,CAACG,OAAN,CAAc,CAAd,CAFJ,CADgB,CAKvBC,QAAQ,CAAE,CACRF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADA,CALa,CAQvBE,SAAS,CAAE,CACTC,SAAS,CAAE,QADF,CARY,CAAL,EAApB,CAcA,GAAMC,CAAAA,UAAU,CAAG,qpBAqBjBC,IArBiB,EAAnB,CAuBA,GAAMC,CAAAA,KAAK,CAAG,6bAYZD,IAZY,EAAd,CAcA,GAAME,CAAAA,OAAO,CAAG,wIAUdF,IAVc,EAAhB,CAYA,GAAMG,CAAAA,UAAU,CAAG,qNAOjBH,IAPiB,EAAnB,CASA,GAAMI,CAAAA,OAAO,CAAG,maAYdJ,IAZc,EAAhB,CAcA,GAAMK,CAAAA,WAAW,CAAG,s4BA6BlBL,IA7BkB,EAApB,C,GAgCMM,CAAAA,c,8TACgB,CAClBC,UAAU,CAAC,iBAAM/B,CAAAA,KAAK,CAACgC,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACD,C,uCACQ,IACCC,CAAAA,OADD,CACa,KAAKC,KADlB,CACCD,OADD,CAEP,MACE,qBAAC,IAAD,EAAM,SAAS,KAAf,EACE,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAAChB,KAA1B,EACE,8BAAI,oBAAC,OAAD,MAAJ,CADF,CADF,CADF,CAME,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEgB,OAAO,CAAChB,KAA1B,EACE,oBAAC,IAAD,MACE,uGADF,8HAGE,8BAHF,CAIE,8BAJF,CAME,0HANF,CAOE,8BAPF,CAQE,8BARF,CASE,2BAAK,KAAK,CAAET,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEe,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CATF,CAgBE,8BAhBF,CAiBE,8BAjBF,CAmBE,iTAnBF,CAsBE,8BAtBF,CAuBE,8BAvBF,CAwBE,2BAAK,GAAG,CAAEhB,SAAV,CAAqB,GAAG,CAAC,QAAzB,CAAkC,SAAS,CAAC,aAA5C,CAA0D,KAAK,CAAEK,QAAjE,EAxBF,CAyBE,8BAzBF,CA0BE,8BA1BF,CA2BE,2BAAK,KAAK,CAAEJ,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEiB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA3BF,CAkCE,8BAlCF,CAoCE,qFApCF,CAqCE,2BAAK,KAAK,CAAEjB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEkB,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CArCF,CA4CE,8BA5CF,CA8CE,sHA9CF,CA+CE,2BAAK,KAAK,CAAElB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEmB,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA/CF,CAsDE,8BAtDF,CAuDE,8BAvDF,CAyDE,uRAzDF,CA0DE,8BA1DF,CA2DE,8BA3DF,CA4DE,mGA5DF,CA6DE,8BA7DF,CA8DE,2BAAK,KAAK,CAAEnB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEoB,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA9DF,CAqEE,8BArEF,CAsEE,8BAtEF,CAwEE,6GAxEF,CAyEE,2BAAK,KAAK,CAAEpB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEqB,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAzEF,CAgFE,8BAhFF,CAiFE,sLAjFF,CADF,CADF,CANF,CADF,CAgGD,C,4BAtG0B9B,S,EA0G7B,cAAgBI,CAAAA,UAAU,CAACY,MAAD,CAAV,CAAmBe,cAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\nimport Gradients from '../../../assets/AI/nn.png'\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst redesign = {\n  height: 200,\n  width: 500\n}\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst childsFile = `\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\ndf = pd.read_csv(\"insurance_data.csv\")\n\nX_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2, \n    random_state=25)\n\n\n#Preprocessing: Scale the data so both age and affordibility are in same scaling range.\nX_train_scaled = X_train.copy()\nX_train_scaled['age'] = X_train_scaled['age'] / 100\n\nX_test_scaled = X_test.copy()\nX_test_scaled['age'] = X_test_scaled['age'] / 100\n`.trim();\n\nconst keras = `\nmodel = keras.Sequential([\n  keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train_scaled, y_train, epochs=5000)\n\nmodel.evaluate(X_test_scaled,y_test)                                            #Evaluate the model on test set.\nmodel.predict(X_test_scaled)\n\ny_test\n`.trim();\n\nconst weights = `\nimport math\n\ncoef, intercept = model.get_weights()\n\ndef sigmoid(x):\n    return 1 / (1 + math.exp(-x))\nsigmoid(18)\n\nX_test\n`.trim();\n\nconst prediction = `\ndef prediction_function(age, affordibility):\n    weighted_sum = coef[0]*age + coef[1]*affordibility + intercept\n    return sigmoid(weighted_sum)\n\nprediction_function(.47, 1)\nprediction_function(.18, 1)\n`.trim();\n\nconst descent = `\ndef sigmoid_numpy(X):\n   return 1/(1+np.exp(-X))\n\nsigmoid_numpy(np.array([12,0,1]))\n\ndef log_loss(y_true, y_predicted):\n    epsilon = 1e-15\n    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n    y_predicted_new = np.array(y_predicted_new)\n    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))\n`.trim();\n\nconst implementse = `\ndef gradient_descent(age, affordability, y_true, epochs, loss_thresold):\n    w1 = w2 = 1\n    bias = 0\n    rate = 0.5\n    n = len(age)\n    for i in range(epochs):\n        weighted_sum = w1 * age + w2 * affordability + bias\n        y_predicted = sigmoid_numpy(weighted_sum)\n        loss = log_loss(y_true, y_predicted)\n\n        w1d = (1/n)*np.dot(np.transpose(age),(y_predicted-y_true)) \n        w2d = (1/n)*np.dot(np.transpose(affordability),(y_predicted-y_true)) \n\n        bias_d = np.mean(y_predicted-y_true)\n        w1 = w1 - rate * w1d\n        w2 = w2 - rate * w2d\n        bias = bias - rate * bias_d\n\n        print (f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n\n        if loss<=loss_thresold:\n            break\n\n    return w1, w2, bias\n    \ngradient_descent(X_train_scaled['age'],X_train_scaled['affordibility'],y_train,1000, 0.4631)\n\ncoef, intercept\n`.trim();\n\n\nclass GradientNeural extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Implement Gradient Descent For Neural Network (or Logistic Regression)</h3>\n              An optimization algorithm used to train machine learning models by minimizing errors between predicted and actual results.\n              <br />\n              <br />\n\n              <b>Predicting if a person would buy life insurnace based on his age using logistic regression</b>\n              <br />\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <br />\n\n              <b>Model Building: First build a model in keras/tensorflow and see what weights and bias values it\n                comes up with. We will than try to reproduce same weights and bias in our plain python implementation\n                of gradient descent. Below is the architecture of our simple neural network</b>\n              <br />\n              <br />\n              <img src={Gradients} alt=\"Theata\" className=\"responsive2\" style={redesign} />\n              <br />\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={keras}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Now get the value of weights and bias from the model</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={weights}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Instead of model.predict, write our own prediction function that uses w1,w2 and bias.</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={prediction}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <br />\n\n              <b>Now we start implementing gradient descent in plain python. Again the goal is to come up with same w1, w2 and bias that keras model calculated. We want to show how keras/tensorflow would have computed these values internally using gradient descent</b>\n              <br />\n              <br />\n              <i>First write couple of helper routines such as sigmoid and log_loss.</i>\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={descent}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <br />\n\n              <b>All right now comes the time to implement our final gradient descent function</b>\n              <div style={titles}>\n                <PrismCode\n                  code={implementse}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <i>This shows that in the end we were able to come up with same value of w1,w2 and bias using a plain python implementation of gradient descent function.</i>\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\n\nexport default (withStyles(styles)(GradientNeural));\n"]},"metadata":{},"sourceType":"module"}
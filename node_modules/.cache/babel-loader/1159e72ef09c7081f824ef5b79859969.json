{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';import Neural from'../../../assets/AI/hp.jpg';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var redesign={height:200,width:500};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var childsFile=\"\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn import preprocessing\\nfrom matplotlib import pyplot as plt\\n%matplotlib inline\\n\\ndf = pd.read_csv(\\\"homeprices_banglore.csv\\\")\\n\\nsx = preprocessing.MinMaxScaler()\\nsy = preprocessing.MinMaxScaler()\\n\\nscaled_X = sx.fit_transform(df.drop('price',axis='columns'))\\nscaled_y = sy.fit_transform(df['price'].values.reshape(df.shape[0],1))\\n\\nscaled_y.reshape(20,)\\n\".trim();var batch=\"\\ndef batch_gradient_descent(X, y_true, epochs, learning_rate = 0.01):\\n    number_of_features = X.shape[1]\\n    w = np.ones(shape=(number_of_features)) \\n    b = 0\\n    total_samples = X.shape[0]                                                  # number of rows in X\\n    cost_list = []\\n    epoch_list = []\\n    \\n    for i in range(epochs):        \\n        y_predicted = np.dot(w, X.T) + b\\n\\n        w_grad = -(2/total_samples)*(X.T.dot(y_true-y_predicted))\\n        b_grad = -(2/total_samples)*np.sum(y_true-y_predicted)\\n        \\n        w = w - learning_rate * w_grad\\n        b = b - learning_rate * b_grad\\n        \\n        cost = np.mean(np.square(y_true-y_predicted))                          # MSE (Mean Squared Error)\\n        \\n        if i%10==0:\\n            cost_list.append(cost)\\n            epoch_list.append(i)\\n    return w, b, cost, cost_list, epoch_list\\n\\nw, b, cost, cost_list, epoch_list = batch_gradient_descent(scaled_X,scaled_y.reshape(scaled_y.shape[0],),500)\\nw, b, cost\\n\\nplt.xlabel(\\\"epoch\\\")\\nplt.ylabel(\\\"cost\\\")\\nplt.plot(epoch_list,cost_list)\\n\\n\".trim();var predictions=\"\\ndef predict(area,bedrooms,w,b):\\n    scaled_X = sx.transform([[area, bedrooms]])[0]\\n    scaled_price = w[0] * scaled_X[0] + w[1] * scaled_X[1] + b\\n    return sy.inverse_transform([[scaled_price]])[0][0]\\n\\npredict(2600,4,w,b)\\npredict(1000,2,w,b)\\npredict(1500,3,w,b)\\n\".trim();var stochastics=\"\\nimport random\\nrandom.randint(0,6)                              # randit gives random number between two numbers specified in the argument.\\n\\ndef stochastic_gradient_descent(X, y_true, epochs, learning_rate = 0.01):\\n    number_of_features = X.shape[1]\\n    w = np.ones(shape=(number_of_features)) \\n    b = 0\\n    total_samples = X.shape[0]\\n    \\n    cost_list = []\\n    epoch_list = []\\n    \\n    for i in range(epochs):    \\n        random_index = random.randint(0,total_samples-1) # random index from total samples\\n        sample_x = X[random_index]\\n        sample_y = y_true[random_index]\\n        y_predicted = np.dot(w, sample_x.T) + b\\n    \\n        w_grad = -(2/total_samples)*(sample_x.T.dot(sample_y-y_predicted))\\n        b_grad = -(2/total_samples)*(sample_y-y_predicted)\\n        \\n        w = w - learning_rate * w_grad\\n        b = b - learning_rate * b_grad\\n        cost = np.square(sample_y-y_predicted)\\n        \\n        if i%100==0: # at every 100th iteration record the cost and epoch value\\n            cost_list.append(cost)\\n            epoch_list.append(i)\\n    return w, b, cost, cost_list, epoch_list\\n\\nw_sgd, b_sgd, cost_sgd, cost_list_sgd, epoch_list_sgd = SGD(scaled_X,scaled_y.reshape(scaled_y.shape[0],),10000)\\nw_sgd, b_sgd, cost_sgd\\n\\nw , b \\nplt.xlabel(\\\"epoch\\\")\\nplt.ylabel(\\\"cost\\\")\\nplt.plot(epoch_list_sgd,cost_list_sgd)\\n\\npredict(2600,4,w_sgd, b_sgd) \\npredict(1000,2,w_sgd, b_sgd)\\npredict(1500,3,w_sgd, b_sgd)\\n\".trim();// const pipes = ``.trim();\nvar Stochastic=/*#__PURE__*/function(_Component){_inherits(Stochastic,_Component);function Stochastic(){_classCallCheck(this,Stochastic);return _possibleConstructorReturn(this,_getPrototypeOf(Stochastic).apply(this,arguments));}_createClass(Stochastic,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"Implementation of stochastic and batch grandient descent in python.\"),React.createElement(\"i\",null,\"We will use home prices data set to implement batch and stochastic gradient descent in python. Batch gradient descent uses \",React.createElement(\"b\",null,\"all\"),\" training samples in forward pass to calculate cumulitive error and than we adjust weights using derivaties. In stochastic GD, we \",React.createElement(\"b\",null,\"randomly pick one\"),\" training sample, perform forward pass, compute the error and immidiately adjust weights.\"),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Preprocessing/ Scaling: \"),\"Since our columns are on different sacle it is important to perform scaling on them.\")),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:childsFile,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"i\",null,\"We should convert target column (price) into one dimensional array. It has become 2D due to scaling that we did above but now we should change to 1D\"),React.createElement(\"br\",null),React.createElement(\"img\",{src:Neural,alt:\"Theata\",className:\"responsive2\",style:redesign}),React.createElement(\"h3\",null,\"Now implement mini batch gradient descent. \"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"numpy array with 1 row and columns equal to number of features. In our case number_of_features = 2 (area, bedroom).\")),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:batch,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Lets do some predictions now. \"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Here w1 = w[0] , w2 = w[1], w3 = w[2] and bias is b.\"),React.createElement(\"li\",null,\"Equation for price is w1*area + w2*bedrooms + w3*age + bias.\"),React.createElement(\"li\",null,\"scaled_X[0] is area.\"),React.createElement(\"li\",null,\"scaled_X[1] is bedrooms.\"),React.createElement(\"li\",null,\"scaled_X[2] is age.\"),React.createElement(\"li\",null,\"Once we get price prediction we need to to rescal it back to original value also since it returns 2D array, to get single value we need to do value[0][0].\")),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:predictions,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Stochastic Gradient Descent Implementation\"),React.createElement(\"i\",null,\"Stochastic GD will use randomly picked single training sample to calculate error and using this error we backpropage to adjust weights.\"),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:stochastics,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"i\",null,\"Compare this with weights and bias that we got using gradient descent. They both of quite similar.\")))));}}]);return Stochastic;}(Component);export default withStyles(styles)(Stochastic);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/angularjs/deepAngularjs/stochastic.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","Neural","titles","backgroundColor","padding","fontSize","redesign","height","width","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","childsFile","trim","batch","predictions","stochastics","Stochastic","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAEA,MAAOC,CAAAA,MAAP,KAAmB,2BAAnB,CAEA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,QAAQ,CAAG,CACfC,MAAM,CAAE,GADO,CAEfC,KAAK,CAAE,GAFQ,CAAjB,CAKA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACvBC,KAAK,CAAE,CACLC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH,CAELT,OAAO,CAAEM,KAAK,CAACG,OAAN,CAAc,CAAd,CAFJ,CADgB,CAKvBC,QAAQ,CAAE,CACRF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADA,CALa,CAQvBE,SAAS,CAAE,CACTC,SAAS,CAAE,QADF,CARY,CAAL,EAApB,CAcA,GAAMC,CAAAA,UAAU,CAAG,qaAgBjBC,IAhBiB,EAAnB,CAkBA,GAAMC,CAAAA,KAAK,CAAG,mkCAgCZD,IAhCY,EAAd,CAkCA,GAAME,CAAAA,WAAW,CAAG,oRASlBF,IATkB,EAApB,CAWA,GAAMG,CAAAA,WAAW,CAAG,47CA0ClBH,IA1CkB,EAApB,CA4CA;GAIMI,CAAAA,U,0SACgB,CAClBC,UAAU,CAAC,iBAAM7B,CAAAA,KAAK,CAAC8B,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACD,C,uCACQ,IACCC,CAAAA,OADD,CACa,KAAKC,KADlB,CACCD,OADD,CAEP,MACE,qBAAC,IAAD,EAAM,SAAS,KAAf,EACE,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAACd,KAA1B,EACE,8BAAI,oBAAC,OAAD,MAAJ,CADF,CADF,CADF,CAME,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEc,OAAO,CAACd,KAA1B,EACE,oBAAC,IAAD,MACE,oGADF,CAGE,2JACsC,mCADtC,sIAE0E,iDAF1E,6FAHF,CAOE,8BAPF,CAQE,8BARF,CASE,8BACE,8BAAI,wDAAJ,wFADF,CATF,CAYE,8BAZF,CAcE,2BAAK,KAAK,CAAET,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEe,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAdF,CAqBE,8BArBF,CAsBE,oLAtBF,CAwBE,8BAxBF,CAyBE,2BAAK,GAAG,CAAEhB,MAAV,CAAkB,GAAG,CAAC,QAAtB,CAA+B,SAAS,CAAC,aAAzC,CAAuD,KAAK,CAAEK,QAA9D,EAzBF,CA2BE,4EA3BF,CA4BE,8BACE,oJADF,CA5BF,CAgCE,2BAAK,KAAK,CAAEJ,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEiB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAhCF,CAuCE,8BAvCF,CAyCE,+DAzCF,CA0CE,8BACE,qFADF,CAEE,6FAFF,CAGE,qDAHF,CAIE,yDAJF,CAKE,oDALF,CAME,2LANF,CA1CF,CAkDE,2BAAK,KAAK,CAAEjB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEkB,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAlDF,CAyDE,8BAzDF,CA2DE,2EA3DF,CA4DE,uKA5DF,CA6DE,8BA7DF,CA8DE,2BAAK,KAAK,CAAElB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEmB,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA9DF,CAqEE,8BArEF,CAsEE,kIAtEF,CADF,CADF,CANF,CADF,CA+FD,C,wBArGsB5B,S,EAyGzB,cAAgBI,CAAAA,UAAU,CAACY,MAAD,CAAV,CAAmBa,UAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\nimport Neural from '../../../assets/AI/hp.jpg'\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst redesign = {\n  height: 200,\n  width: 500\n}\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst childsFile = `\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\ndf = pd.read_csv(\"homeprices_banglore.csv\")\n\nsx = preprocessing.MinMaxScaler()\nsy = preprocessing.MinMaxScaler()\n\nscaled_X = sx.fit_transform(df.drop('price',axis='columns'))\nscaled_y = sy.fit_transform(df['price'].values.reshape(df.shape[0],1))\n\nscaled_y.reshape(20,)\n`.trim();\n\nconst batch = `\ndef batch_gradient_descent(X, y_true, epochs, learning_rate = 0.01):\n    number_of_features = X.shape[1]\n    w = np.ones(shape=(number_of_features)) \n    b = 0\n    total_samples = X.shape[0]                                                  # number of rows in X\n    cost_list = []\n    epoch_list = []\n    \n    for i in range(epochs):        \n        y_predicted = np.dot(w, X.T) + b\n\n        w_grad = -(2/total_samples)*(X.T.dot(y_true-y_predicted))\n        b_grad = -(2/total_samples)*np.sum(y_true-y_predicted)\n        \n        w = w - learning_rate * w_grad\n        b = b - learning_rate * b_grad\n        \n        cost = np.mean(np.square(y_true-y_predicted))                          # MSE (Mean Squared Error)\n        \n        if i%10==0:\n            cost_list.append(cost)\n            epoch_list.append(i)\n    return w, b, cost, cost_list, epoch_list\n\nw, b, cost, cost_list, epoch_list = batch_gradient_descent(scaled_X,scaled_y.reshape(scaled_y.shape[0],),500)\nw, b, cost\n\nplt.xlabel(\"epoch\")\nplt.ylabel(\"cost\")\nplt.plot(epoch_list,cost_list)\n\n`.trim();\n\nconst predictions = `\ndef predict(area,bedrooms,w,b):\n    scaled_X = sx.transform([[area, bedrooms]])[0]\n    scaled_price = w[0] * scaled_X[0] + w[1] * scaled_X[1] + b\n    return sy.inverse_transform([[scaled_price]])[0][0]\n\npredict(2600,4,w,b)\npredict(1000,2,w,b)\npredict(1500,3,w,b)\n`.trim();\n\nconst stochastics = `\nimport random\nrandom.randint(0,6)                              # randit gives random number between two numbers specified in the argument.\n\ndef stochastic_gradient_descent(X, y_true, epochs, learning_rate = 0.01):\n    number_of_features = X.shape[1]\n    w = np.ones(shape=(number_of_features)) \n    b = 0\n    total_samples = X.shape[0]\n    \n    cost_list = []\n    epoch_list = []\n    \n    for i in range(epochs):    \n        random_index = random.randint(0,total_samples-1) # random index from total samples\n        sample_x = X[random_index]\n        sample_y = y_true[random_index]\n        y_predicted = np.dot(w, sample_x.T) + b\n    \n        w_grad = -(2/total_samples)*(sample_x.T.dot(sample_y-y_predicted))\n        b_grad = -(2/total_samples)*(sample_y-y_predicted)\n        \n        w = w - learning_rate * w_grad\n        b = b - learning_rate * b_grad\n        cost = np.square(sample_y-y_predicted)\n        \n        if i%100==0: # at every 100th iteration record the cost and epoch value\n            cost_list.append(cost)\n            epoch_list.append(i)\n    return w, b, cost, cost_list, epoch_list\n\nw_sgd, b_sgd, cost_sgd, cost_list_sgd, epoch_list_sgd = SGD(scaled_X,scaled_y.reshape(scaled_y.shape[0],),10000)\nw_sgd, b_sgd, cost_sgd\n\nw , b \nplt.xlabel(\"epoch\")\nplt.ylabel(\"cost\")\nplt.plot(epoch_list_sgd,cost_list_sgd)\n\npredict(2600,4,w_sgd, b_sgd) \npredict(1000,2,w_sgd, b_sgd)\npredict(1500,3,w_sgd, b_sgd)\n`.trim();\n\n// const pipes = ``.trim();\n\n\n\nclass Stochastic extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Implementation of stochastic and batch grandient descent in python.</h3>\n\n              <i>We will use home prices data set to implement batch and stochastic gradient descent in\n                python. Batch gradient descent uses <b>all</b> training samples in forward pass to calculate cumulitive\n                error and than we adjust weights using derivaties. In stochastic GD, we <b>randomly pick one</b> training\n                sample, perform forward pass, compute the error and immidiately adjust weights.</i>\n              <br />\n              <br />\n              <ul>\n                <li><b>Preprocessing/ Scaling: </b>Since our columns are on different sacle it is important to perform scaling on them.</li>\n              </ul>\n              <br />\n\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <i>We should convert target column (price) into one dimensional array. It has become 2D due to\n                scaling that we did above but now we should change to 1D</i>\n              <br />\n              <img src={Neural} alt=\"Theata\" className=\"responsive2\" style={redesign} />\n\n              <h3>Now implement mini batch gradient descent. </h3>\n              <ul>\n                <li>numpy array with 1 row and columns equal to number of features. In\n                  our case number_of_features = 2 (area, bedroom).</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={batch}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Lets do some predictions now. </h3>\n              <ul>\n                <li>Here w1 = w[0] , w2 = w[1], w3 = w[2] and bias is b.</li>\n                <li>Equation for price is w1*area + w2*bedrooms + w3*age + bias.</li>\n                <li>scaled_X[0] is area.</li>\n                <li>scaled_X[1] is bedrooms.</li>\n                <li>scaled_X[2] is age.</li>\n                <li>Once we get price prediction we need to to rescal it back to original value also since it returns 2D array, to get single value we need to do value[0][0].</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={predictions}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Stochastic Gradient Descent Implementation</h3>\n              <i>Stochastic GD will use randomly picked single training sample to calculate error and using this error we backpropage to adjust weights.</i>\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={stochastics}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <i>Compare this with weights and bias that we got using gradient descent. They both of quite similar.</i>\n              {/* <br />\n\n              <h3></h3>\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div> */}\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\n\nexport default (withStyles(styles)(Stochastic));\n"]},"metadata":{},"sourceType":"module"}
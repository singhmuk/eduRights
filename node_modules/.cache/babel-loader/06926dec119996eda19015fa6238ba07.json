{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var sklearn=\"\\nfrom sklearn.datasets import load_iris\\n\\niris = load_iris()\\nX = iris.data\\ny = iris.target\\n\\nfeature_names = iris.feature_names\\ntarget_names = iris.target_names\\n\\nprint(\\\"Feature names:\\\", feature_names)\\nprint(\\\"Target names:\\\", target_names)\\nprint(\\\"First 10 rows of X\\\", X[:10])\\n\".trim();var accuracy=\"\\nfrom sklearn.model_selection import train_test_split\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\\n\\nX_train.shape\\nX_test.shape\\n\\ny_train.shape\\ny_test.shape\\n\".trim();var trains=\"\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn import metrics\\n\\nclassifier_knn = KNeighborsClassifier(n_neighbors = 3)\\nclassifier_knn.fit(X_train, y_train)\\ny_pred = classifier_knn.predict(X_test)\\n\\n# Finding accuracy by comparing actual response values(y_test)with predicted response value(y_pred)\\nprint(\\\"Accuracy:\\\", metrics.accuracy_score(y_test, y_pred))\\n\\n# Providing sample data and the model will make prediction out of that data\\nsample = [[5, 5, 3, 2], [2, 4, 3, 5]]\\npreds = classifier_knn.predict(sample)\\n\".trim();var stack=\"\\nfrom sklearn import linear_model\\nreg = linear_model.LinearRegression()  \\n\\nfrom sklearn.linear_model import LinearRegression\\nmodel = LinearRegression()\\nmodel.fit(X_train, Y_train)                       \\n\\nfrom sklearn.preprocessing import StandardScaler  \\nsc_X = StandardScaler()\\n\\nfrom sklearn.linear_model import LogisticRegression\\nmodel = LogisticRegression()\\n\\nfrom sklearn.svm import SVC\\nsvm = SVC(gamma='auto') \\n\\nfrom sklearn.svm import SVC\\nmodel = SVC()\\nmodel.fit(X_train, y_train)\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\nrf = RandomForestClassifier(n_estimators=40)                                                      \\n\\nfrom sklearn.model_selection import KFold\\nkf = KFold(n_splits=3)\\n\\nfrom sklearn.neighbors import KNeighborsClassifier \\nknn = KNeighborsClassifier(n_neighbors=10)\\n\\nfrom sklearn.preprocessing import MinMaxScaler\\nscaler = MinMaxScaler()\\nscaler.fit(df[['Income($)']])\\n\\nfrom sklearn.pipeline import Pipeline\\nclf = Pipeline([('vectorizer', CountVectorizer()),('nb', MultinomialNB())])\\nclf.fit(X_train, y_train)\\n\\nfrom sklearn.preprocessing import LabelEncoder\\nle_company = LabelEncoder()\\n\\nfrom sklearn import tree\\nmodel = tree.DecisionTreeClassifier()\\nmodel.fit(inputs_n, target)\\n\\nfrom sklearn.decomposition import PCA\\npca = PCA(0.95)\\nX_pca = pca.fit_transform(X)\\n\\nfrom sklearn import preprocessing\\nencoder = preprocessing.LabelEncoder()\\nencoder.fit(input_labels)\\n\\nfrom sklearn.linear_model import Ridge                                                  \\nridge_reg= Ridge(alpha=50, max_iter=100, tol=0.1) \\nridge_reg.fit(train_X, train_y)\\n\\nfrom sklearn.preprocessing import StandardScaler\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn.tree import DecisionTreeClassifier\\nscores = cross_val_score(DecisionTreeClassifier(), X, y, cv=5)\\n\\nfrom sklearn.model_selection import GridSearchCV\\nclf = GridSearchCV(svm.SVC(gamma='auto'), {'C': [1,10,20], 'kernel': ['rbf','linear']}, cv=5, return_train_score=False)\\nclf.fit(iris.data, iris.target)\\n\\nfrom sklearn.model_selection import RandomizedSearchCV\\nrs = RandomizedSearchCV(svm.SVC(gamma='auto'), {'C': [1,10,20],'kernel': ['rbf','linear']}, \\n    cv=5, return_train_score=False, n_iter=2)\\nrs.fit(iris.data, iris.target)\\n\\nfrom sklearn.ensemble import BaggingClassifier\\n\\nbag_model = BaggingClassifier(\\n    base_estimator=DecisionTreeClassifier(), \\n    n_estimators=100, \\n    max_samples=0.8, \\n    oob_score=True,\\n    random_state=0\\n)\\nbag_model.fit(X_train, y_train)\\n\".trim();// const stack = ``.trim();\nvar LogisticReg=/*#__PURE__*/function(_Component){_inherits(LogisticReg,_Component);function LogisticReg(){_classCallCheck(this,LogisticReg);return _possibleConstructorReturn(this,_getPrototypeOf(LogisticReg).apply(this,arguments));}_createClass(LogisticReg,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"Scikit Learn (common algoritham) - Modelling Process\"),\"Rather than focusing on loading, manipulating and summarising data, Scikit-learn library is focused on modeling the data. Some of the most popular groups of models provided by Sklearn are as follows \\u2212\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"We can do following with scikit Learn.\",React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Classification: \"),\"SVM, nearest neighbors, random forest, logistic regression, etc.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Regression: \"),\"Lasso, ridge regression, etc.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Clustering: \"),\"k-means, spectral clustering, etc.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Dimensionality reduction: \"),\"PCA, feature selection, matrix factorization, etc.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Model selection: \"),\"Grid search, cross-validation, metrics.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Preprocessing: \"),\".Feature extraction, normalization\")),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Dataset Loading:\"),\"A collection of data is called dataset. It is having the following two components.\",React.createElement(\"br\",null),\"Dataset having the following two components.\",React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Features: \"),\"The variables of data are called its features.\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Feature matrix: \"),\"It is the collection of features, in case there are more than one.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Feature Names: \"),\"It is the list of all the names of the features.\")),React.createElement(\"br\",null),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Response: \"),\"It is the output variable that basically depends upon the feature variables.\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Response Vector: \"),\"It is used to represent response column. Generally, we have just one response column.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Target Names: \"),\"It represent the possible values taken by a response vector.\"))),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:sklearn,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Some popular groups of models provided by scikit-learn include:\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Clustering: \"),\"For grouping unlabeled data such as KMeans.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Cross Validation: \"),\"For estimating the performance of supervised models on unseen data.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Datasets: \"),\"For test datasets and for generating datasets with specific properties for investigating model behavior.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Dimensionality Reduction: \"),\"For reducing the number of attributes in data for summarization, visualization and feature selection such as Principal component analysis.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Ensemble methods: \"),\"For combining the predictions of multiple supervised models.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Feature extraction: \"),\"For defining attributes in image and text data.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Feature selection: \"),\"For identifying meaningful attributes from which to create supervised models.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Parameter Tuning: \"),\"For getting the most out of supervised models.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Manifold Learning: \"),\"For summarizing and depicting complex multi-dimensional data.\")),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Splitting the dataset\"),\"To check the accuracy of our model, we can split the dataset into two pieces-a training set and a testing set.\",React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:accuracy,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Train the Model\"),\"Next, we can use our dataset to train some prediction-model. ML algorithms have a consistent interface for fitting, predicting accuracy, recall etc.\",React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:trains,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"sklearn Models\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:stack,language:\"js\",plugins:[\"line-numbers\"]}))))));}}]);return LogisticReg;}(Component);export default withStyles(styles)(LogisticReg);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/ml/deepMl/logisticRegrations.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","titles","backgroundColor","padding","fontSize","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","sklearn","trim","accuracy","trains","stack","LogisticReg","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAGA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACvBC,KAAK,CAAE,CACLC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH,CAELN,OAAO,CAAEG,KAAK,CAACG,OAAN,CAAc,CAAd,CAFJ,CADgB,CAKvBC,QAAQ,CAAE,CACRF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADA,CALa,CAQvBE,SAAS,CAAE,CACTC,SAAS,CAAE,QADF,CARY,CAAL,EAApB,CAcA,GAAMC,CAAAA,OAAO,CAAG,sSAadC,IAbc,EAAhB,CAeA,GAAMC,CAAAA,QAAQ,CAAG,yNAUfD,IAVe,EAAjB,CAYA,GAAME,CAAAA,MAAM,CAAG,kiBAcbF,IAda,EAAf,CAgBA,GAAMG,CAAAA,KAAK,CAAG,0iFAoFZH,IApFY,EAAd,CAsFA;GAIMI,CAAAA,W,+SACgB,CAClBC,UAAU,CAAC,iBAAMzB,CAAAA,KAAK,CAAC0B,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACD,C,uCACQ,IACCC,CAAAA,OADD,CACa,KAAKC,KADlB,CACCD,OADD,CAEP,MACE,qBAAC,IAAD,EAAM,SAAS,KAAf,EACE,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAACd,KAA1B,EACE,8BAAI,oBAAC,OAAD,MAAJ,CADF,CADF,CADF,CAME,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEc,OAAO,CAACd,KAA1B,EACE,oBAAC,IAAD,MACE,qFADF,iNAGE,8BAHF,CAIE,8BAJF,0CAME,8BACE,8BAAI,gDAAJ,oEADF,CAEE,8BAAI,4CAAJ,iCAFF,CAGE,8BAAI,4CAAJ,sCAHF,CAIE,8BAAI,0DAAJ,sDAJF,CAKE,8BAAI,iDAAJ,2CALF,CAME,8BAAI,+CAAJ,sCANF,CANF,CAcE,8BAdF,CAeE,gDAfF,sFAgBE,8BAhBF,gDAkBE,8BACE,8BAAI,0CAAJ,kDADF,CAEE,8BACE,8BAAI,gDAAJ,sEADF,CAEE,8BAAI,+CAAJ,oDAFF,CAFF,CAME,8BANF,CAOE,8BAAI,0CAAJ,gFAPF,CAQE,8BACE,8BAAI,iDAAJ,yFADF,CAEE,8BAAI,8CAAJ,gEAFF,CARF,CAlBF,CAgCE,2BAAK,KAAK,CAAEN,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEY,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAhCF,CAuCE,8BAvCF,CAwCE,8BAxCF,CA0CE,+FA1CF,CA2CE,8BACE,8BAAI,4CAAJ,+CADF,CAEE,8BAAI,kDAAJ,uEAFF,CAGE,8BAAI,0CAAJ,4GAHF,CAKE,8BAAI,0DAAJ,8IALF,CAOE,8BAAI,kDAAJ,gEAPF,CAQE,8BAAI,oDAAJ,mDARF,CASE,8BAAI,mDAAJ,iFATF,CAUE,8BAAI,kDAAJ,kDAVF,CAWE,8BAAI,mDAAJ,iEAXF,CA3CF,CAwDE,8BAxDF,CA0DE,sDA1DF,kHA4DE,2BAAK,KAAK,CAAEZ,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEc,QADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA5DF,CAmEE,8BAnEF,CAqEE,gDArEF,wJAwEE,2BAAK,KAAK,CAAEd,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEe,MADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAxEF,CA+EE,8BA/EF,CAiFE,+CAjFF,CAkFE,2BAAK,KAAK,CAAEf,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEgB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAlFF,CADF,CADF,CANF,CADF,CAuGD,C,yBA7GuBxB,S,EAgH1B,cAAgBI,CAAAA,UAAU,CAACQ,MAAD,CAAV,CAAmBa,WAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst sklearn = `\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nfeature_names = iris.feature_names\ntarget_names = iris.target_names\n\nprint(\"Feature names:\", feature_names)\nprint(\"Target names:\", target_names)\nprint(\"First 10 rows of X\", X[:10])\n`.trim();\n\nconst accuracy = `\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n\nX_train.shape\nX_test.shape\n\ny_train.shape\ny_test.shape\n`.trim();\n\nconst trains = `\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nclassifier_knn = KNeighborsClassifier(n_neighbors = 3)\nclassifier_knn.fit(X_train, y_train)\ny_pred = classifier_knn.predict(X_test)\n\n# Finding accuracy by comparing actual response values(y_test)with predicted response value(y_pred)\nprint(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n\n# Providing sample data and the model will make prediction out of that data\nsample = [[5, 5, 3, 2], [2, 4, 3, 5]]\npreds = classifier_knn.predict(sample)\n`.trim();\n\nconst stack = `\nfrom sklearn import linear_model\nreg = linear_model.LinearRegression()  \n\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, Y_train)                       \n\nfrom sklearn.preprocessing import StandardScaler  \nsc_X = StandardScaler()\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\n\nfrom sklearn.svm import SVC\nsvm = SVC(gamma='auto') \n\nfrom sklearn.svm import SVC\nmodel = SVC()\nmodel.fit(X_train, y_train)\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=40)                                                      \n\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=3)\n\nfrom sklearn.neighbors import KNeighborsClassifier \nknn = KNeighborsClassifier(n_neighbors=10)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(df[['Income($)']])\n\nfrom sklearn.pipeline import Pipeline\nclf = Pipeline([('vectorizer', CountVectorizer()),('nb', MultinomialNB())])\nclf.fit(X_train, y_train)\n\nfrom sklearn.preprocessing import LabelEncoder\nle_company = LabelEncoder()\n\nfrom sklearn import tree\nmodel = tree.DecisionTreeClassifier()\nmodel.fit(inputs_n, target)\n\nfrom sklearn.decomposition import PCA\npca = PCA(0.95)\nX_pca = pca.fit_transform(X)\n\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\nencoder.fit(input_labels)\n\nfrom sklearn.linear_model import Ridge                                                  \nridge_reg= Ridge(alpha=50, max_iter=100, tol=0.1) \nridge_reg.fit(train_X, train_y)\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nscores = cross_val_score(DecisionTreeClassifier(), X, y, cv=5)\n\nfrom sklearn.model_selection import GridSearchCV\nclf = GridSearchCV(svm.SVC(gamma='auto'), {'C': [1,10,20], 'kernel': ['rbf','linear']}, cv=5, return_train_score=False)\nclf.fit(iris.data, iris.target)\n\nfrom sklearn.model_selection import RandomizedSearchCV\nrs = RandomizedSearchCV(svm.SVC(gamma='auto'), {'C': [1,10,20],'kernel': ['rbf','linear']}, \n    cv=5, return_train_score=False, n_iter=2)\nrs.fit(iris.data, iris.target)\n\nfrom sklearn.ensemble import BaggingClassifier\n\nbag_model = BaggingClassifier(\n    base_estimator=DecisionTreeClassifier(), \n    n_estimators=100, \n    max_samples=0.8, \n    oob_score=True,\n    random_state=0\n)\nbag_model.fit(X_train, y_train)\n`.trim();\n\n// const stack = ``.trim();\n\n\n\nclass LogisticReg extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Scikit Learn (common algoritham) - Modelling Process</h3>\n              Rather than focusing on loading, manipulating and summarising data, Scikit-learn library is focused on modeling the data. Some of the most popular groups of models provided by Sklearn are as follows −\n              <br />\n              <br />\n              We can do following with scikit Learn.\n              <ul>\n                <li><b>Classification: </b>SVM, nearest neighbors, random forest, logistic regression, etc.</li>\n                <li><b>Regression: </b>Lasso, ridge regression, etc.</li>\n                <li><b>Clustering: </b>k-means, spectral clustering, etc.</li>\n                <li><b>Dimensionality reduction: </b>PCA, feature selection, matrix factorization, etc.</li>\n                <li><b>Model selection: </b>Grid search, cross-validation, metrics.</li>\n                <li><b>Preprocessing: </b>.Feature extraction, normalization</li>\n              </ul>\n              <br />\n              <b>Dataset Loading:</b>A collection of data is called dataset. It is having the following two components.\n              <br />\n              Dataset having the following two components.\n              <ul>\n                <li><b>Features: </b>The variables of data are called its features.</li>\n                <ul>\n                  <li><b>Feature matrix: </b>It is the collection of features, in case there are more than one.</li>\n                  <li><b>Feature Names: </b>It is the list of all the names of the features.</li>\n                </ul>\n                <br />\n                <li><b>Response: </b>It is the output variable that basically depends upon the feature variables.</li>\n                <ul>\n                  <li><b>Response Vector: </b>It is used to represent response column. Generally, we have just one response column.</li>\n                  <li><b>Target Names: </b>It represent the possible values taken by a response vector.</li>\n                </ul>\n              </ul>\n\n              <div style={titles}>\n                <PrismCode\n                  code={sklearn}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <br />\n\n              <b>Some popular groups of models provided by scikit-learn include:</b>\n              <ul>\n                <li><b>Clustering: </b>For grouping unlabeled data such as KMeans.</li>\n                <li><b>Cross Validation: </b>For estimating the performance of supervised models on unseen data.</li>\n                <li><b>Datasets: </b>For test datasets and for generating datasets with specific properties for\n                  investigating model behavior.</li>\n                <li><b>Dimensionality Reduction: </b>For reducing the number of attributes in data for summarization,\n                  visualization and feature selection such as Principal component analysis.</li>\n                <li><b>Ensemble methods: </b>For combining the predictions of multiple supervised models.</li>\n                <li><b>Feature extraction: </b>For defining attributes in image and text data.</li>\n                <li><b>Feature selection: </b>For identifying meaningful attributes from which to create supervised models.</li>\n                <li><b>Parameter Tuning: </b>For getting the most out of supervised models.</li>\n                <li><b>Manifold Learning: </b>For summarizing and depicting complex multi-dimensional data.</li>\n              </ul>\n              <br />\n\n              <h3>Splitting the dataset</h3>\n              To check the accuracy of our model, we can split the dataset into two pieces-a training set and a testing set.\n              <div style={titles}>\n                <PrismCode\n                  code={accuracy}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Train the Model</h3>\n              Next, we can use our dataset to train some prediction-model. ML algorithms have a consistent interface for fitting, predicting\n              accuracy, recall etc.\n              <div style={titles}>\n                <PrismCode\n                  code={trains}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>sklearn Models</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={stack}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\nexport default (withStyles(styles)(LogisticReg));\n"]},"metadata":{},"sourceType":"module"}
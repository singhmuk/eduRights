{"ast":null,"code":"var _jsxFileName = \"/home/mukeshs/Projects/edurights/client/src/components/angularjs/deepAngularjs/transfer.js\";\nimport React, { Component } from 'react';\nimport Prism from \"prismjs\";\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\nimport '../../ReactJs/styles.css';\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\nconst titles = {\n  backgroundColor: '#F0F8FF',\n  padding: '1px',\n  fontSize: '16px'\n};\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n});\n\nconst childsFile = `\nimport numpy as np\nimport cv2\nimport PIL.Image as Image\nimport os\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\n\nIMAGE_SHAPE = (224, 224)                                      #Make predictions using ready made model (without training).\n\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n])\n\ngold_fish = Image.open(\"goldfish.jpg\").resize(IMAGE_SHAPE)\ngold_fish = np.array(gold_fish)/255.0\n\ngold_fish[np.newaxis, ...]\nresult = classifier.predict(gold_fish[np.newaxis, ...])\n\npredicted_label_index = np.argmax(result)\npredicted_label_index\n\n# tf.keras.utils.get_file('ImageNetLabels.txt',\n#                         'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\nimage_labels = []\nwith open(\"ImageNetLabels.txt\", \"r\") as f:\n    image_labels = f.read().splitlines()\nimage_labels[:5]\n\nimage_labels[predicted_label_index]\n`.trim();\nconst flowers = `\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n\ndata_dir\n\nimport pathlib\ndata_dir = pathlib.Path(data_dir)\n\nlist(data_dir.glob('*/*.jpg'))[:5]\nimage_count = len(list(data_dir.glob('*/*.jpg')))\nprint(image_count)\n\nroses = list(data_dir.glob('roses/*'))\nroses[:5]\n\nPIL.Image.open(str(roses[1]))\n\ntulips = list(data_dir.glob('tulips/*'))\nPIL.Image.open(str(tulips[0]))\n`.trim();\nconst opencv = `\nflowers_images_dict = {\n  'roses': list(data_dir.glob('roses/*')),\n  'daisy': list(data_dir.glob('daisy/*')),\n  'dandelion': list(data_dir.glob('dandelion/*')),\n  'sunflowers': list(data_dir.glob('sunflowers/*')),\n  'tulips': list(data_dir.glob('tulips/*')),\n}\n\nflowers_labels_dict = {\n  'roses': 0,\n  'daisy': 1,\n  'dandelion': 2,\n  'sunflowers': 3,\n  'tulips': 4,\n}\n\nflowers_images_dict['roses'][:5]\nstr(flowers_images_dict['roses'][0])\n\nimg = cv2.imread(str(flowers_images_dict['roses'][0]))\ncv2.resize(img,(224,224)).shape\nX, y = [], []\n\nfor flower_name, images in flowers_images_dict.items():\n    for image in images:\n        img = cv2.imread(str(image))\n        resized_img = cv2.resize(img,(224,224))\n        X.append(resized_img)\n        y.append(flowers_labels_dict[flower_name])\n        \nX = np.array(X)\ny = np.array(y)\n`.trim();\nconst split = `\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nX_train_scaled = X_train / 255\nX_test_scaled = X_test / 255\n\n\nX[0].shape                                                #Make prediction using pre-trained model on new flowers dataset.\nIMAGE_SHAPE+(3,)\n\nx0_resized = cv2.resize(X[0], IMAGE_SHAPE)\nx1_resized = cv2.resize(X[1], IMAGE_SHAPE)\nx2_resized = cv2.resize(X[2], IMAGE_SHAPE)\n\nplt.axis('off')\nplt.imshow(X[0])\n\nplt.axis('off')\nplt.imshow(X[1])\n\nplt.axis('off')\nplt.imshow(X[2])\n\npredicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\npredicted = np.argmax(predicted, axis=1)\npredicted\n\nimage_labels[795]\n`.trim();\nconst images = `\nfeature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n\npretrained_model_without_top_layer = hub.KerasLayer(\n    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n    \nnum_of_flowers = 5\nmodel = tf.keras.Sequential([pretrained_model_without_top_layer, tf.keras.layers.Dense(num_of_flowers)])\n\nmodel.summary()\n\n\nmodel.compile(\n  optimizer=\"adam\",\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['acc'])\n\nmodel.fit(X_train_scaled, y_train, epochs=5)\n\nmodel.evaluate(X_test_scaled,y_test)\n`.trim();\n\nclass Transfer extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0);\n  }\n\n  render() {\n    const {\n      classes\n    } = this.props;\n    return React.createElement(Grid, {\n      container: true,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 183\n      },\n      __self: this\n    }, React.createElement(Grid, {\n      item: true,\n      xs: 2,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 184\n      },\n      __self: this\n    }, React.createElement(Paper, {\n      className: classes.paper,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 185\n      },\n      __self: this\n    }, React.createElement(\"h4\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 186\n      },\n      __self: this\n    }, React.createElement(Sidebar, {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 186\n      },\n      __self: this\n    })))), React.createElement(Grid, {\n      item: true,\n      xs: 10,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 189\n      },\n      __self: this\n    }, React.createElement(Paper, {\n      className: classes.paper,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 190\n      },\n      __self: this\n    }, React.createElement(List, {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 191\n      },\n      __self: this\n    }, React.createElement(\"h3\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 192\n      },\n      __self: this\n    }, \"Transfer learning in image classification\"), \"We will use transfer learning and take pre-trained model from google's Tensorflow Hub and re-train that on flowers dataset.\", React.createElement(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 195\n      },\n      __self: this\n    }), React.createElement(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 196\n      },\n      __self: this\n    }), React.createElement(\"div\", {\n      style: titles,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 197\n      },\n      __self: this\n    }, React.createElement(PrismCode, {\n      code: childsFile,\n      language: \"js\",\n      plugins: [\"line-numbers\"],\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 198\n      },\n      __self: this\n    })), React.createElement(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 204\n      },\n      __self: this\n    }), React.createElement(\"h3\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 206\n      },\n      __self: this\n    }, \"Load flowers dataset\"), React.createElement(\"i\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 207\n      },\n      __self: this\n    }, \"cache_dir indicates where to download data.\"), React.createElement(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 208\n      },\n      __self: this\n    }), React.createElement(\"div\", {\n      style: titles,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 209\n      },\n      __self: this\n    }, React.createElement(PrismCode, {\n      code: flowers,\n      language: \"js\",\n      plugins: [\"line-numbers\"],\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 210\n      },\n      __self: this\n    })), React.createElement(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 216\n      },\n      __self: this\n    }), React.createElement(\"h3\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 218\n      },\n      __self: this\n    }, \"Read flowers images from disk into numpy array using opencv\"), React.createElement(\"div\", {\n      style: titles,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 219\n      },\n      __self: this\n    }, React.createElement(PrismCode, {\n      code: opencv,\n      language: \"js\",\n      plugins: [\"line-numbers\"],\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 220\n      },\n      __self: this\n    })), React.createElement(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 226\n      },\n      __self: this\n    }), React.createElement(\"h3\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 228\n      },\n      __self: this\n    }, \"Train test split\"), React.createElement(\"div\", {\n      style: titles,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 229\n      },\n      __self: this\n    }, React.createElement(PrismCode, {\n      code: split,\n      language: \"js\",\n      plugins: [\"line-numbers\"],\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 230\n      },\n      __self: this\n    })), React.createElement(\"br\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 236\n      },\n      __self: this\n    }), React.createElement(\"h3\", {\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 238\n      },\n      __self: this\n    }, \"Now take pre-trained model and retrain it using flowers images\"), React.createElement(\"div\", {\n      style: titles,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 239\n      },\n      __self: this\n    }, React.createElement(PrismCode, {\n      code: images,\n      language: \"js\",\n      plugins: [\"line-numbers\"],\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 240\n      },\n      __self: this\n    }))))));\n  }\n\n}\n\nexport default withStyles(styles)(Transfer);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/client/src/components/angularjs/deepAngularjs/transfer.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","titles","backgroundColor","padding","fontSize","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","childsFile","trim","flowers","opencv","split","images","Transfer","componentDidMount","setTimeout","highlightAll","render","classes","props"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,KAAP,MAAkB,SAAlB;AACA,SAASC,IAAT,EAAeC,KAAf,EAAsBC,UAAtB,EAAkCC,IAAlC,QAA8C,mBAA9C;AAEA,OAAO,0BAAP;AACA,OAAOC,OAAP,MAAoB,YAApB;AACA,OAAOC,SAAP,MAAsB,yBAAtB;AAGA,MAAMC,MAAM,GAAG;AAAEC,EAAAA,eAAe,EAAE,SAAnB;AAA8BC,EAAAA,OAAO,EAAE,KAAvC;AAA8CC,EAAAA,QAAQ,EAAE;AAAxD,CAAf;;AAEA,MAAMC,MAAM,GAAGC,KAAK,KAAK;AACvBC,EAAAA,KAAK,EAAE;AACLC,IAAAA,MAAM,EAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH;AAELN,IAAAA,OAAO,EAAEG,KAAK,CAACG,OAAN,CAAc,CAAd;AAFJ,GADgB;AAKvBC,EAAAA,QAAQ,EAAE;AACRF,IAAAA,MAAM,EAAEF,KAAK,CAACG,OAAN,CAAc,CAAd;AADA,GALa;AAQvBE,EAAAA,SAAS,EAAE;AACTC,IAAAA,SAAS,EAAE;AADF;AARY,CAAL,CAApB;;AAcA,MAAMC,UAAU,GAAI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CAAD,CAoCjBC,IApCiB,EAAnB;AAsCA,MAAMC,OAAO,GAAI;;;;;;;;;;;;;;;;;;;;CAAD,CAoBdD,IApBc,EAAhB;AAsBA,MAAME,MAAM,GAAI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CAAD,CAiCbF,IAjCa,EAAf;AAmCA,MAAMG,KAAK,GAAI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CAAD,CA6BZH,IA7BY,EAAd;AA+BA,MAAMI,MAAM,GAAI;;;;;;;;;;;;;;;;;;;;CAAD,CAoBbJ,IApBa,EAAf;;AAwBA,MAAMK,QAAN,SAAuB1B,SAAvB,CAAiC;AAC/B2B,EAAAA,iBAAiB,GAAG;AAClBC,IAAAA,UAAU,CAAC,MAAM3B,KAAK,CAAC4B,YAAN,EAAP,EAA6B,CAA7B,CAAV;AACD;;AACDC,EAAAA,MAAM,GAAG;AACP,UAAM;AAAEC,MAAAA;AAAF,QAAc,KAAKC,KAAzB;AACA,WACE,oBAAC,IAAD;AAAM,MAAA,SAAS,MAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,IAAD;AAAM,MAAA,IAAI,MAAV;AAAW,MAAA,EAAE,EAAE,CAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,KAAD;AAAO,MAAA,SAAS,EAAED,OAAO,CAACjB,KAA1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAI,oBAAC,OAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAAJ,CADF,CADF,CADF,EAME,oBAAC,IAAD;AAAM,MAAA,IAAI,MAAV;AAAW,MAAA,EAAE,EAAE,EAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,KAAD;AAAO,MAAA,SAAS,EAAEiB,OAAO,CAACjB,KAA1B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mDADF,iIAIE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAJF,EAKE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MALF,EAME;AAAK,MAAA,KAAK,EAAEN,MAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,SAAD;AACE,MAAA,IAAI,EAAEY,UADR;AAEE,MAAA,QAAQ,EAAC,IAFX;AAGE,MAAA,OAAO,EAAE,CAAC,cAAD,CAHX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,CANF,EAaE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAbF,EAeE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAfF,EAgBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qDAhBF,EAiBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAjBF,EAkBE;AAAK,MAAA,KAAK,EAAEZ,MAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,SAAD;AACE,MAAA,IAAI,EAAEc,OADR;AAEE,MAAA,QAAQ,EAAC,IAFX;AAGE,MAAA,OAAO,EAAE,CAAC,cAAD,CAHX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,CAlBF,EAyBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAzBF,EA2BE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qEA3BF,EA4BE;AAAK,MAAA,KAAK,EAAEd,MAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,SAAD;AACE,MAAA,IAAI,EAAEe,MADR;AAEE,MAAA,QAAQ,EAAC,IAFX;AAGE,MAAA,OAAO,EAAE,CAAC,cAAD,CAHX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,CA5BF,EAmCE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAnCF,EAqCE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BArCF,EAsCE;AAAK,MAAA,KAAK,EAAEf,MAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,SAAD;AACE,MAAA,IAAI,EAAEgB,KADR;AAEE,MAAA,QAAQ,EAAC,IAFX;AAGE,MAAA,OAAO,EAAE,CAAC,cAAD,CAHX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,CAtCF,EA6CE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MA7CF,EA+CE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wEA/CF,EAgDE;AAAK,MAAA,KAAK,EAAEhB,MAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OACE,oBAAC,SAAD;AACE,MAAA,IAAI,EAAEiB,MADR;AAEE,MAAA,QAAQ,EAAC,IAFX;AAGE,MAAA,OAAO,EAAE,CAAC,cAAD,CAHX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,CAhDF,CADF,CADF,CANF,CADF;AAqED;;AA3E8B;;AA+EjC,eAAgBrB,UAAU,CAACQ,MAAD,CAAV,CAAmBc,QAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst childsFile = `\nimport numpy as np\nimport cv2\nimport PIL.Image as Image\nimport os\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\n\nIMAGE_SHAPE = (224, 224)                                      #Make predictions using ready made model (without training).\n\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n])\n\ngold_fish = Image.open(\"goldfish.jpg\").resize(IMAGE_SHAPE)\ngold_fish = np.array(gold_fish)/255.0\n\ngold_fish[np.newaxis, ...]\nresult = classifier.predict(gold_fish[np.newaxis, ...])\n\npredicted_label_index = np.argmax(result)\npredicted_label_index\n\n# tf.keras.utils.get_file('ImageNetLabels.txt',\n#                         'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\nimage_labels = []\nwith open(\"ImageNetLabels.txt\", \"r\") as f:\n    image_labels = f.read().splitlines()\nimage_labels[:5]\n\nimage_labels[predicted_label_index]\n`.trim();\n\nconst flowers = `\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n\ndata_dir\n\nimport pathlib\ndata_dir = pathlib.Path(data_dir)\n\nlist(data_dir.glob('*/*.jpg'))[:5]\nimage_count = len(list(data_dir.glob('*/*.jpg')))\nprint(image_count)\n\nroses = list(data_dir.glob('roses/*'))\nroses[:5]\n\nPIL.Image.open(str(roses[1]))\n\ntulips = list(data_dir.glob('tulips/*'))\nPIL.Image.open(str(tulips[0]))\n`.trim();\n\nconst opencv = `\nflowers_images_dict = {\n  'roses': list(data_dir.glob('roses/*')),\n  'daisy': list(data_dir.glob('daisy/*')),\n  'dandelion': list(data_dir.glob('dandelion/*')),\n  'sunflowers': list(data_dir.glob('sunflowers/*')),\n  'tulips': list(data_dir.glob('tulips/*')),\n}\n\nflowers_labels_dict = {\n  'roses': 0,\n  'daisy': 1,\n  'dandelion': 2,\n  'sunflowers': 3,\n  'tulips': 4,\n}\n\nflowers_images_dict['roses'][:5]\nstr(flowers_images_dict['roses'][0])\n\nimg = cv2.imread(str(flowers_images_dict['roses'][0]))\ncv2.resize(img,(224,224)).shape\nX, y = [], []\n\nfor flower_name, images in flowers_images_dict.items():\n    for image in images:\n        img = cv2.imread(str(image))\n        resized_img = cv2.resize(img,(224,224))\n        X.append(resized_img)\n        y.append(flowers_labels_dict[flower_name])\n        \nX = np.array(X)\ny = np.array(y)\n`.trim();\n\nconst split = `\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nX_train_scaled = X_train / 255\nX_test_scaled = X_test / 255\n\n\nX[0].shape                                                #Make prediction using pre-trained model on new flowers dataset.\nIMAGE_SHAPE+(3,)\n\nx0_resized = cv2.resize(X[0], IMAGE_SHAPE)\nx1_resized = cv2.resize(X[1], IMAGE_SHAPE)\nx2_resized = cv2.resize(X[2], IMAGE_SHAPE)\n\nplt.axis('off')\nplt.imshow(X[0])\n\nplt.axis('off')\nplt.imshow(X[1])\n\nplt.axis('off')\nplt.imshow(X[2])\n\npredicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\npredicted = np.argmax(predicted, axis=1)\npredicted\n\nimage_labels[795]\n`.trim();\n\nconst images = `\nfeature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n\npretrained_model_without_top_layer = hub.KerasLayer(\n    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n    \nnum_of_flowers = 5\nmodel = tf.keras.Sequential([pretrained_model_without_top_layer, tf.keras.layers.Dense(num_of_flowers)])\n\nmodel.summary()\n\n\nmodel.compile(\n  optimizer=\"adam\",\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['acc'])\n\nmodel.fit(X_train_scaled, y_train, epochs=5)\n\nmodel.evaluate(X_test_scaled,y_test)\n`.trim();\n\n\n\nclass Transfer extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Transfer learning in image classification</h3>\n              We will use transfer learning and take pre-trained model from google's Tensorflow Hub and re-train that\n              on flowers dataset.\n              <br />\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Load flowers dataset</h3>\n              <i>cache_dir indicates where to download data.</i>\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={flowers}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Read flowers images from disk into numpy array using opencv</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={opencv}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Train test split</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={split}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Now take pre-trained model and retrain it using flowers images</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={images}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\n\nexport default (withStyles(styles)(Transfer));\n"]},"metadata":{},"sourceType":"module"}
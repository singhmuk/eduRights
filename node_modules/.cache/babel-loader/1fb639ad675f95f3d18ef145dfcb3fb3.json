{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';import Neural from'../../../assets/AI/daisy2.JPG';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var redesign={height:200,width:500};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var childsFile=\"\\ndataset_url = \\\"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\\\"\\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\\ndata_dir\\n\\nimport pathlib\\ndata_dir = pathlib.Path(data_dir)\\n\\nlist(data_dir.glob('*/*.jpg'))[:5]\\n\\nimage_count = len(list(data_dir.glob('*/*.jpg')))\\n\\nroses = list(data_dir.glob('roses/*'))\\nroses[:5]\\n\\nPIL.Image.open(str(roses[1]))\\n\\ntulips = list(data_dir.glob('tulips/*'))\\nPIL.Image.open(str(tulips[0]))\\n\".trim();var flowers=\"\\nflowers_images_dict = {\\n  'roses': list(data_dir.glob('roses/*')),\\n  'daisy': list(data_dir.glob('daisy/*')),\\n  'dandelion': list(data_dir.glob('dandelion/*')),\\n  'sunflowers': list(data_dir.glob('sunflowers/*')),\\n  'tulips': list(data_dir.glob('tulips/*')),\\n}\\n\\n\\nflowers_labels_dict = {\\n  'roses': 0,\\n  'daisy': 1,\\n  'dandelion': 2,\\n  'sunflowers': 3,\\n  'tulips': 4,\\n}\\n\\nflowers_images_dict['roses'][:5]\\n\\nstr(flowers_images_dict['roses'][0])\\nimg = cv2.imread(str(flowers_images_dict['roses'][0]))\\n\\ncv2.resize(img,(180,180)).shape\\nX, y = [], []\\n\\nfor flower_name, images in flowers_images_dict.items():\\n    for image in images:\\n        img = cv2.imread(str(image))\\n        resized_img = cv2.resize(img,(180,180))\\n        X.append(resized_img)\\n        y.append(flowers_labels_dict[flower_name])\\n        \\n        \\nX = np.array(X)\\ny = np.array(y)\\n\".trim();var split=\"\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\\n\\nX_train_scaled = X_train / 255                                                            #Preprocessing: scale images.\\nX_test_scaled = X_test / 255\\n\".trim();var convolutional=\"\\nnum_classes = 5\\n\\nmodel = Sequential([\\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\\n  layers.MaxPooling2D(),\\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\\n  layers.MaxPooling2D(),\\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\\n  layers.MaxPooling2D(),\\n  layers.Flatten(),\\n  layers.Dense(128, activation='relu'),\\n  layers.Dense(num_classes)\\n])\\n\\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\\n              \\nmodel.fit(X_train_scaled, y_train, epochs=30) \\nmodel.evaluate(X_test_scaled,y_test) \\n\\npredictions = model.predict(X_test_scaled)\\nscore = tf.nn.softmax(predictions[0])\\nnp.argmax(score)\\n\\ny_test[0]\\n\".trim();var augmentation=\"\\ndata_augmentation = keras.Sequential(\\n  [\\n    layers.experimental.preprocessing.RandomFlip(\\\"horizontal\\\", input_shape=(img_height, img_width, 3)),\\n    layers.experimental.preprocessing.RandomRotation(0.1),\\n    layers.experimental.preprocessing.RandomZoom(0.1),\\n  ]\\n)\\n\\n\\nplt.axis('off')                                                                                   #Original Image.\\nplt.imshow(X[0])                     \\n\".trim();var generated=\"\\nplt.axis('off')\\nplt.imshow(data_augmentation(X)[0].numpy().astype(\\\"uint8\\\"))\\n\\nnum_classes = 5\\n\\nmodel = Sequential([\\n  data_augmentation,\\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\\n  layers.MaxPooling2D(),\\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\\n  layers.MaxPooling2D(),\\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\\n  layers.MaxPooling2D(),\\n  layers.Dropout(0.2),\\n  layers.Flatten(),\\n  layers.Dense(128, activation='relu'),\\n  layers.Dense(num_classes)\\n])\\n\\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\\n              \\nmodel.fit(X_train_scaled, y_train, epochs=30)  \\nmodel.evaluate(X_test_scaled,y_test)\\n\".trim();var dataAugmentation=/*#__PURE__*/function(_Component){_inherits(dataAugmentation,_Component);function dataAugmentation(){_classCallCheck(this,dataAugmentation);return _possibleConstructorReturn(this,_getPrototypeOf(dataAugmentation).apply(this,arguments));}_createClass(dataAugmentation,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"Data Augmentation To Address Overfitting In Flower Classification CNN\"),\"Data augmentation is a process of generating new training samples from current training dataset using transformations such as zoom, rotations, change in contrast etc.\",React.createElement(\"br\",null),React.createElement(\"i\",null,\"We build a CNN to classify flower images. Also see how our model overfits and overfitting can be addressed using data augmentation.\"),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"4 new training samples are generated from original sample using different transformations.\"),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"img\",{src:Neural,alt:\"Theata\",className:\"responsive2\",style:redesign}),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Load flowers dataset.\"),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:childsFile,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Read flowers images from disk into numpy array using opencv.\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:flowers,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Train test split\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:split,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Build convolutional neural network and train it.\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:convolutional,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Improve Test Accuracy Using Data Augmentation\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:augmentation,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Newly generated training sample using data augmentation\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:generated,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"i\",null,\"By using data augmentation and drop out layer the accuracy of test set predictions is increased to 73.74%.\")))));}}]);return dataAugmentation;}(Component);export default withStyles(styles)(dataAugmentation);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/angularjs/deepAngularjs/data_augmentation.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","Neural","titles","backgroundColor","padding","fontSize","redesign","height","width","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","childsFile","trim","flowers","split","convolutional","augmentation","generated","dataAugmentation","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAEA,MAAOC,CAAAA,MAAP,KAAmB,+BAAnB,CAEA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,QAAQ,CAAG,CACfC,MAAM,CAAE,GADO,CAEfC,KAAK,CAAE,GAFQ,CAAjB,CAKA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACvBC,KAAK,CAAE,CACLC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH,CAELT,OAAO,CAAEM,KAAK,CAACG,OAAN,CAAc,CAAd,CAFJ,CADgB,CAKvBC,QAAQ,CAAE,CACRF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADA,CALa,CAQvBE,SAAS,CAAE,CACTC,SAAS,CAAE,QADF,CARY,CAAL,EAApB,CAcA,GAAMC,CAAAA,UAAU,CAAG,ihBAmBjBC,IAnBiB,EAAnB,CAqBA,GAAMC,CAAAA,OAAO,CAAG,i3BAoCdD,IApCc,EAAhB,CAsCA,GAAME,CAAAA,KAAK,CAAG,+RAMZF,IANY,EAAd,CAQA,GAAMG,CAAAA,aAAa,CAAG,yuBAyBpBH,IAzBoB,EAAtB,CA2BA,GAAMI,CAAAA,YAAY,CAAG,ubAYnBJ,IAZmB,EAArB,CAcA,GAAMK,CAAAA,SAAS,CAAG,qvBAwBhBL,IAxBgB,EAAlB,C,GA4BMM,CAAAA,gB,wUACgB,CAClBC,UAAU,CAAC,iBAAM/B,CAAAA,KAAK,CAACgC,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACD,C,uCACQ,IACCC,CAAAA,OADD,CACa,KAAKC,KADlB,CACCD,OADD,CAEP,MACE,qBAAC,IAAD,EAAM,SAAS,KAAf,EACE,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAAChB,KAA1B,EACE,8BAAI,oBAAC,OAAD,MAAJ,CADF,CADF,CADF,CAME,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEgB,OAAO,CAAChB,KAA1B,EACE,oBAAC,IAAD,MACE,sGADF,0KAIE,8BAJF,CAKE,mKALF,CAME,8BANF,CAOE,8BAPF,CASE,0HATF,CAUE,8BAVF,CAWE,8BAXF,CAYE,2BAAK,GAAG,CAAEV,MAAV,CAAkB,GAAG,CAAC,QAAtB,CAA+B,SAAS,CAAC,aAAzC,CAAuD,KAAK,CAAEK,QAA9D,EAZF,CAaE,8BAbF,CAcE,8BAdF,CAeE,qDAfF,CAgBE,8BAhBF,CAiBE,2BAAK,KAAK,CAAEJ,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEe,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAjBF,CAwBE,8BAxBF,CA0BE,6FA1BF,CA2BE,2BAAK,KAAK,CAAEf,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEiB,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA3BF,CAkCE,8BAlCF,CAoCE,iDApCF,CAqCE,2BAAK,KAAK,CAAEjB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEkB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CArCF,CA4CE,8BA5CF,CA8CE,iFA9CF,CA+CE,2BAAK,KAAK,CAAElB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEmB,aADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA/CF,CAsDE,8BAtDF,CAwDE,8EAxDF,CAyDE,2BAAK,KAAK,CAAEnB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEoB,YADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAzDF,CAgEE,8BAhEF,CAkEE,wFAlEF,CAmEE,2BAAK,KAAK,CAAEpB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEqB,SADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAnEF,CA0EE,8BA1EF,CA2EE,0IA3EF,CADF,CADF,CANF,CADF,CA0FD,C,8BAhG4B9B,S,EAoG/B,cAAgBI,CAAAA,UAAU,CAACY,MAAD,CAAV,CAAmBe,gBAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\nimport Neural from '../../../assets/AI/daisy2.JPG'\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst redesign = {\n  height: 200,\n  width: 500\n}\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst childsFile = `\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\ndata_dir\n\nimport pathlib\ndata_dir = pathlib.Path(data_dir)\n\nlist(data_dir.glob('*/*.jpg'))[:5]\n\nimage_count = len(list(data_dir.glob('*/*.jpg')))\n\nroses = list(data_dir.glob('roses/*'))\nroses[:5]\n\nPIL.Image.open(str(roses[1]))\n\ntulips = list(data_dir.glob('tulips/*'))\nPIL.Image.open(str(tulips[0]))\n`.trim();\n\nconst flowers = `\nflowers_images_dict = {\n  'roses': list(data_dir.glob('roses/*')),\n  'daisy': list(data_dir.glob('daisy/*')),\n  'dandelion': list(data_dir.glob('dandelion/*')),\n  'sunflowers': list(data_dir.glob('sunflowers/*')),\n  'tulips': list(data_dir.glob('tulips/*')),\n}\n\n\nflowers_labels_dict = {\n  'roses': 0,\n  'daisy': 1,\n  'dandelion': 2,\n  'sunflowers': 3,\n  'tulips': 4,\n}\n\nflowers_images_dict['roses'][:5]\n\nstr(flowers_images_dict['roses'][0])\nimg = cv2.imread(str(flowers_images_dict['roses'][0]))\n\ncv2.resize(img,(180,180)).shape\nX, y = [], []\n\nfor flower_name, images in flowers_images_dict.items():\n    for image in images:\n        img = cv2.imread(str(image))\n        resized_img = cv2.resize(img,(180,180))\n        X.append(resized_img)\n        y.append(flowers_labels_dict[flower_name])\n        \n        \nX = np.array(X)\ny = np.array(y)\n`.trim();\n\nconst split = `\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nX_train_scaled = X_train / 255                                                            #Preprocessing: scale images.\nX_test_scaled = X_test / 255\n`.trim();\n\nconst convolutional = `\nnum_classes = 5\n\nmodel = Sequential([\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n              \nmodel.fit(X_train_scaled, y_train, epochs=30) \nmodel.evaluate(X_test_scaled,y_test) \n\npredictions = model.predict(X_test_scaled)\nscore = tf.nn.softmax(predictions[0])\nnp.argmax(score)\n\ny_test[0]\n`.trim();\n\nconst augmentation = `\ndata_augmentation = keras.Sequential(\n  [\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)\n\n\nplt.axis('off')                                                                                   #Original Image.\nplt.imshow(X[0])                     \n`.trim();\n\nconst generated = `\nplt.axis('off')\nplt.imshow(data_augmentation(X)[0].numpy().astype(\"uint8\"))\n\nnum_classes = 5\n\nmodel = Sequential([\n  data_augmentation,\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n              \nmodel.fit(X_train_scaled, y_train, epochs=30)  \nmodel.evaluate(X_test_scaled,y_test)\n`.trim();\n\n\n\nclass dataAugmentation extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Data Augmentation To Address Overfitting In Flower Classification CNN</h3>\n              Data augmentation is a process of generating new training samples from current training dataset using transformations such as zoom, rotations,\n              change in contrast etc.\n              <br />\n              <i>We build a CNN to classify flower images. Also see how our model overfits and overfitting can be addressed using data augmentation.</i>\n              <br />\n              <br />\n\n              <b>4 new training samples are generated from original sample using different transformations.</b>\n              <br />\n              <br />\n              <img src={Neural} alt=\"Theata\" className=\"responsive2\" style={redesign} />\n              <br />\n              <br />\n              <b>Load flowers dataset.</b>\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Read flowers images from disk into numpy array using opencv.</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={flowers}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Train test split</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={split}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Build convolutional neural network and train it.</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={convolutional}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Improve Test Accuracy Using Data Augmentation</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={augmentation}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Newly generated training sample using data augmentation</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={generated}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <i>By using data augmentation and drop out layer the accuracy of test set predictions is increased to 73.74%.</i>\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\n\nexport default (withStyles(styles)(dataAugmentation));\n"]},"metadata":{},"sourceType":"module"}
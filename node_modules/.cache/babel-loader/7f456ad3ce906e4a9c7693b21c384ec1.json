{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var prediction=\"\\ndf = pd.read_csv(\\\"customer_churn.csv\\\")\\n\\ndf.Churn.value_counts()\\n517400/ df.shape[0]\\n\\ndf.drop('customerID',axis='columns',inplace=True)\\n\\ndf.TotalCharges.values\\npd.to_numeric(df.TotalCharges,errors='coerce').isnull()\\ndf[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()]\\n\\ndf.iloc[488].TotalCharges\\ndf[df.TotalCharges!=' '].shape\\ndf1 = df[df.TotalCharges!=' ']\\n\\ndf1.TotalCharges = pd.to_numeric(df1.TotalCharges)\\ndf1.TotalCharges.values\\ndf1[df1.Churn=='No']\\n\".trim();var visualization=\"\\ntenure_churn_no = df1[df1.Churn=='No'].tenure\\ntenure_churn_yes = df1[df1.Churn=='Yes'].tenure\\n\\nplt.xlabel(\\\"tenure\\\")\\nplt.ylabel(\\\"Number Of Customers\\\")\\nplt.title(\\\"Customer Churn Prediction Visualiztion\\\")\\n\\nblood_sugar_men = [113, 85, 90, 150, 149, 88, 93, 115, 135, 80, 77, 82, 129]\\nblood_sugar_women = [67, 98, 89, 120, 133, 150, 84, 69, 89, 79, 120, 112, 100]\\n\\nplt.hist([tenure_churn_yes, tenure_churn_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])\\nplt.legend()\\n\\n\\nmc_churn_no = df1[df1.Churn=='No'].MonthlyCharges      \\nmc_churn_yes = df1[df1.Churn=='Yes'].MonthlyCharges      \\n\\nplt.xlabel(\\\"Monthly Charges\\\")\\nplt.ylabel(\\\"Number Of Customers\\\")\\nplt.title(\\\"Customer Churn Prediction Visualiztion\\\")\\n\\nblood_sugar_men = [113, 85, 90, 150, 149, 88, 93, 115, 135, 80, 77, 82, 129]\\nblood_sugar_women = [67, 98, 89, 120, 133, 150, 84, 69, 89, 79, 120, 112, 100]\\n\\nplt.hist([mc_churn_yes, mc_churn_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])\\nplt.legend()\\n\\n\\ndef print_unique_col_values(df):\\n       for column in df:\\n            if df[column].dtypes=='object':\\n                print(f'{column}: {df[column].unique()}') \\n                \\nprint_unique_col_values(df1)\\n\\ndf1.replace('No internet service','No',inplace=True)\\ndf1.replace('No phone service','No',inplace=True)\\nprint_unique_col_values(df1)\\n\\nyes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\\n                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\\nfor col in yes_no_columns:\\n    df1[col].replace({'Yes': 1,'No': 0},inplace=True)\\n    \\n    \\nfor col in df1:\\n    print(f'{col}: {df1[col].unique()}') \\n    \\ndf1['gender'].replace({'Female':1,'Male':0},inplace=True)\\ndf1.gender.unique()\\n\".trim();var categorical=\"\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\ndf2 = pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])\\n\\ncols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\\n\\nscaler = MinMaxScaler()\\ndf2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])\\n\\nfor col in df2:\\n    print(f'{col}: {df2[col].unique()}')\\n\".trim();var split=\"\\nX = df2.drop('Churn',axis='columns')\\ny = testLabels = df2.Churn.astype(np.float32)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\\n\\ny_train.value_counts()\\n5163/1869\\nlen(X_train.columns)\\n\".trim();var keras=\"\\nfrom tensorflow_addons import losses\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nfrom sklearn.metrics import confusion_matrix , classification_report\\n\\ndef ANN(X_train, y_train, X_test, y_test, loss, weights):\\n    model = keras.Sequential([\\n        keras.layers.Dense(26, input_dim=26, activation='relu'),\\n        keras.layers.Dense(15, activation='relu'),\\n        keras.layers.Dense(1, activation='sigmoid')\\n    ])\\n\\n    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\\n    \\n    if weights == -1:\\n        model.fit(X_train, y_train, epochs=100)\\n    else:\\n        model.fit(X_train, y_train, epochs=100, class_weight = weights)\\n    \\n    print(model.evaluate(X_test, y_test))\\n    \\n    y_preds = model.predict(X_test)\\n    y_preds = np.round(y_preds)\\n    \\n    print(\\\"Classification Report:\\\", classification_report(y_test, y_preds))\\n    \\n    return y_preds\\n    \\ny_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\\n\".trim();var pipes=\"\\n# Method 1: Undersampling\\ncount_class_0, count_class_1 = df1.Churn.value_counts()\\n\\ndf_class_0 = df2[df2['Churn'] == 0]\\ndf_class_1 = df2[df2['Churn'] == 1]\\n\\ndf_class_0_under = df_class_0.sample(count_class_1)\\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\\n\\nprint('Random under-sampling:')\\nprint(df_test_under.Churn.value_counts())\\n\\nX = df_test_under.drop('Churn',axis='columns')\\ny = df_test_under['Churn']\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\\ny_train.value_counts()\\n\\ny_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\\n\".trim();// const pipes = ``.trim();\nvar Imbalanced=/*#__PURE__*/function(_Component){_inherits(Imbalanced,_Component);function Imbalanced(){_classCallCheck(this,Imbalanced);return _possibleConstructorReturn(this,_getPrototypeOf(Imbalanced).apply(this,arguments));}_createClass(Imbalanced,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"Handling imbalanced data in customer churn prediction\"),React.createElement(\"b\",null,\"Handling imbalanced dataset:\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1. Under sampling majority class.\"),React.createElement(\"li\",null,\"2. Over sampling minority class by duplication.\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Generate new sample from current sample by simply duplicating them.\")),React.createElement(\"br\",null),React.createElement(\"li\",null,\"3. Over sampling minority class using SMOTE.\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Generate synthetic example using KNN aglo.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"SMOTE: \"),\"Synthetic Minority Over-sampling Technique.\")),React.createElement(\"br\",null),React.createElement(\"li\",null,\"Ensemble Method.\"),React.createElement(\"li\",null,\"Focal loss.\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Focal loss will penalize majority samples during loss calculation and give weight to minority class samples.\"))),React.createElement(\"br\",null),React.createElement(\"i\",null,\"Customer churn prediction is to measure why customers are leaving a business. Looking at customer churn in telecom business. We will build a deep learning model to predict the churn and use precision,recall, f1-score to measure performance of our model. We will then handle imbalance in data using various techniques and improve f1-score.\"),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:prediction,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Data Visualization\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:visualization,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"One hot encoding for categorical columns\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:categorical,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Train test split\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:split,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Build a model (ANN) in tensorflow/ keras\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:keras,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Mitigating Skewdness of Data\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:pipes,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"i\",null,\"Printing Classification in the last, Scroll down till the last epoch to watch the classification report.\")))));}}]);return Imbalanced;}(Component);export default withStyles(styles)(Imbalanced);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/angularjs/deepAngularjs/imbalanced2.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","titles","backgroundColor","padding","fontSize","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","prediction","trim","visualization","categorical","split","keras","pipes","Imbalanced","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAGA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACvBC,KAAK,CAAE,CACLC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH,CAELN,OAAO,CAAEG,KAAK,CAACG,OAAN,CAAc,CAAd,CAFJ,CADgB,CAKvBC,QAAQ,CAAE,CACRF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADA,CALa,CAQvBE,SAAS,CAAE,CACTC,SAAS,CAAE,QADF,CARY,CAAL,EAApB,CAcA,GAAMC,CAAAA,UAAU,CAAG,seAmBjBC,IAnBiB,EAAnB,CAqBA,GAAMC,CAAAA,aAAa,CAAG,6zDAmDpBD,IAnDoB,EAAtB,CAqDA,GAAME,CAAAA,WAAW,CAAG,oWAYlBF,IAZkB,EAApB,CAcA,GAAMG,CAAAA,KAAK,CAAG,8PASZH,IATY,EAAd,CAWA,GAAMI,CAAAA,KAAK,CAAG,g+BA8BZJ,IA9BY,EAAd,CAgCA,GAAMK,CAAAA,KAAK,CAAG,0oBAoBZL,IApBY,EAAd,CAsBA;GAGMM,CAAAA,U,0SACgB,CAClBC,UAAU,CAAC,iBAAM3B,CAAAA,KAAK,CAAC4B,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACD,C,uCACQ,IACCC,CAAAA,OADD,CACa,KAAKC,KADlB,CACCD,OADD,CAEP,MACE,qBAAC,IAAD,EAAM,SAAS,KAAf,EACE,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAAChB,KAA1B,EACE,8BAAI,oBAAC,OAAD,MAAJ,CADF,CADF,CADF,CAME,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEgB,OAAO,CAAChB,KAA1B,EACE,oBAAC,IAAD,MACE,sFADF,CAEE,4DAFF,CAGE,8BACE,kEADF,CAEE,gFAFF,CAGE,8BACE,oGADF,CAHF,CAME,8BANF,CAOE,6EAPF,CAQE,8BACE,2EADF,CAEE,8BAAI,uCAAJ,+CAFF,CARF,CAYE,8BAZF,CAaE,iDAbF,CAcE,4CAdF,CAeE,8BACE,6IADF,CAfF,CAHF,CAsBE,8BAtBF,CAwBE,kXAxBF,CA2BE,8BA3BF,CA4BE,2BAAK,KAAK,CAAEN,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEY,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA5BF,CAmCE,8BAnCF,CAqCE,mDArCF,CAsCE,2BAAK,KAAK,CAAEZ,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEc,aADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAtCF,CA6CE,8BA7CF,CA+CE,yEA/CF,CAgDE,2BAAK,KAAK,CAAEd,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEe,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAhDF,CAuDE,8BAvDF,CAyDE,iDAzDF,CA0DE,2BAAK,KAAK,CAAEf,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEgB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA1DF,CAiEE,8BAjEF,CAmEE,yEAnEF,CAoEE,2BAAK,KAAK,CAAEhB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEiB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CApEF,CA2EE,8BA3EF,CA6EE,6DA7EF,CA8EE,2BAAK,KAAK,CAAEjB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEkB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA9EF,CAqFE,8BArFF,CAsFE,wIAtFF,CADF,CADF,CANF,CADF,CAgHD,C,wBAtHsB1B,S,EA0HzB,cAAgBI,CAAAA,UAAU,CAACQ,MAAD,CAAV,CAAmBe,UAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst prediction = `\ndf = pd.read_csv(\"customer_churn.csv\")\n\ndf.Churn.value_counts()\n517400/ df.shape[0]\n\ndf.drop('customerID',axis='columns',inplace=True)\n\ndf.TotalCharges.values\npd.to_numeric(df.TotalCharges,errors='coerce').isnull()\ndf[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()]\n\ndf.iloc[488].TotalCharges\ndf[df.TotalCharges!=' '].shape\ndf1 = df[df.TotalCharges!=' ']\n\ndf1.TotalCharges = pd.to_numeric(df1.TotalCharges)\ndf1.TotalCharges.values\ndf1[df1.Churn=='No']\n`.trim();\n\nconst visualization = `\ntenure_churn_no = df1[df1.Churn=='No'].tenure\ntenure_churn_yes = df1[df1.Churn=='Yes'].tenure\n\nplt.xlabel(\"tenure\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nblood_sugar_men = [113, 85, 90, 150, 149, 88, 93, 115, 135, 80, 77, 82, 129]\nblood_sugar_women = [67, 98, 89, 120, 133, 150, 84, 69, 89, 79, 120, 112, 100]\n\nplt.hist([tenure_churn_yes, tenure_churn_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])\nplt.legend()\n\n\nmc_churn_no = df1[df1.Churn=='No'].MonthlyCharges      \nmc_churn_yes = df1[df1.Churn=='Yes'].MonthlyCharges      \n\nplt.xlabel(\"Monthly Charges\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Churn Prediction Visualiztion\")\n\nblood_sugar_men = [113, 85, 90, 150, 149, 88, 93, 115, 135, 80, 77, 82, 129]\nblood_sugar_women = [67, 98, 89, 120, 133, 150, 84, 69, 89, 79, 120, 112, 100]\n\nplt.hist([mc_churn_yes, mc_churn_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])\nplt.legend()\n\n\ndef print_unique_col_values(df):\n       for column in df:\n            if df[column].dtypes=='object':\n                print(f'{column}: {df[column].unique()}') \n                \nprint_unique_col_values(df1)\n\ndf1.replace('No internet service','No',inplace=True)\ndf1.replace('No phone service','No',inplace=True)\nprint_unique_col_values(df1)\n\nyes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\n                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\nfor col in yes_no_columns:\n    df1[col].replace({'Yes': 1,'No': 0},inplace=True)\n    \n    \nfor col in df1:\n    print(f'{col}: {df1[col].unique()}') \n    \ndf1['gender'].replace({'Female':1,'Male':0},inplace=True)\ndf1.gender.unique()\n`.trim();\n\nconst categorical = `\nfrom sklearn.preprocessing import MinMaxScaler\n\ndf2 = pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])\n\ncols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n\nscaler = MinMaxScaler()\ndf2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])\n\nfor col in df2:\n    print(f'{col}: {df2[col].unique()}')\n`.trim();\n\nconst split = `\nX = df2.drop('Churn',axis='columns')\ny = testLabels = df2.Churn.astype(np.float32)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n\ny_train.value_counts()\n5163/1869\nlen(X_train.columns)\n`.trim();\n\nconst keras = `\nfrom tensorflow_addons import losses\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.metrics import confusion_matrix , classification_report\n\ndef ANN(X_train, y_train, X_test, y_test, loss, weights):\n    model = keras.Sequential([\n        keras.layers.Dense(26, input_dim=26, activation='relu'),\n        keras.layers.Dense(15, activation='relu'),\n        keras.layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n    \n    if weights == -1:\n        model.fit(X_train, y_train, epochs=100)\n    else:\n        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n    \n    print(model.evaluate(X_test, y_test))\n    \n    y_preds = model.predict(X_test)\n    y_preds = np.round(y_preds)\n    \n    print(\"Classification Report:\", classification_report(y_test, y_preds))\n    \n    return y_preds\n    \ny_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n`.trim();\n\nconst pipes = `\n# Method 1: Undersampling\ncount_class_0, count_class_1 = df1.Churn.value_counts()\n\ndf_class_0 = df2[df2['Churn'] == 0]\ndf_class_1 = df2[df2['Churn'] == 1]\n\ndf_class_0_under = df_class_0.sample(count_class_1)\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nprint('Random under-sampling:')\nprint(df_test_under.Churn.value_counts())\n\nX = df_test_under.drop('Churn',axis='columns')\ny = df_test_under['Churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\ny_train.value_counts()\n\ny_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n`.trim();\n\n// const pipes = ``.trim();\n\n\nclass Imbalanced extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Handling imbalanced data in customer churn prediction</h3>\n              <b>Handling imbalanced dataset:</b>\n              <ul>\n                <li>1. Under sampling majority class.</li>\n                <li>2. Over sampling minority class by duplication.</li>\n                <ul>\n                  <li>Generate new sample from current sample by simply duplicating them.</li>\n                </ul>\n                <br />\n                <li>3. Over sampling minority class using SMOTE.</li>\n                <ul>\n                  <li>Generate synthetic example using KNN aglo.</li>\n                  <li><b>SMOTE: </b>Synthetic Minority Over-sampling Technique.</li>\n                </ul>\n                <br />\n                <li>Ensemble Method.</li>\n                <li>Focal loss.</li>\n                <ul>\n                  <li>Focal loss will penalize majority samples during loss calculation and give weight to minority class samples.</li>\n                </ul>\n              </ul>\n              <br />\n\n              <i>Customer churn prediction is to measure why customers are leaving a business. Looking at customer churn in telecom business.\n                We will build a deep learning model to predict the churn and use precision,recall, f1-score to measure performance of our model.\n                We will then handle imbalance in data using various techniques and improve f1-score.</i>\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={prediction}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Data Visualization</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={visualization}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>One hot encoding for categorical columns</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={categorical}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Train test split</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={split}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Build a model (ANN) in tensorflow/ keras</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={keras}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Mitigating Skewdness of Data</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={pipes}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <i>Printing Classification in the last, Scroll down till the last epoch to watch the\n                classification report.</i>\n              {/* <br />\n\n              <h3></h3>\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div> */}\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\n\nexport default (withStyles(styles)(Imbalanced));\n"]},"metadata":{},"sourceType":"module"}
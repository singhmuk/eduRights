{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var Series=\"\\na = [1, 7, 2]\\n\\nmyvar = pd.Series(a)\\nprint(myvar)\".trim();var dataFrames=\"\\ndata = {\\n  \\\"calories\\\": [420, 380, 390],\\n  \\\"duration\\\": [50, 40, 45]\\n}\\n\\ndf = pd.DataFrame(data)\\ndf\\n\\n\\ndf.loc[0]                                                                             #refer to the row index.\\ndf = pd.DataFrame(data, index = [\\\"day1\\\", \\\"day2\\\", \\\"day3\\\"])                             #name your own indexes.\\ndf.loc[\\\"day2\\\"]                                                                        #refer to the named index:\\n\".trim();var readJson=\"\\ndf = pd.read_json('data.json')\\n\\nprint(df.to_string()) \\n\".trim();var cleanData=\"\\ndf.dropna()                                                             //Remove rows that contain empty cells.\\ndf.fillna(130, inplace = True)                                          //Replace NULL values with the number 130.\\ndf[\\\"Calories\\\"].fillna(130, inplace = True)                              //Replace Only For Specified Columns.\\n\\nx = df[\\\"Calories\\\"].mean()                                               //Find MEAN, and replace any empty values with it.\\ndf[\\\"Calories\\\"].fillna(x, inplace = True)\\n\".trim();var wrongs=\"\\ndf['Date'] = pd.to_datetime(df['Date'])                                 //Convert to date.\\ndf.dropna(subset=['Date'], inplace = True)                              //Remove rows with a NULL value in the \\\"Date\\\" column.\\n\".trim();var fixings=\"\\nfor x in df.index:\\n  if df.loc[x, \\\"Duration\\\"] > 120:\\n    df.loc[x, \\\"Duration\\\"] = 120\\n\\n    \\ndf.drop_duplicates(inplace = True)                                      //Remove all duplicates.\\n\".trim();var correlations=\"\\ndf.corr()                                                               //Relationship between the columns.\\n\".trim();var Plotting=\"\\ndf.plot()\\nplt.show()                                                         \\n\\n\\ndf.plot(kind = 'scatter', x = 'Duration', y = 'Calories')\\n\\ndf[\\\"Duration\\\"].plot(kind = 'hist')\\n\".trim();var data_=\"\\nimport pandas as pd\\nX = music_data = pd.read_csv('music.csv')\\nX \\ny = music_data['genre']\\n\".trim();var preadicting=\"\\nimport pandas as pd \\nfrom sklearn.tree import DecisionTreeClassifier\\n\\nmusic_data = pd.read_csv('music.csv')\\nx = music_data.drop(columns=['genre'])\\ny = music_data['genre']\\n\\nmodel = DecisionTreeClassifier()\\nmodel.fit(x, y)\\nmusic_data\\n\\npredictions = model.predict([21, 1], [22, 0])\\npredictions\\n\".trim();var dataFramesd=\"\\ndf = pd.read_csv(\\\"pandas.csv\\\")\\npd.read_csv(\\\"pandas.csv\\\", skiprows=1)\\npd.read_csv('pandas.csv', nrows=2)\\npd.read_csv(\\\"pandas.csv\\\", header=1)                                                       #skiprows and header are same\\npd.read_csv(\\\"pandas.csv\\\", na_values=[\\\"n.a.\\\", \\\"not available\\\"])\\npd.read_csv(\\\"pandas.csv\\\", header=None, names = [\\\"ticker\\\",\\\"eps\\\",\\\"revenue\\\",\\\"people\\\"])\\npd.read_csv('pandas.csv',header=0, parse_dates=[0], index_col=0, squeeze=True)\\npd.read_csv('pandas.csv',  na_values={'eps': ['not available'],'revenue': [-1],'people': ['not available','n.a.']})\\n    \\n    \\ndf.to_csv(\\\"new.csv\\\", index=False)                                                             #Write to CSV\\ndf.to_csv(\\\"new.csv\\\", columns=[\\\"tickers\\\",\\\"price\\\"], index=False)\\n\\npd.read_excel(\\\"stock_data.xlsx\\\",\\\"Sheet1\\\")                                                     #Read Excel\\ndf.to_excel(\\\"new.xlsx\\\", sheet_name=\\\"stocks\\\", index=False, startrow=2, startcol=1)             #Write to Excel\\n\\n\\ndf.to_string()                                                                                #Print the entire DataFrame.\\ndf=pd.options.display.max_rows                                                                #Maximum returned rows\\ndf=pd.options.display.max_rows = 9999                       #Increase max. number of rows to display the entire DataFrame\\n\\n\".trim();var sheets=\"\\ndf_stocks = pd.DataFrame({\\n    'tickers': ['GOOGL', 'WMT', 'MSFT'],\\n    'price': [845, 65, 64 ],\\n    'pe': [30.37, 14.26, 30.97],\\n    'eps': [27.82, 4.61, 2.12]\\n})\\n\\ndf_weather =  pd.DataFrame({\\n    'day': ['1/1/2017','1/2/2017','1/3/2017'],\\n    'temperature': [32,35,28],\\n    'event': ['Rain', 'Sunny', 'Snow']\\n})\\n\\n\\nwith pd.ExcelWriter('stocks_weather.xlsx') as writer:\\n    df_stocks.to_excel(writer, sheet_name=\\\"stocks\\\")\\n    df_weather.to_excel(writer, sheet_name=\\\"weather\\\")\\n\".trim();var interpolate=\"\\ndf.fillna(0)                                                                          #fillna\\ndf.fillna(130, inplace = True)                                                        #Replace NULL values with the 130.\\ndf[\\\"Calories\\\"].fillna(130, inplace = True)                                            #Replace Only For Specified Columns.\\n\\n\\nnew_df = df.fillna(method=\\\"ffill\\\")                                                    #determine how to fill na values.\\nnew_df = df.fillna(method=\\\"bfill\\\")\\n\\n\\n#Use of axis\\ndf.fillna(method=\\\"bfill\\\", axis=\\\"columns\\\")                                             # axis is either \\\"index\\\" or \\\"columns\\\"\\ndf.fillna(method=\\\"ffill\\\",limit=1)                                                     #limit parameter\\ndf.interpolate()                                                                      #interpolate\\ndf.interpolate(method=\\\"time\\\")\\n\\ndf.dropna()                                                                           #dropna\\ndf.drop_duplicates()\\n\\n\\n#Inserting Missing Dates\\ndt = pd.date_range(\\\"01-01-2017\\\",\\\"01-11-2017\\\")\\nidx = pd.DatetimeIndex(dt)\\ndf.reindex(idx)\\n\\n\\ndf.replace(-99999, value=np.NaN)                                                      #Handling Missing Data-replace method\\ndf.replace(to_replace=[-99999,-88888], value=0)                                       #Replacing list with single value\\ndf.replace({'temperature': -99999,'windspeed': -99999,'event': '0'}, np.nan)          #Replacing per column\\n          \\nnew_df = df.replace({-99999: np.nan, 'no event': 'Sunny', })                          #Replacing by using mapping\\ndf['area'][0] = 50                                                                    #Update data.\\n\\ndf=pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])                       #reindex\\n\\n\".trim();var windspeed=\"\\ndf.replace({'temperature': '[A-Za-z]', 'windspeed': '[a-z]'},'', regex=True) \\n\\n\\n3Replacing list with another list\\n    df = pd.DataFrame({\\n    'score': ['exceptional','average', 'good', 'poor', 'average', 'exceptional'],\\n    'student': ['rob', 'maya', 'parthiv', 'tom', 'julian', 'erica']\\n  })\\n\\n    df.replace(['poor', 'average', 'good', 'exceptional'], [1,2,3,4])\\n\".trim();var groupby=\"\\n    g.get_group('mumbai')\\n    g.max()\\n    g.min()\\n    g.mean()\\n    g.describe()\\n    g.size()\\n    g.count()\\n    g.plot()\\n\".trim();var temperature=\"\\ndef grouper(df, idx, col):\\n    if 80 <= df[col].loc[idx] <= 90:\\n        return '80-90'\\n    elif 50 <= df[col].loc[idx] <= 60:\\n        return '50-60'\\n    else:\\n        return 'others'\\n        \\ng = df.groupby(lambda x: grouper(df, x, 'temperature'))\\nfor key, d in g:\\nprint(\\\"Group by Key: {}\\n\\\".format(key))\\nprint(d)\\n\".trim();var concatenation=\"\\nindia_weather = pd.DataFrame({\\n  \\\"city\\\": [\\\"mumbai\\\",\\\"delhi\\\",\\\"banglore\\\"],\\n  \\\"temperature\\\": [32,45,30],\\n  \\\"humidity\\\": [80, 60, 78]\\n})\\n\\ndf = pd.concat([india_weather, us_weather])\\n\\n\\n#Concatenation Using Index.\\ntemperature_df = pd.DataFrame({\\n  \\\"city\\\": [\\\"mumbai\\\",\\\"delhi\\\",\\\"banglore\\\"],\\n  \\\"temperature\\\": [32,45,30],\\n}, index=[0,1,2])\\n\\npd.concat([temperature_df,windspeed_df],axis=1)\\n\\n\\n#Concatenate dataframe with series\\ns = pd.Series([\\\"Humid\\\",\\\"Dry\\\",\\\"Rain\\\"], name=\\\"event\\\")\\npd.concat([temperature_df,s],axis=1)\\n\".trim();var ignore=\"\\npd.concat([india_weather, us_weather], ignore_index=True)\\n\\n\\n#pivot\\ndf.pivot(index='city',columns='date')\\ndf.pivot(index='city',columns='date',values=\\\"humidity\\\")\\n\\nf.pivot_table(index=\\\"city\\\",columns=\\\"date\\\", margins=True,aggfunc=np.sum)                                 #margins\\ndf.pivot_table(index=pd.Grouper(freq='M',key='date'),columns='city')                                    #grouper\\n\\n\\n#Melt\\npd.melt(df, id_vars=[\\\"day\\\"], var_name='city', value_name='temperature')\\n\\n\\n#Reshape dataframe using stack/unstack\\ndf = pd.read_excel(\\\"stocks.xlsx\\\",header=[0,1])\\ndf.stack()\\ndf.stack(level=0)\\ndf_stacked.unstack()\\n\\n\\npd.read_excel(\\\"stocks_3_levels.xlsx\\\",header=[0,1,2])                                      #3 levels of column headers\\ndf2.stack(level=1)\\n\".trim();var crosstab=\"\\npd.crosstab(df.Nationality,df.Handedness)\\nMargins: pd.crosstab(df.Sex,df.Handedness, margins=True)\\nNormalize: pd.crosstab(df.Sex, df.Handedness, normalize='index')\\nAggfunc and Values: pd.crosstab(df.Sex, df.Handedness, values=df.Age, aggfunc=np.average)\\n\".trim();var specifics=\"\\n#Partial Date Index\\ndf['2017-06-30']\\ndf['2017-06'].Close.mean() \\n\\n\\n#Date Range\\ndf['2017-01-08':'2017-01-03']\\n\\ndf['Close'].resample('M').mean().head()                                                       #Resampling\\n\\n#Finding missing dates from datetimeindex\\ndaily_index = pd.date_range(start=\\\"6/1/2016\\\",end=\\\"6/30/2016\\\",freq='D')\\ndaily_index.difference(df.index)\\n\\n\\n#generating DatetimeIndex with periods argument\\npd.date_range('1/1/2011', periods=72, freq='H')\\n\".trim();var mergeDataframes=\"\\ndf1 = pd.DataFrame({\\n  \\\"city\\\": [\\\"new york\\\",\\\"chicago\\\",\\\"orlando\\\"],\\n  \\\"temperature\\\": [21,14,35],\\n})\\n\\ndf2 = pd.DataFrame({\\n  \\\"city\\\": [\\\"chicago\\\",\\\"new york\\\",\\\"orlando\\\"],\\n  \\\"humidity\\\": [65,68,75],\\n})\\n\\ndf3 = pd.merge(df1, df2, on=\\\"city\\\")\\n\\ndf3=pd.merge(df1,df2,on=\\\"city\\\",how=\\\"outer\\\",indicator=True)\\ndf3= pd.merge(df1,df2,on=\\\"city\\\",how=\\\"outer\\\", suffixes=('_first','_second'))\\n\".trim();var sqlalchemes=\"\\nimport pandas as pd\\nimport sqlalchemy\\n\\nengine = sqlalchemy.create_engine('mysql+pymysql://root:@localhost:3306/application')\\n\\ndf = pd.read_sql_table('customers',engine)\\n\\ndf = pd.read_sql_table('customers', engine, columns=[\\\"name\\\"])       #Read only selected columns\\n\\n\\n#Join two tables and read them in a dataframe using read_sql_query\\ndf = pd.read_sql_query(\\\"select id,name from customers\\\",engine)      \\n\\n\\nquery = '''\\n SELECT customers.name, customers.phone_number, orders.name, orders.amount\\n FROM customers INNER JOIN orders\\n ON customers.id=orders.customer_id\\n'''\\npd.read_sql(query,engine)                           #read_sql is a wrapper around read_sql_query and read_sql_table\\n\\ndf = pd.read_csv(\\\"customers.csv\\\")                   #Write to mysql database using to_sql\\n\\ndf = pd.read_csv(\\\"customers.csv\\\")\\n\\ndf.rename(columns={\\n    'Customer Name': 'name',\\n    'Customer Phone': 'phone_number'\\n}, inplace=True)\\n\\n\\n\\n#to_sql has different parameters such as chunksize which allows to write data in chunks. Useful when size is huge\\ndf.to_sql(\\n    name='customers', # database table name\\n    con=engine,\\n    if_exists='append',\\n    index=False                                                             \\n)                                   \\n\".trim();var pandasMethods=\"\\ndf.shape\\ndf.values\\ndf.head(10)\\ndf.describe()\\ndf.memory_usage()\\ndf.memory_usage(deep=True)\\ndf.loc[1:3]\\ndf.drop_duplicates()\\ndf.count()\\ndf.tail() \\ndf.info()\\ndf.sort_index()\\ndf.isna()                            #Returns a dataframe filled with boolean values with true indicating missing values.\\ndf.isnull().sum()                    #Calculate the number of missing values in each column.\\n\".trim();var pandasCopy=\"\\nimport numpy as np\\n\\nseries = pd.Series([1,2,np.nan,4])\\n\\nseries_2=series.copy(deep=True)\\nprint(series_2)\\n\".trim();var addRows=\"\\n#Add rows\\ndict = {'Name':['Martha', 'Tim', 'Rob', 'Georgia'],\\n        'Maths':[87, 91, 97, 95],\\n        'Science':[83, 99, 84, 76]\\n       }\\n  \\ndf = pd.DataFrame(dict)\\n  \\ndf2 = {'Name': 'Amy', 'Maths': 89, 'Science': 93}\\ndf = df.append(df2, ignore_index = True)\\ndf\\n\\ndf.reset_index()\\n\\n\\n\\n#add columns\\ndata = {'Name':['Martha', 'Tim', 'Rob', 'Georgia'],\\n        'Maths':[87, 91, 97, 95],\\n        'Science':[83, 99, 84, 76]\\n       }\\n\\ndf = pd.DataFrame(data)\\n\\naddress = ['Delhi', 'Bangalore', 'Chennai', 'Patna']\\n\\ndf['Address'] = address\\ndf\\n\\n\\n\\n#Add An Index\\ndata = pd.read_csv(\\\"areas.csv\\\")\\ndata.set_index(\\\"area\\\", inplace = True)                                                      #Setting area as index column\\ndata.head()\\n\".trim();var Pandas=/*#__PURE__*/function(_Component){_inherits(Pandas,_Component);function Pandas(){_classCallCheck(this,Pandas);return _possibleConstructorReturn(this,_getPrototypeOf(Pandas).apply(this,arguments));}_createClass(Pandas,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"Pandas (Data analysis)\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Provides functions to make working with structured or tabular data fast, easy, and expressive.\"),React.createElement(\"li\",null,\"Pandas allows us to analyze big data and make conclusions based on statistical theories.\"),React.createElement(\"li\",null,\"Primary objects is DataFrame and data.Series.\"),React.createElement(\"li\",null,\"Pandas find correlation between two/ more columns.\"),React.createElement(\"li\",null,\"Pandas is designed for working with tabular/ heterogeneous data.\"),React.createElement(\"li\",null,\"Pandas blends the high-performance, array-computing ideas of NumPy with the flexible data manipulation capabilities of spreadsheets and relational databases.\"),React.createElement(\"li\",null,\"Pandas has a special Categorical type for holding data that uses the integer-based categorical representation or encoding.\")),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Data Science/ Data Analytics: \"),\"Is a process of analyzing large set of data point to get answer on questions releted to that data set.\"),React.createElement(\"br\",null),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Data Munging/ Data Wrangling: \"),\"It's a Process of cleaning messy data.\")),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Dataframe\"),\"Different ways of creating dataframe:\",React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Using CSV\"),React.createElement(\"li\",null,\"Using excel\"),React.createElement(\"li\",null,\"From python dictionary\"),React.createElement(\"li\",null,\"From list of tuples\"),React.createElement(\"li\",null,\"From list of dictionaries\")),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"What Are The Most Important Features Of The Pandas Library?\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Data Alignment\"),React.createElement(\"li\",null,\"Merge and join\"),React.createElement(\"li\",null,\"Memory Efficient\"),React.createElement(\"li\",null,\"Time series\"),React.createElement(\"li\",null,\"Reshaping\")),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Explain Categorical Data in Pandas?\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Categorical data refers to real-time data that can be repetitive for instance, data values under categories such as country, gender, codes will always be repetitive.\"),React.createElement(\"li\",null,\"Categorical values also take only a limited and fixed number of possible values. \"),React.createElement(\"li\",null,\"Numerical operations cannot be performed on such data. All values of categorical data in pandas are either in categories or np.nan.\")),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Import file.\"),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:dataFramesd,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Methods:\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:pandasMethods,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Write two dataframes to two separate sheets in excel\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:sheets,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Handle Missing Data\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:interpolate,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Data Structures: \"),\"2\",React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Series: \"),\"Is a 1D array-like object containing a sequence of values and an associated array of data labels, called its index.\"),React.createElement(\"br\",null),React.createElement(\"li\",null,React.createElement(\"b\",null,\"DataFrame: \"),\"A DataFrame represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type (numeric, string, boolean, etc.). DataFrame has both a row and column index.\"),React.createElement(\"br\",null),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Panel: \"),\"Is a 3-dimensional DS and includes items such as major_axis and minor_axis.\")),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Series\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:Series,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"DataFrames\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:dataFrames,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"How can we create copy of series in Pandas?\"),\"copy() Make a deep copy, including a copy of the data and the indices. With deep=False neither the indices or the data are copied.\",React.createElement(\"br\",null),\"Note that when deep=True data is copied, actual python objects will not be copied recursively, only the reference to the object.\",React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:pandasCopy,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"How Will You Add An Index, Row, Or Column To A Dataframe In Pandas?\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\".loc (): \"),\"Is label based.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\".iloc (): \"),\"Integer based.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\".ix(): \"),\"Both label and integer based.\"),React.createElement(\"br\",null),React.createElement(\"li\",null,\"To add columns to the DataFrame, we can use .loc () or .iloc ().\")),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:addRows,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Pandas Read JSON\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:readJson,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Cleaning Empty Cells\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:cleanData,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Cleaning Data of Wrong Format\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:wrongs,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Pandas - Fixing Wrong Data\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:fixings,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Data Correlations\"),\"The corr() method calculates the relationship between each column in our data set.\",React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"The number varies from -1 to 1.\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well.\"),React.createElement(\"li\",null,\"0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.\"),React.createElement(\"li\",null,\"-0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down.\"),React.createElement(\"li\",null,\"0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will.\")),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:correlations,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Plotting\"),\"Uses the plot() method to create diagrams.\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"Specify that you want a scatter plot with the kind argument:\",React.createElement(\"br\",null),\"kind = 'scatter'\",React.createElement(\"br\",null),\"A scatter plot needs an x- and a y-axis.\",React.createElement(\"br\",null),\"Will use \\\"Duration\\\" for the x-axis and \\\"Calories\\\" for the y-axis.\",React.createElement(\"br\",null),\"Include the x and y arguments like this:\",React.createElement(\"br\",null),\"x = 'Duration', y = 'Calories'\",React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Histogram\"),React.createElement(\"br\",null),\"Use the kind argument to specify that you want a histogram:\",React.createElement(\"br\",null),React.createElement(\"br\",null),\"kind = 'hist'\",React.createElement(\"br\",null),\"A histogram needs only one column.\",React.createElement(\"br\",null),\"A histogram shows us the frequency of each interval, e.g. how many workouts lasted between 50 and 60 minutes?\",React.createElement(\"br\",null),\"Will use the \\\"Duration\\\" column to create the histogram.\",React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:Plotting,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"h3\",null,\"Preparing the Data\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:data_,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"h3\",null,\"Learning and Predicting\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:preadicting,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Regex\"),\"when windspeed is 6 mph, 7 mph etc. & temperature is 32 F, 28 F etc.\",React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:windspeed,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"SELECT * from weather_data GROUP BY city\"),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:groupby,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Group data using custom function\"),\"Let's say you want to group your data using custom function. Here the requirement is to create three groups.\",React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1.Days when temperature was between 80 and 90.\"),React.createElement(\"li\",null,\"2.Days when it was between 50 and 60.\"),React.createElement(\"li\",null,\"3.Days when it was anything else.\")),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:temperature,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Basic Concatenation\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:concatenation,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Ignore Index\"),React.createElement(\"b\",null,\"Pivot: \"),\"Allows to Transform/ reshape data.\",React.createElement(\"br\",null),\"Pivot table used tosummarize and aggregate data inside dataframe.\",React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Melt:\"),\"Used to transform/ reshape data.\",React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:ignore,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Crosstab\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:crosstab,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Time Series Analysis\"),\"Time Series is a set of data points indexed in time order.\",React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Benefits of DatetimeIndex:\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1.Partial Date Index: Select Specific Months Data.\"),React.createElement(\"li\",null,\"2.Select Date Range.\")),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Benefits of having DatetimeIndex:\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"Generating DatetimeIndex with periods argument.\")),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:specifics,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Merge DataFrame\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:mergeDataframes,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"sqlalchemy\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:sqlalchemes,language:\"js\",plugins:[\"line-numbers\"]}))))));}}]);return Pandas;}(Component);export default withStyles(styles)(Pandas);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/ml/deepMl/pandas.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","titles","backgroundColor","padding","fontSize","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","Series","trim","dataFrames","readJson","cleanData","wrongs","fixings","correlations","Plotting","data_","preadicting","dataFramesd","sheets","interpolate","windspeed","groupby","temperature","concatenation","ignore","crosstab","specifics","mergeDataframes","sqlalchemes","pandasMethods","pandasCopy","addRows","Pandas","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAGA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACvBC,KAAK,CAAE,CACLC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH,CAELN,OAAO,CAAEG,KAAK,CAACG,OAAN,CAAc,CAAd,CAFJ,CADgB,CAKvBC,QAAQ,CAAE,CACRF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADA,CALa,CAQvBE,SAAS,CAAE,CACTC,SAAS,CAAE,QADF,CARY,CAAL,EAApB,CAaA,GAAMC,CAAAA,MAAM,CAAG,wDAIDC,IAJC,EAAf,CAMA,GAAMC,CAAAA,UAAU,CAAG,8cAajBD,IAbiB,EAAnB,CAeA,GAAME,CAAAA,QAAQ,CAAG,+DAIfF,IAJe,EAAjB,CAMA,GAAMG,CAAAA,SAAS,CAAG,ugBAOhBH,IAPgB,EAAlB,CASA,GAAMI,CAAAA,MAAM,CAAG,kOAGbJ,IAHa,EAAf,CAKA,GAAMK,CAAAA,OAAO,CAAG,2MAOdL,IAPc,EAAhB,CASA,GAAMM,CAAAA,YAAY,CAAG,kHAEnBN,IAFmB,EAArB,CAIA,GAAMO,CAAAA,QAAQ,CAAG,4LAQfP,IARe,EAAjB,CAUA,GAAMQ,CAAAA,KAAK,CAAG,kGAKZR,IALY,EAAd,CAOA,GAAMS,CAAAA,WAAW,CAAG,qTAclBT,IAdkB,EAApB,CAgBA,GAAMU,CAAAA,WAAW,CAAG,i3CAsBlBV,IAtBkB,EAApB,CAwBA,GAAMW,CAAAA,MAAM,CAAG,sfAkBbX,IAlBa,EAAf,CAoBA,GAAMY,CAAAA,WAAW,CAAG,2yDAmClBZ,IAnCkB,EAApB,CAqCA,GAAMa,CAAAA,SAAS,CAAG,2XAWhBb,IAXgB,EAAlB,CAaA,GAAMc,CAAAA,OAAO,CAAG,qIASdd,IATc,EAAhB,CAWA,GAAMe,CAAAA,WAAW,CAAG,6UAalBf,IAbkB,EAApB,CAeA,GAAMgB,CAAAA,aAAa,CAAG,6iBAsBpBhB,IAtBoB,EAAtB,CAwBA,GAAMiB,CAAAA,MAAM,CAAG,kxBAyBbjB,IAzBa,EAAf,CA2BA,GAAMkB,CAAAA,QAAQ,CAAG,uQAKflB,IALe,EAAjB,CAOA,GAAMmB,CAAAA,SAAS,CAAG,ueAkBhBnB,IAlBgB,EAAlB,CAoBA,GAAMoB,CAAAA,eAAe,CAAG,8ZAetBpB,IAfsB,EAAxB,CAiBA,GAAMqB,CAAAA,WAAW,CAAG,2wCAwClBrB,IAxCkB,EAApB,CA0CA,GAAMsB,CAAAA,aAAa,CAAG,qZAepBtB,IAfoB,EAAtB,CAiBA,GAAMuB,CAAAA,UAAU,CAAG,mHAOjBvB,IAPiB,EAAnB,CASA,GAAMwB,CAAAA,OAAO,CAAG,0vBAoCdxB,IApCc,EAAhB,C,GAuCMyB,CAAAA,M,sRACgB,CAClBC,UAAU,CAAC,iBAAM9C,CAAAA,KAAK,CAAC+C,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACD,C,uCACQ,IACCC,CAAAA,OADD,CACa,KAAKC,KADlB,CACCD,OADD,CAEP,MACE,qBAAC,IAAD,EAAM,SAAS,KAAf,EACE,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAACnC,KAA1B,EACE,8BAAI,oBAAC,OAAD,MAAJ,CADF,CADF,CADF,CAME,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEmC,OAAO,CAACnC,KAA1B,EACE,oBAAC,IAAD,MACE,uDADF,CAEE,8BACE,+HADF,CAEE,yHAFF,CAGE,8EAHF,CAIE,mFAJF,CAKE,iGALF,CAME,8LANF,CAOE,2JAPF,CAFF,CAWE,8BAXF,CAaE,8BAbF,CAcE,8BACE,8BAAI,8DAAJ,0GADF,CAEE,8BAFF,CAIE,8BAAI,8DAAJ,0CAJF,CAdF,CAoBE,8BApBF,CAsBE,0CAtBF,yCAwBE,8BACE,0CADF,CAEE,4CAFF,CAGE,uDAHF,CAIE,oDAJF,CAKE,0DALF,CAxBF,CA+BE,8BA/BF,CAiCE,4FAjCF,CAkCE,8BACE,+CADF,CAEE,+CAFF,CAGE,iDAHF,CAIE,4CAJF,CAKE,0CALF,CAlCF,CAyCE,8BAzCF,CA2CE,oEA3CF,CA4CE,8BACE,sMADF,CAGE,kHAHF,CAIE,oKAJF,CA5CF,CAmDE,8BAnDF,CAqDE,4CArDF,CAsDE,8BAtDF,CAwDE,2BAAK,KAAK,CAAEN,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEuB,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAxDF,CA+DE,8BA/DF,CAgEE,8BAhEF,CAiEE,wCAjEF,CAkEE,2BAAK,KAAK,CAAEvB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEmC,aADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAlEF,CAyEE,8BAzEF,CA0EE,8BA1EF,CA4EE,oFA5EF,CA6EE,2BAAK,KAAK,CAAEnC,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEwB,MADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA7EF,CAoFE,8BApFF,CAsFE,oDAtFF,CAuFE,2BAAK,KAAK,CAAExB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEyB,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAvFF,CA8FE,8BA9FF,CAgGE,iDAhGF,KAiGE,8BACE,8BAAI,wCAAJ,uHADF,CAEE,8BAFF,CAGE,8BAAI,2CAAJ,8NAHF,CAKE,8BALF,CAME,8BAAI,uCAAJ,+EANF,CAjGF,CAyGE,8BAzGF,CA2GE,uCA3GF,CA4GE,2BAAK,KAAK,CAAEzB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEY,MADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA5GF,CAmHE,8BAnHF,CAqHE,2CArHF,CAuHE,2BAAK,KAAK,CAAEZ,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEc,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAvHF,CA+HE,8BA/HF,CAiIE,4EAjIF,sIAoIE,8BApIF,oIAuIE,8BAvIF,CAwIE,2BAAK,KAAK,CAAEd,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEoC,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAxIF,CA+IE,8BA/IF,CAiJE,oGAjJF,CAkJE,8BACE,8BAAI,yCAAJ,mBADF,CAEE,8BAAI,0CAAJ,kBAFF,CAGE,8BAAI,uCAAJ,iCAHF,CAIE,8BAJF,CAKE,iGALF,CAlJF,CAyJE,2BAAK,KAAK,CAAEpC,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEqC,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAzJF,CAgKE,8BAhKF,CAkKE,iDAlKF,CAmKE,2BAAK,KAAK,CAAErC,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEe,QADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAnKF,CA0KE,8BA1KF,CA4KE,qDA5KF,CA6KE,2BAAK,KAAK,CAAEf,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEgB,SADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA7KF,CAoLE,8BApLF,CAsLE,8DAtLF,CAuLE,2BAAK,KAAK,CAAEhB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEiB,MADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAvLF,CA8LE,8BA9LF,CAgME,2DAhMF,CAiME,2BAAK,KAAK,CAAEjB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEkB,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAjMF,CAwME,8BAxMF,CA0ME,kDA1MF,sFA4ME,8BA5MF,CA6ME,8BA7MF,CA8ME,+DA9MF,CA+ME,8BACE,0MADF,CAGE,0IAHF,CAIE,gJAJF,CAME,wIANF,CA/MF,CAwNE,2BAAK,KAAK,CAAElB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEmB,YADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAxNF,CA+NE,8BA/NF,CAiOE,yCAjOF,8CAmOE,8BAnOF,CAoOE,8BApOF,gEAsOE,8BAtOF,oBAwOE,8BAxOF,4CA0OE,8BA1OF,yEA4OE,8BA5OF,4CA8OE,8BA9OF,kCAgPE,8BAhPF,CAiPE,8BAjPF,CAmPE,yCAnPF,CAoPE,8BApPF,+DAsPE,8BAtPF,CAuPE,8BAvPF,iBAyPE,8BAzPF,sCA2PE,8BA3PF,iHA6PE,8BA7PF,6DA+PE,8BA/PF,CAiQE,2BAAK,KAAK,CAAEnB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEoB,QADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAjQF,CAyQE,mDAzQF,CA0QE,2BAAK,KAAK,CAAEpB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEqB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA1QF,CAkRE,wDAlRF,CAmRE,2BAAK,KAAK,CAAErB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEsB,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAnRF,CA0RE,8BA1RF,CA4RE,sCA5RF,wEA8RE,2BAAK,KAAK,CAAEtB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAE0B,SADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA9RF,CAqSE,8BArSF,CAsSE,8BAtSF,CAwSE,wEAxSF,CAySE,8BAzSF,CA0SE,2BAAK,KAAK,CAAE1B,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAE2B,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA1SF,CAiTE,8BAjTF,CAmTE,iEAnTF,gHAqTE,8BACE,+EADF,CAEE,sEAFF,CAGE,kEAHF,CArTF,CA0TE,2BAAK,KAAK,CAAE3B,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAE4B,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA1TF,CAiUE,8BAjUF,CAmUE,oDAnUF,CAoUE,2BAAK,KAAK,CAAE5B,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAE6B,aADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CApUF,CA2UE,8BA3UF,CA6UE,6CA7UF,CA8UE,uCA9UF,sCA+UE,8BA/UF,qEAiVE,8BAjVF,CAkVE,8BAlVF,CAmVE,qCAnVF,oCAoVE,8BApVF,CAqVE,2BAAK,KAAK,CAAE7B,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAE8B,MADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CArVF,CA4VE,8BA5VF,CA8VE,yCA9VF,CA+VE,2BAAK,KAAK,CAAE9B,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAE+B,QADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA/VF,CAsWE,8BAtWF,CAwWE,qDAxWF,8DA0WE,8BA1WF,CA2WE,8BA3WF,CA4WE,0DA5WF,CA6WE,8BACE,mFADF,CAEE,qDAFF,CA7WF,CAiXE,8BAjXF,CAkXE,8BAlXF,CAmXE,iEAnXF,CAoXE,8BACE,gFADF,CApXF,CAuXE,2BAAK,KAAK,CAAE/B,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEgC,SADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAvXF,CA8XE,8BA9XF,CAgYE,gDAhYF,CAiYE,2BAAK,KAAK,CAAEhC,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEiC,eADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAjYF,CAwYE,8BAxYF,CA0YE,2CA1YF,CA2YE,2BAAK,KAAK,CAAEjC,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEkC,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA3YF,CADF,CADF,CANF,CADF,CAgaD,C,oBAtakB1C,S,EAyarB,cAAgBI,CAAAA,UAAU,CAACQ,MAAD,CAAV,CAAmBkC,MAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\nconst Series = `\na = [1, 7, 2]\n\nmyvar = pd.Series(a)\nprint(myvar)`.trim();\n\nconst dataFrames = `\ndata = {\n  \"calories\": [420, 380, 390],\n  \"duration\": [50, 40, 45]\n}\n\ndf = pd.DataFrame(data)\ndf\n\n\ndf.loc[0]                                                                             #refer to the row index.\ndf = pd.DataFrame(data, index = [\"day1\", \"day2\", \"day3\"])                             #name your own indexes.\ndf.loc[\"day2\"]                                                                        #refer to the named index:\n`.trim();\n\nconst readJson = `\ndf = pd.read_json('data.json')\n\nprint(df.to_string()) \n`.trim();\n\nconst cleanData = `\ndf.dropna()                                                             //Remove rows that contain empty cells.\ndf.fillna(130, inplace = True)                                          //Replace NULL values with the number 130.\ndf[\"Calories\"].fillna(130, inplace = True)                              //Replace Only For Specified Columns.\n\nx = df[\"Calories\"].mean()                                               //Find MEAN, and replace any empty values with it.\ndf[\"Calories\"].fillna(x, inplace = True)\n`.trim();\n\nconst wrongs = `\ndf['Date'] = pd.to_datetime(df['Date'])                                 //Convert to date.\ndf.dropna(subset=['Date'], inplace = True)                              //Remove rows with a NULL value in the \"Date\" column.\n`.trim();\n\nconst fixings = `\nfor x in df.index:\n  if df.loc[x, \"Duration\"] > 120:\n    df.loc[x, \"Duration\"] = 120\n\n    \ndf.drop_duplicates(inplace = True)                                      //Remove all duplicates.\n`.trim();\n\nconst correlations = `\ndf.corr()                                                               //Relationship between the columns.\n`.trim();\n\nconst Plotting = `\ndf.plot()\nplt.show()                                                         \n\n\ndf.plot(kind = 'scatter', x = 'Duration', y = 'Calories')\n\ndf[\"Duration\"].plot(kind = 'hist')\n`.trim();\n\nconst data_ = `\nimport pandas as pd\nX = music_data = pd.read_csv('music.csv')\nX \ny = music_data['genre']\n`.trim()\n\nconst preadicting = `\nimport pandas as pd \nfrom sklearn.tree import DecisionTreeClassifier\n\nmusic_data = pd.read_csv('music.csv')\nx = music_data.drop(columns=['genre'])\ny = music_data['genre']\n\nmodel = DecisionTreeClassifier()\nmodel.fit(x, y)\nmusic_data\n\npredictions = model.predict([21, 1], [22, 0])\npredictions\n`.trim()\n\nconst dataFramesd = `\ndf = pd.read_csv(\"pandas.csv\")\npd.read_csv(\"pandas.csv\", skiprows=1)\npd.read_csv('pandas.csv', nrows=2)\npd.read_csv(\"pandas.csv\", header=1)                                                       #skiprows and header are same\npd.read_csv(\"pandas.csv\", na_values=[\"n.a.\", \"not available\"])\npd.read_csv(\"pandas.csv\", header=None, names = [\"ticker\",\"eps\",\"revenue\",\"people\"])\npd.read_csv('pandas.csv',header=0, parse_dates=[0], index_col=0, squeeze=True)\npd.read_csv('pandas.csv',  na_values={'eps': ['not available'],'revenue': [-1],'people': ['not available','n.a.']})\n    \n    \ndf.to_csv(\"new.csv\", index=False)                                                             #Write to CSV\ndf.to_csv(\"new.csv\", columns=[\"tickers\",\"price\"], index=False)\n\npd.read_excel(\"stock_data.xlsx\",\"Sheet1\")                                                     #Read Excel\ndf.to_excel(\"new.xlsx\", sheet_name=\"stocks\", index=False, startrow=2, startcol=1)             #Write to Excel\n\n\ndf.to_string()                                                                                #Print the entire DataFrame.\ndf=pd.options.display.max_rows                                                                #Maximum returned rows\ndf=pd.options.display.max_rows = 9999                       #Increase max. number of rows to display the entire DataFrame\n\n`.trim();\n\nconst sheets = `\ndf_stocks = pd.DataFrame({\n    'tickers': ['GOOGL', 'WMT', 'MSFT'],\n    'price': [845, 65, 64 ],\n    'pe': [30.37, 14.26, 30.97],\n    'eps': [27.82, 4.61, 2.12]\n})\n\ndf_weather =  pd.DataFrame({\n    'day': ['1/1/2017','1/2/2017','1/3/2017'],\n    'temperature': [32,35,28],\n    'event': ['Rain', 'Sunny', 'Snow']\n})\n\n\nwith pd.ExcelWriter('stocks_weather.xlsx') as writer:\n    df_stocks.to_excel(writer, sheet_name=\"stocks\")\n    df_weather.to_excel(writer, sheet_name=\"weather\")\n`.trim();\n\nconst interpolate = `\ndf.fillna(0)                                                                          #fillna\ndf.fillna(130, inplace = True)                                                        #Replace NULL values with the 130.\ndf[\"Calories\"].fillna(130, inplace = True)                                            #Replace Only For Specified Columns.\n\n\nnew_df = df.fillna(method=\"ffill\")                                                    #determine how to fill na values.\nnew_df = df.fillna(method=\"bfill\")\n\n\n#Use of axis\ndf.fillna(method=\"bfill\", axis=\"columns\")                                             # axis is either \"index\" or \"columns\"\ndf.fillna(method=\"ffill\",limit=1)                                                     #limit parameter\ndf.interpolate()                                                                      #interpolate\ndf.interpolate(method=\"time\")\n\ndf.dropna()                                                                           #dropna\ndf.drop_duplicates()\n\n\n#Inserting Missing Dates\ndt = pd.date_range(\"01-01-2017\",\"01-11-2017\")\nidx = pd.DatetimeIndex(dt)\ndf.reindex(idx)\n\n\ndf.replace(-99999, value=np.NaN)                                                      #Handling Missing Data-replace method\ndf.replace(to_replace=[-99999,-88888], value=0)                                       #Replacing list with single value\ndf.replace({'temperature': -99999,'windspeed': -99999,'event': '0'}, np.nan)          #Replacing per column\n          \nnew_df = df.replace({-99999: np.nan, 'no event': 'Sunny', })                          #Replacing by using mapping\ndf['area'][0] = 50                                                                    #Update data.\n\ndf=pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])                       #reindex\n\n`.trim();\n\nconst windspeed = `\ndf.replace({'temperature': '[A-Za-z]', 'windspeed': '[a-z]'},'', regex=True) \n\n\n3Replacing list with another list\n    df = pd.DataFrame({\n    'score': ['exceptional','average', 'good', 'poor', 'average', 'exceptional'],\n    'student': ['rob', 'maya', 'parthiv', 'tom', 'julian', 'erica']\n  })\n\n    df.replace(['poor', 'average', 'good', 'exceptional'], [1,2,3,4])\n`.trim();\n\nconst groupby = `\n    g.get_group('mumbai')\n    g.max()\n    g.min()\n    g.mean()\n    g.describe()\n    g.size()\n    g.count()\n    g.plot()\n`.trim();\n\nconst temperature = `\ndef grouper(df, idx, col):\n    if 80 <= df[col].loc[idx] <= 90:\n        return '80-90'\n    elif 50 <= df[col].loc[idx] <= 60:\n        return '50-60'\n    else:\n        return 'others'\n        \ng = df.groupby(lambda x: grouper(df, x, 'temperature'))\nfor key, d in g:\nprint(\"Group by Key: {}\\n\".format(key))\nprint(d)\n`.trim();\n\nconst concatenation = `\nindia_weather = pd.DataFrame({\n  \"city\": [\"mumbai\",\"delhi\",\"banglore\"],\n  \"temperature\": [32,45,30],\n  \"humidity\": [80, 60, 78]\n})\n\ndf = pd.concat([india_weather, us_weather])\n\n\n#Concatenation Using Index.\ntemperature_df = pd.DataFrame({\n  \"city\": [\"mumbai\",\"delhi\",\"banglore\"],\n  \"temperature\": [32,45,30],\n}, index=[0,1,2])\n\npd.concat([temperature_df,windspeed_df],axis=1)\n\n\n#Concatenate dataframe with series\ns = pd.Series([\"Humid\",\"Dry\",\"Rain\"], name=\"event\")\npd.concat([temperature_df,s],axis=1)\n`.trim();\n\nconst ignore = `\npd.concat([india_weather, us_weather], ignore_index=True)\n\n\n#pivot\ndf.pivot(index='city',columns='date')\ndf.pivot(index='city',columns='date',values=\"humidity\")\n\nf.pivot_table(index=\"city\",columns=\"date\", margins=True,aggfunc=np.sum)                                 #margins\ndf.pivot_table(index=pd.Grouper(freq='M',key='date'),columns='city')                                    #grouper\n\n\n#Melt\npd.melt(df, id_vars=[\"day\"], var_name='city', value_name='temperature')\n\n\n#Reshape dataframe using stack/unstack\ndf = pd.read_excel(\"stocks.xlsx\",header=[0,1])\ndf.stack()\ndf.stack(level=0)\ndf_stacked.unstack()\n\n\npd.read_excel(\"stocks_3_levels.xlsx\",header=[0,1,2])                                      #3 levels of column headers\ndf2.stack(level=1)\n`.trim();\n\nconst crosstab = `\npd.crosstab(df.Nationality,df.Handedness)\nMargins: pd.crosstab(df.Sex,df.Handedness, margins=True)\nNormalize: pd.crosstab(df.Sex, df.Handedness, normalize='index')\nAggfunc and Values: pd.crosstab(df.Sex, df.Handedness, values=df.Age, aggfunc=np.average)\n`.trim();\n\nconst specifics = `\n#Partial Date Index\ndf['2017-06-30']\ndf['2017-06'].Close.mean() \n\n\n#Date Range\ndf['2017-01-08':'2017-01-03']\n\ndf['Close'].resample('M').mean().head()                                                       #Resampling\n\n#Finding missing dates from datetimeindex\ndaily_index = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq='D')\ndaily_index.difference(df.index)\n\n\n#generating DatetimeIndex with periods argument\npd.date_range('1/1/2011', periods=72, freq='H')\n`.trim();\n\nconst mergeDataframes = `\ndf1 = pd.DataFrame({\n  \"city\": [\"new york\",\"chicago\",\"orlando\"],\n  \"temperature\": [21,14,35],\n})\n\ndf2 = pd.DataFrame({\n  \"city\": [\"chicago\",\"new york\",\"orlando\"],\n  \"humidity\": [65,68,75],\n})\n\ndf3 = pd.merge(df1, df2, on=\"city\")\n\ndf3=pd.merge(df1,df2,on=\"city\",how=\"outer\",indicator=True)\ndf3= pd.merge(df1,df2,on=\"city\",how=\"outer\", suffixes=('_first','_second'))\n`.trim();\n\nconst sqlalchemes = `\nimport pandas as pd\nimport sqlalchemy\n\nengine = sqlalchemy.create_engine('mysql+pymysql://root:@localhost:3306/application')\n\ndf = pd.read_sql_table('customers',engine)\n\ndf = pd.read_sql_table('customers', engine, columns=[\"name\"])       #Read only selected columns\n\n\n#Join two tables and read them in a dataframe using read_sql_query\ndf = pd.read_sql_query(\"select id,name from customers\",engine)      \n\n\nquery = '''\n SELECT customers.name, customers.phone_number, orders.name, orders.amount\n FROM customers INNER JOIN orders\n ON customers.id=orders.customer_id\n'''\npd.read_sql(query,engine)                           #read_sql is a wrapper around read_sql_query and read_sql_table\n\ndf = pd.read_csv(\"customers.csv\")                   #Write to mysql database using to_sql\n\ndf = pd.read_csv(\"customers.csv\")\n\ndf.rename(columns={\n    'Customer Name': 'name',\n    'Customer Phone': 'phone_number'\n}, inplace=True)\n\n\n\n#to_sql has different parameters such as chunksize which allows to write data in chunks. Useful when size is huge\ndf.to_sql(\n    name='customers', # database table name\n    con=engine,\n    if_exists='append',\n    index=False                                                             \n)                                   \n`.trim();\n\nconst pandasMethods = `\ndf.shape\ndf.values\ndf.head(10)\ndf.describe()\ndf.memory_usage()\ndf.memory_usage(deep=True)\ndf.loc[1:3]\ndf.drop_duplicates()\ndf.count()\ndf.tail() \ndf.info()\ndf.sort_index()\ndf.isna()                            #Returns a dataframe filled with boolean values with true indicating missing values.\ndf.isnull().sum()                    #Calculate the number of missing values in each column.\n`.trim();\n\nconst pandasCopy = `\nimport numpy as np\n\nseries = pd.Series([1,2,np.nan,4])\n\nseries_2=series.copy(deep=True)\nprint(series_2)\n`.trim();\n\nconst addRows = `\n#Add rows\ndict = {'Name':['Martha', 'Tim', 'Rob', 'Georgia'],\n        'Maths':[87, 91, 97, 95],\n        'Science':[83, 99, 84, 76]\n       }\n  \ndf = pd.DataFrame(dict)\n  \ndf2 = {'Name': 'Amy', 'Maths': 89, 'Science': 93}\ndf = df.append(df2, ignore_index = True)\ndf\n\ndf.reset_index()\n\n\n\n#add columns\ndata = {'Name':['Martha', 'Tim', 'Rob', 'Georgia'],\n        'Maths':[87, 91, 97, 95],\n        'Science':[83, 99, 84, 76]\n       }\n\ndf = pd.DataFrame(data)\n\naddress = ['Delhi', 'Bangalore', 'Chennai', 'Patna']\n\ndf['Address'] = address\ndf\n\n\n\n#Add An Index\ndata = pd.read_csv(\"areas.csv\")\ndata.set_index(\"area\", inplace = True)                                                      #Setting area as index column\ndata.head()\n`.trim();\n\n\nclass Pandas extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Pandas (Data analysis)</h3>\n              <ul>\n                <li>Provides functions to make working with structured or tabular data fast, easy, and expressive.</li>\n                <li>Pandas allows us to analyze big data and make conclusions based on statistical theories.</li>\n                <li>Primary objects is DataFrame and data.Series.</li>\n                <li>Pandas find correlation between two/ more columns.</li>\n                <li>Pandas is designed for working with tabular/ heterogeneous data.</li>\n                <li>Pandas blends the high-performance, array-computing ideas of NumPy with the flexible data manipulation capabilities of spreadsheets and relational databases.</li>\n                <li>Pandas has a special Categorical type for holding data that uses the integer-based categorical representation or encoding.</li>\n              </ul>\n              <br />\n\n              <br />\n              <ul>\n                <li><b>Data Science/ Data Analytics: </b>Is a process of analyzing large set of data point to get answer on questions releted to that data set.</li>\n                <br />\n\n                <li><b>Data Munging/ Data Wrangling: </b>It's a Process of cleaning messy data.</li>\n              </ul>\n              <br />\n\n              <h3>Dataframe</h3>\n              Different ways of creating dataframe:\n              <ul>\n                <li>Using CSV</li>\n                <li>Using excel</li>\n                <li>From python dictionary</li>\n                <li>From list of tuples</li>\n                <li>From list of dictionaries</li>\n              </ul>\n              <br />\n\n              <h3>What Are The Most Important Features Of The Pandas Library?</h3>\n              <ul>\n                <li>Data Alignment</li>\n                <li>Merge and join</li>\n                <li>Memory Efficient</li>\n                <li>Time series</li>\n                <li>Reshaping</li>\n              </ul>\n              <br />\n\n              <h3>Explain Categorical Data in Pandas?</h3>\n              <ul>\n                <li>Categorical data refers to real-time data that can be repetitive for instance, data values under\n                  categories such as country, gender, codes will always be repetitive.</li>\n                <li>Categorical values also take only a limited and fixed number of possible values. </li>\n                <li>Numerical operations cannot be performed on such data. All values of categorical data in pandas\n                  are either in categories or np.nan.</li>\n              </ul>\n              <br />\n\n              <b>Import file.</b>\n              <br />\n\n              <div style={titles}>\n                <PrismCode\n                  code={dataFramesd}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <br />\n              <b>Methods:</b>\n              <div style={titles}>\n                <PrismCode\n                  code={pandasMethods}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <br />\n\n              <b>Write two dataframes to two separate sheets in excel</b>\n              <div style={titles}>\n                <PrismCode\n                  code={sheets}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Handle Missing Data</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={interpolate}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <b>Data Structures: </b>2\n              <ul>\n                <li><b>Series: </b>Is a 1D array-like object containing a sequence of values and an associated array of data labels, called its index.</li>\n                <br />\n                <li><b>DataFrame: </b>A DataFrame represents a rectangular table of data and contains an ordered collection of columns, each of which can be\n                  a different value type (numeric, string, boolean, etc.). DataFrame has both a row and column index.</li>\n                <br />\n                <li><b>Panel: </b>Is a 3-dimensional DS and includes items such as major_axis and minor_axis.</li>\n              </ul>\n              <br />\n\n              <h3>Series</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={Series}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>DataFrames</h3>\n\n              <div style={titles}>\n                <PrismCode\n                  code={dataFrames}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n\n              <br />\n\n              <h3>How can we create copy of series in Pandas?</h3>\n              copy() Make a deep copy, including a copy of the data and the indices. With deep=False neither the\n              indices or the data are copied.\n              <br />\n              Note that when deep=True data is copied, actual python objects will not be copied\n              recursively, only the reference to the object.\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={pandasCopy}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>How Will You Add An Index, Row, Or Column To A Dataframe In Pandas?</h3>\n              <ul>\n                <li><b>.loc (): </b>Is label based.</li>\n                <li><b>.iloc (): </b>Integer based.</li>\n                <li><b>.ix(): </b>Both label and integer based.</li>\n                <br />\n                <li>To add columns to the DataFrame, we can use .loc () or .iloc ().</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={addRows}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Pandas Read JSON</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={readJson}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Cleaning Empty Cells</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={cleanData}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Cleaning Data of Wrong Format</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={wrongs}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Pandas - Fixing Wrong Data</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={fixings}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Data Correlations</h3>\n              The corr() method calculates the relationship between each column in our data set.\n              <br />\n              <br />\n              <b>The number varies from -1 to 1.</b>\n              <ul>\n                <li>1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each\n                  time a value went up in the first column, the other one went up as well.</li>\n                <li>0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.</li>\n                <li>-0.9 would be just as good relationship as 0.9, but if you increase one value, the other will\n                  probably go down.</li>\n                <li>0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the\n                  other will.</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={correlations}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Plotting</h3>\n              Uses the plot() method to create diagrams.\n              <br />\n              <br />\n              Specify that you want a scatter plot with the kind argument:\n              <br />\n              kind = 'scatter'\n              <br />\n              A scatter plot needs an x- and a y-axis.\n              <br />\n              Will use \"Duration\" for the x-axis and \"Calories\" for the y-axis.\n              <br />\n              Include the x and y arguments like this:\n              <br />\n              x = 'Duration', y = 'Calories'\n              <br />\n              <br />\n\n              <b>Histogram</b>\n              <br />\n              Use the kind argument to specify that you want a histogram:\n              <br />\n              <br />\n              kind = 'hist'\n              <br />\n              A histogram needs only one column.\n              <br />\n              A histogram shows us the frequency of each interval, e.g. how many workouts lasted between 50 and 60 minutes?\n              <br />\n              Will use the \"Duration\" column to create the histogram.\n              <br />\n\n              <div style={titles}>\n                <PrismCode\n                  code={Plotting}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n\n              <h3>Preparing the Data</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={data_}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n\n              <h3>Learning and Predicting</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={preadicting}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Regex</h3>\n              when windspeed is 6 mph, 7 mph etc. & temperature is 32 F, 28 F etc.\n              <div style={titles}>\n                <PrismCode\n                  code={windspeed}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <br />\n\n              <b>SELECT * from weather_data GROUP BY city</b>\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={groupby}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Group data using custom function</h3>\n              Let's say you want to group your data using custom function. Here the requirement is to create three groups.\n              <ul>\n                <li>1.Days when temperature was between 80 and 90.</li>\n                <li>2.Days when it was between 50 and 60.</li>\n                <li>3.Days when it was anything else.</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={temperature}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Basic Concatenation</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={concatenation}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Ignore Index</h3>\n              <b>Pivot: </b>Allows to Transform/ reshape data.\n              <br />\n              Pivot table used tosummarize and aggregate data inside dataframe.\n              <br />\n              <br />\n              <b>Melt:</b>Used to transform/ reshape data.\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={ignore}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Crosstab</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={crosstab}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Time Series Analysis</h3>\n              Time Series is a set of data points indexed in time order.\n              <br />\n              <br />\n              <b>Benefits of DatetimeIndex:</b>\n              <ul>\n                <li>1.Partial Date Index: Select Specific Months Data.</li>\n                <li>2.Select Date Range.</li>\n              </ul>\n              <br />\n              <br />\n              <b>Benefits of having DatetimeIndex:</b>\n              <ul>\n                <li>Generating DatetimeIndex with periods argument.</li>\n              </ul>\n              <div style={titles}>\n                <PrismCode\n                  code={specifics}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Merge DataFrame</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={mergeDataframes}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>sqlalchemy</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={sqlalchemes}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\nexport default (withStyles(styles)(Pandas));\n"]},"metadata":{},"sourceType":"module"}
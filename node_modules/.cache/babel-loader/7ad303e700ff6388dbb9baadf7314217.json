{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var childsFile=\"\\nimport numpy as np\\nimport cv2\\nimport PIL.Image as Image\\nimport os\\nimport matplotlib.pylab as plt\\nimport tensorflow as tf\\nimport tensorflow_hub as hub\\nfrom tensorflow import keras\\nfrom tensorflow.keras import layers\\nfrom tensorflow.keras.models import Sequential\\n\\n\\nIMAGE_SHAPE = (224, 224)                                      #Make predictions using ready made model (without training).\\n\\nclassifier = tf.keras.Sequential([\\n    hub.KerasLayer(\\\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\\\", input_shape=IMAGE_SHAPE+(3,))\\n])\\n\\ngold_fish = Image.open(\\\"goldfish.jpg\\\").resize(IMAGE_SHAPE)\\ngold_fish = np.array(gold_fish)/255.0\\n\\ngold_fish[np.newaxis, ...]\\nresult = classifier.predict(gold_fish[np.newaxis, ...])\\n\\npredicted_label_index = np.argmax(result)\\npredicted_label_index\\n\\n# tf.keras.utils.get_file('ImageNetLabels.txt',\\n#                         'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\\nimage_labels = []\\nwith open(\\\"ImageNetLabels.txt\\\", \\\"r\\\") as f:\\n    image_labels = f.read().splitlines()\\nimage_labels[:5]\\n\\nimage_labels[predicted_label_index]\\n\".trim();var flowers=\"\\ndataset_url = \\\"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\\\"\\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\\n\\ndata_dir\\n\\nimport pathlib\\ndata_dir = pathlib.Path(data_dir)\\n\\nlist(data_dir.glob('*/*.jpg'))[:5]\\nimage_count = len(list(data_dir.glob('*/*.jpg')))\\nprint(image_count)\\n\\nroses = list(data_dir.glob('roses/*'))\\nroses[:5]\\n\\nPIL.Image.open(str(roses[1]))\\n\\ntulips = list(data_dir.glob('tulips/*'))\\nPIL.Image.open(str(tulips[0]))\\n\".trim();var opencv=\"\\nflowers_images_dict = {\\n  'roses': list(data_dir.glob('roses/*')),\\n  'daisy': list(data_dir.glob('daisy/*')),\\n  'dandelion': list(data_dir.glob('dandelion/*')),\\n  'sunflowers': list(data_dir.glob('sunflowers/*')),\\n  'tulips': list(data_dir.glob('tulips/*')),\\n}\\n\\nflowers_labels_dict = {\\n  'roses': 0,\\n  'daisy': 1,\\n  'dandelion': 2,\\n  'sunflowers': 3,\\n  'tulips': 4,\\n}\\n\\nflowers_images_dict['roses'][:5]\\nstr(flowers_images_dict['roses'][0])\\n\\nimg = cv2.imread(str(flowers_images_dict['roses'][0]))\\ncv2.resize(img,(224,224)).shape\\nX, y = [], []\\n\\nfor flower_name, images in flowers_images_dict.items():\\n    for image in images:\\n        img = cv2.imread(str(image))\\n        resized_img = cv2.resize(img,(224,224))\\n        X.append(resized_img)\\n        y.append(flowers_labels_dict[flower_name])\\n        \\nX = np.array(X)\\ny = np.array(y)\\n\".trim();var split=\"\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\\n\\nX_train_scaled = X_train / 255\\nX_test_scaled = X_test / 255\\n\\n\\nX[0].shape                                                #Make prediction using pre-trained model on new flowers dataset.\\nIMAGE_SHAPE+(3,)\\n\\nx0_resized = cv2.resize(X[0], IMAGE_SHAPE)\\nx1_resized = cv2.resize(X[1], IMAGE_SHAPE)\\nx2_resized = cv2.resize(X[2], IMAGE_SHAPE)\\n\\nplt.axis('off')\\nplt.imshow(X[0])\\n\\nplt.axis('off')\\nplt.imshow(X[1])\\n\\nplt.axis('off')\\nplt.imshow(X[2])\\n\\npredicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\\npredicted = np.argmax(predicted, axis=1)\\npredicted\\n\\nimage_labels[795]\\n\".trim();var images=\"\\nfeature_extractor_model = \\\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\\\"\\n\\npretrained_model_without_top_layer = hub.KerasLayer(\\n    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\\n    \\nnum_of_flowers = 5\\nmodel = tf.keras.Sequential([pretrained_model_without_top_layer, tf.keras.layers.Dense(num_of_flowers)])\\n\\nmodel.summary()\\n\\n\\nmodel.compile(\\n  optimizer=\\\"adam\\\",\\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\\n  metrics=['acc'])\\n\\nmodel.fit(X_train_scaled, y_train, epochs=5)\\n\\nmodel.evaluate(X_test_scaled,y_test)\\n\".trim();var Transfer=/*#__PURE__*/function(_Component){_inherits(Transfer,_Component);function Transfer(){_classCallCheck(this,Transfer);return _possibleConstructorReturn(this,_getPrototypeOf(Transfer).apply(this,arguments));}_createClass(Transfer,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"Transfer learning in image classification\"),\"We will use transfer learning and take pre-trained model from google's Tensorflow Hub and re-train that on flowers dataset.\",React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:childsFile,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Load flowers dataset\"),React.createElement(\"i\",null,\"cache_dir indicates where to download data.\"),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:flowers,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Read flowers images from disk into numpy array using opencv\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:opencv,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Train test split\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:split,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Now take pre-trained model and retrain it using flowers images\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:images,language:\"js\",plugins:[\"line-numbers\"]}))))));}}]);return Transfer;}(Component);export default withStyles(styles)(Transfer);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/angularjs/deepAngularjs/transfer.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","titles","backgroundColor","padding","fontSize","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","childsFile","trim","flowers","opencv","split","images","Transfer","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAGA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACvBC,KAAK,CAAE,CACLC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH,CAELN,OAAO,CAAEG,KAAK,CAACG,OAAN,CAAc,CAAd,CAFJ,CADgB,CAKvBC,QAAQ,CAAE,CACRF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADA,CALa,CAQvBE,SAAS,CAAE,CACTC,SAAS,CAAE,QADF,CARY,CAAL,EAApB,CAcA,GAAMC,CAAAA,UAAU,CAAG,ioCAoCjBC,IApCiB,EAAnB,CAsCA,GAAMC,CAAAA,OAAO,CAAG,qiBAoBdD,IApBc,EAAhB,CAsBA,GAAME,CAAAA,MAAM,CAAG,m2BAiCbF,IAjCa,EAAf,CAmCA,GAAMG,CAAAA,KAAK,CAAG,yuBA6BZH,IA7BY,EAAd,CA+BA,GAAMI,CAAAA,MAAM,CAAG,gmBAoBbJ,IApBa,EAAf,C,GAwBMK,CAAAA,Q,gSACgB,CAClBC,UAAU,CAAC,iBAAM1B,CAAAA,KAAK,CAAC2B,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACD,C,uCACQ,IACCC,CAAAA,OADD,CACa,KAAKC,KADlB,CACCD,OADD,CAEP,MACE,qBAAC,IAAD,EAAM,SAAS,KAAf,EACE,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAACf,KAA1B,EACE,8BAAI,oBAAC,OAAD,MAAJ,CADF,CADF,CADF,CAME,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEe,OAAO,CAACf,KAA1B,EACE,oBAAC,IAAD,MACE,0EADF,+HAIE,8BAJF,CAKE,8BALF,CAME,2BAAK,KAAK,CAAEN,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEY,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CANF,CAaE,8BAbF,CAeE,qDAfF,CAgBE,2EAhBF,CAiBE,8BAjBF,CAkBE,2BAAK,KAAK,CAAEZ,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEc,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAlBF,CAyBE,8BAzBF,CA2BE,4FA3BF,CA4BE,2BAAK,KAAK,CAAEd,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEe,MADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA5BF,CAmCE,8BAnCF,CAqCE,iDArCF,CAsCE,2BAAK,KAAK,CAAEf,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEgB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAtCF,CA6CE,8BA7CF,CA+CE,+FA/CF,CAgDE,2BAAK,KAAK,CAAEhB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEiB,MADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAhDF,CADF,CADF,CANF,CADF,CAqED,C,sBA3EoBzB,S,EA+EvB,cAAgBI,CAAAA,UAAU,CAACQ,MAAD,CAAV,CAAmBc,QAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst childsFile = `\nimport numpy as np\nimport cv2\nimport PIL.Image as Image\nimport os\nimport matplotlib.pylab as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\n\nIMAGE_SHAPE = (224, 224)                                      #Make predictions using ready made model (without training).\n\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n])\n\ngold_fish = Image.open(\"goldfish.jpg\").resize(IMAGE_SHAPE)\ngold_fish = np.array(gold_fish)/255.0\n\ngold_fish[np.newaxis, ...]\nresult = classifier.predict(gold_fish[np.newaxis, ...])\n\npredicted_label_index = np.argmax(result)\npredicted_label_index\n\n# tf.keras.utils.get_file('ImageNetLabels.txt',\n#                         'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\nimage_labels = []\nwith open(\"ImageNetLabels.txt\", \"r\") as f:\n    image_labels = f.read().splitlines()\nimage_labels[:5]\n\nimage_labels[predicted_label_index]\n`.trim();\n\nconst flowers = `\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n\ndata_dir\n\nimport pathlib\ndata_dir = pathlib.Path(data_dir)\n\nlist(data_dir.glob('*/*.jpg'))[:5]\nimage_count = len(list(data_dir.glob('*/*.jpg')))\nprint(image_count)\n\nroses = list(data_dir.glob('roses/*'))\nroses[:5]\n\nPIL.Image.open(str(roses[1]))\n\ntulips = list(data_dir.glob('tulips/*'))\nPIL.Image.open(str(tulips[0]))\n`.trim();\n\nconst opencv = `\nflowers_images_dict = {\n  'roses': list(data_dir.glob('roses/*')),\n  'daisy': list(data_dir.glob('daisy/*')),\n  'dandelion': list(data_dir.glob('dandelion/*')),\n  'sunflowers': list(data_dir.glob('sunflowers/*')),\n  'tulips': list(data_dir.glob('tulips/*')),\n}\n\nflowers_labels_dict = {\n  'roses': 0,\n  'daisy': 1,\n  'dandelion': 2,\n  'sunflowers': 3,\n  'tulips': 4,\n}\n\nflowers_images_dict['roses'][:5]\nstr(flowers_images_dict['roses'][0])\n\nimg = cv2.imread(str(flowers_images_dict['roses'][0]))\ncv2.resize(img,(224,224)).shape\nX, y = [], []\n\nfor flower_name, images in flowers_images_dict.items():\n    for image in images:\n        img = cv2.imread(str(image))\n        resized_img = cv2.resize(img,(224,224))\n        X.append(resized_img)\n        y.append(flowers_labels_dict[flower_name])\n        \nX = np.array(X)\ny = np.array(y)\n`.trim();\n\nconst split = `\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nX_train_scaled = X_train / 255\nX_test_scaled = X_test / 255\n\n\nX[0].shape                                                #Make prediction using pre-trained model on new flowers dataset.\nIMAGE_SHAPE+(3,)\n\nx0_resized = cv2.resize(X[0], IMAGE_SHAPE)\nx1_resized = cv2.resize(X[1], IMAGE_SHAPE)\nx2_resized = cv2.resize(X[2], IMAGE_SHAPE)\n\nplt.axis('off')\nplt.imshow(X[0])\n\nplt.axis('off')\nplt.imshow(X[1])\n\nplt.axis('off')\nplt.imshow(X[2])\n\npredicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))\npredicted = np.argmax(predicted, axis=1)\npredicted\n\nimage_labels[795]\n`.trim();\n\nconst images = `\nfeature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n\npretrained_model_without_top_layer = hub.KerasLayer(\n    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n    \nnum_of_flowers = 5\nmodel = tf.keras.Sequential([pretrained_model_without_top_layer, tf.keras.layers.Dense(num_of_flowers)])\n\nmodel.summary()\n\n\nmodel.compile(\n  optimizer=\"adam\",\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['acc'])\n\nmodel.fit(X_train_scaled, y_train, epochs=5)\n\nmodel.evaluate(X_test_scaled,y_test)\n`.trim();\n\n\n\nclass Transfer extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>Transfer learning in image classification</h3>\n              We will use transfer learning and take pre-trained model from google's Tensorflow Hub and re-train that\n              on flowers dataset.\n              <br />\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Load flowers dataset</h3>\n              <i>cache_dir indicates where to download data.</i>\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={flowers}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Read flowers images from disk into numpy array using opencv</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={opencv}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Train test split</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={split}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Now take pre-trained model and retrain it using flowers images</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={images}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\n\nexport default (withStyles(styles)(Transfer));\n"]},"metadata":{},"sourceType":"module"}
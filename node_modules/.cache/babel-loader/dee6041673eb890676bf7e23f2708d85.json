{"ast":null,"code":"import _classCallCheck from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/home/mukeshs/Projects/edurights/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import Prism from\"prismjs\";import{Grid,Paper,withStyles,List}from\"@material-ui/core\";import'../../ReactJs/styles.css';import Sidebar from'../sidebar';import PrismCode from'../../ReactJs/prismCode';import logsvalues from'../../../assets/AI/convolutinal.png';var titles={backgroundColor:'#F0F8FF',padding:'1px',fontSize:'16px'};var redesign={height:200,width:500};var styles=function styles(theme){return{paper:{margin:theme.spacing(1),padding:theme.spacing(1)},smMargin:{margin:theme.spacing(1)},actionDiv:{textAlign:\"center\"}};};var childsFile=\"\\n(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\\nX_train.shape\\nX_test.shape\\ny_train[:5]\\n\\ny_train = y_train.reshape(-1,)\\ny_test = y_test.reshape(-1,)\\n\".trim();var images=\"\\ndef plot_sample(X, y, index):\\n    plt.figure(figsize = (15,2))\\n    plt.imshow(X[index])\\n    plt.xlabel(classes[y[index]])\\n    \\nplot_sample(X_train, y_train, 0)\\nplot_sample(X_train, y_train, 1)\\n\".trim();var normalize=\"\\nX_train = X_train / 255.0\\nX_test = X_test / 255.0\\n\".trim();var artificial=\"\\nann = models.Sequential([\\n  layers.Flatten(input_shape=(32,32,3)),\\n  layers.Dense(3000, activation='relu'),\\n  layers.Dense(1000, activation='relu'),\\n  layers.Dense(10, activation='sigmoid')    \\n])\\n\\nann.compile(optimizer='SGD',\\n        loss='sparse_categorical_crossentropy',\\n        metrics=['accuracy'])\\n\\nann.fit(X_train, y_train, epochs=5)\\n\\n\\nfrom sklearn.metrics import confusion_matrix , classification_report\\nimport numpy as np\\ny_pred = ann.predict(X_test)\\ny_pred_classes = [np.argmax(element) for element in y_pred]\\n\\nprint(\\\"Classification Report: nL\\\", classification_report(y_test, y_pred_classes))\\n\".trim();var imagesp=\"\\ncnn = models.Sequential([\\n  layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\\n  layers.MaxPooling2D((2, 2)),\\n  \\n  layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\\n  layers.MaxPooling2D((2, 2)),\\n  \\n  layers.Flatten(),\\n  layers.Dense(64, activation='relu'),\\n  layers.Dense(10, activation='softmax')\\n])\\n\\n\\ncnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\\n              \\ncnn.fit(X_train, y_train, epochs=10)\\ncnn.evaluate(X_test,y_test)\\ncnn.evaluate(X_test,y_test)\\n\\ny_pred = cnn.predict(X_test)\\ny_pred[:5]\\n\\ny_classes = [np.argmax(element) for element in y_pred]\\ny_classes[:5]\\ny_test[:5]\\n\\nplot_sample(X_test, y_test,3)\\nclasses[y_classes[3]]\\nclasses[y_classes[3]]\\n\".trim();var childsFile2=\"\\n(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()\\nX_train.shape\\nX_train[0].shape\\n\\nplt.matshow(X_train[0])\\nX_train = X_train / 255\\n\".trim();var classifications=\"\\nmodel = keras.Sequential([\\n  keras.layers.Flatten(input_shape=(28, 28)),\\n  keras.layers.Dense(100, activation='relu'),\\n  keras.layers.Dense(10, activation='sigmoid')\\n])\\n\\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\\n\\nmodel.fit(X_train, y_train, epochs=10)\\nmodel.evaluate(X_test,y_test)\\nX_train = X_train.reshape(-1,28,28,1)\\nX_train.shape\\n\\nX_test = X_test.reshape(-1,28,28,1)\\nX_test.shape\\n\".trim();var pipes=\"\\nmodel = keras.Sequential([\\n    \\n  layers.Conv2D(30, (3,3), activation='relu', input_shape=(28, 28, 1)),\\n  layers.MaxPooling2D((2,2)),\\n\\n  layers.Flatten(),\\n  layers.Dense(100, activation='relu'),\\n  keras.layers.Dense(10, activation='sigmoid')\\n])\\n\\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\\nmodel.fit(X_train, y_train, epochs=5)\\n\\ny_train[:5]\\nmodel.evaluate(X_test,y_test)\\n\".trim();// const pipes = ``.trim();\nvar Convolutionals=/*#__PURE__*/function(_Component){_inherits(Convolutionals,_Component);function Convolutionals(){_classCallCheck(this,Convolutionals);return _possibleConstructorReturn(this,_getPrototypeOf(Convolutionals).apply(this,arguments));}_createClass(Convolutionals,[{key:\"componentDidMount\",value:function componentDidMount(){setTimeout(function(){return Prism.highlightAll();},0);}},{key:\"render\",value:function render(){var classes=this.props.classes;return React.createElement(Grid,{container:true},React.createElement(Grid,{item:true,xs:2},React.createElement(Paper,{className:classes.paper},React.createElement(\"h4\",null,React.createElement(Sidebar,null)))),React.createElement(Grid,{item:true,xs:10},React.createElement(Paper,{className:classes.paper},React.createElement(List,null,React.createElement(\"h3\",null,\"1. Small Image Classification Using Convolutional Neural Network (CNN)\"),\"In deep learning, CNN/ConvNet is a class of deep neural networks, most commonly applied to analyze visual imagery. In mathematics convolution is a mathematical operation on two functions that produces a third function that expresses how the shape of one is modified by the other.\",React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"img\",{src:logsvalues,alt:\"Theata\",className:\"responsive2\",style:redesign}),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:childsFile,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Plot some images to see what they are\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:images,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Normalizing the training data\"),\"Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel can range from 0 to 255. Hence to normalize in 0--1 range, we need to divide it by 255.\",React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:normalize,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Build simple artificial neural network for image classification\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:artificial,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Now let us build a convolutional neural network to train our images\"),\"To handle variety in digits we use simple artificial Neural network (ANN).\",React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1.Loopy Pattern detector.\"),React.createElement(\"li\",null,\"2.Vertical line detector.\"),React.createElement(\"li\",null,\"3.Diagonal line detector.\")),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Disadvantages of using ANN for image classification:\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\" 1.Too much computation.\"),React.createElement(\"li\",null,\"2.Treats local pixels same as pixels far apart.\"),React.createElement(\"li\",null,\"3.Sensitive to location of an object in an image.\")),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"ReLU helps with making the model nonlinear.\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1.Introduces nonlinearity.\"),React.createElement(\"li\",null,\"2.Speeds up training, faster to compute.\")),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:imagesp,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"i\",null,\"With CNN, at the end 5 epochs, accuracy was at around 70.28% which is a significant improvement over ANN. CNN's are best for image classification and gives superb accuracy. Also computation is much less compared to simple ANN as maxpooling reduces the image dimensions while still preserving the features.\"),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Pooling\"),\"Pooling layer is used to reduce the size.\",React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Benifits of Pooling:\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1.Reduce dimensions & computation.\"),React.createElement(\"li\",null,\"2.Reduce overfitting as there are less parameter.\"),React.createElement(\"li\",null,\"3.Model is tolerant towards variations, distotions.\")),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Convolution\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1.Connections sparsity reduces overfitting.\"),React.createElement(\"li\",null,\"2.Conv + Pooling gives location invariant feature detection.\"),React.createElement(\"li\",null,\"3.Parameter sharing.\")),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"CNN by itself dpesn't take care of Rotation and Scale.\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,\"1.You need to have rotated, scaled samples in training dataset.\"),React.createElement(\"li\",null,\"2.If you don't have such samples than data augmentation methods to generate new rotated/ scaled samples from existing training samples.\")),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"b\",null,\"Convolution padding and stride:\"),React.createElement(\"ul\",null,React.createElement(\"li\",null,React.createElement(\"b\",null,\"Disadvantage: \"),\"Corner pixels don't contribute as much in feature detection.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Valid Connections: \"),\"Np Padding.\"),React.createElement(\"li\",null,React.createElement(\"b\",null,\"Same Connections: \"),\"Pad such that o/p is same.\")),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"2. Handwritten digits classification using CNN\"),React.createElement(\"i\",null,\"We will classify handwritten digits using a simple neural network (ANN) first and than repeat same thing with convolutional neural network. We will see how accuracy improves clickly when you use convolutional neural network.\"),React.createElement(\"br\",null),React.createElement(\"br\",null),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:childsFile2,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Using ANN for classification\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:classifications,language:\"js\",plugins:[\"line-numbers\"]})),React.createElement(\"br\",null),React.createElement(\"h3\",null,\"Using CNN for classification\"),React.createElement(\"div\",{style:titles},React.createElement(PrismCode,{code:pipes,language:\"js\",plugins:[\"line-numbers\"]}))))));}}]);return Convolutionals;}(Component);export default withStyles(styles)(Convolutionals);","map":{"version":3,"sources":["/home/mukeshs/Projects/edurights/src/components/angularjs/deepAngularjs/convolutionals.js"],"names":["React","Component","Prism","Grid","Paper","withStyles","List","Sidebar","PrismCode","logsvalues","titles","backgroundColor","padding","fontSize","redesign","height","width","styles","theme","paper","margin","spacing","smMargin","actionDiv","textAlign","childsFile","trim","images","normalize","artificial","imagesp","childsFile2","classifications","pipes","Convolutionals","setTimeout","highlightAll","classes","props"],"mappings":"6kBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,MAAOC,CAAAA,KAAP,KAAkB,SAAlB,CACA,OAASC,IAAT,CAAeC,KAAf,CAAsBC,UAAtB,CAAkCC,IAAlC,KAA8C,mBAA9C,CAEA,MAAO,0BAAP,CACA,MAAOC,CAAAA,OAAP,KAAoB,YAApB,CACA,MAAOC,CAAAA,SAAP,KAAsB,yBAAtB,CAEA,MAAOC,CAAAA,UAAP,KAAuB,qCAAvB,CAEA,GAAMC,CAAAA,MAAM,CAAG,CAAEC,eAAe,CAAE,SAAnB,CAA8BC,OAAO,CAAE,KAAvC,CAA8CC,QAAQ,CAAE,MAAxD,CAAf,CAEA,GAAMC,CAAAA,QAAQ,CAAG,CACfC,MAAM,CAAE,GADO,CAEfC,KAAK,CAAE,GAFQ,CAAjB,CAKA,GAAMC,CAAAA,MAAM,CAAG,QAATA,CAAAA,MAAS,CAAAC,KAAK,QAAK,CACvBC,KAAK,CAAE,CACLC,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADH,CAELT,OAAO,CAAEM,KAAK,CAACG,OAAN,CAAc,CAAd,CAFJ,CADgB,CAKvBC,QAAQ,CAAE,CACRF,MAAM,CAAEF,KAAK,CAACG,OAAN,CAAc,CAAd,CADA,CALa,CAQvBE,SAAS,CAAE,CACTC,SAAS,CAAE,QADF,CARY,CAAL,EAApB,CAcA,GAAMC,CAAAA,UAAU,CAAG,mLAQjBC,IARiB,EAAnB,CAUA,GAAMC,CAAAA,MAAM,CAAG,6MAQbD,IARa,EAAf,CAUA,GAAME,CAAAA,SAAS,CAAG,yDAGhBF,IAHgB,EAAlB,CAKA,GAAMG,CAAAA,UAAU,CAAG,unBAqBjBH,IArBiB,EAAnB,CAuBA,GAAMI,CAAAA,OAAO,CAAG,sxBA8BdJ,IA9Bc,EAAhB,CAgCA,GAAMK,CAAAA,WAAW,CAAG,oKAOlBL,IAPkB,EAApB,CASA,GAAMM,CAAAA,eAAe,CAAG,wcAgBtBN,IAhBsB,EAAxB,CAkBA,GAAMO,CAAAA,KAAK,CAAG,ybAgBZP,IAhBY,EAAd,CAkBA;GAGMQ,CAAAA,c,8TACgB,CAClBC,UAAU,CAAC,iBAAMjC,CAAAA,KAAK,CAACkC,YAAN,EAAN,EAAD,CAA6B,CAA7B,CAAV,CACD,C,uCACQ,IACCC,CAAAA,OADD,CACa,KAAKC,KADlB,CACCD,OADD,CAEP,MACE,qBAAC,IAAD,EAAM,SAAS,KAAf,EACE,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,CAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEA,OAAO,CAAClB,KAA1B,EACE,8BAAI,oBAAC,OAAD,MAAJ,CADF,CADF,CADF,CAME,oBAAC,IAAD,EAAM,IAAI,KAAV,CAAW,EAAE,CAAE,EAAf,EACE,oBAAC,KAAD,EAAO,SAAS,CAAEkB,OAAO,CAAClB,KAA1B,EACE,oBAAC,IAAD,MACE,uGADF,2RAKE,8BALF,CAME,8BANF,CAOE,2BAAK,GAAG,CAAEV,UAAV,CAAsB,GAAG,CAAC,QAA1B,CAAmC,SAAS,CAAC,aAA7C,CAA2D,KAAK,CAAEK,QAAlE,EAPF,CASE,2BAAK,KAAK,CAAEJ,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEe,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CATF,CAgBE,8BAhBF,CAkBE,sEAlBF,CAmBE,2BAAK,KAAK,CAAEf,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEiB,MADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAnBF,CA0BE,8BA1BF,CA4BE,8DA5BF,oMA+BE,8BA/BF,CAgCE,2BAAK,KAAK,CAAEjB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEkB,SADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAhCF,CAuCE,8BAvCF,CAyCE,gGAzCF,CA0CE,2BAAK,KAAK,CAAElB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEmB,UADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA1CF,CAiDE,8BAjDF,CAmDE,oGAnDF,8EAqDE,8BACE,0DADF,CAEE,0DAFF,CAGE,0DAHF,CArDF,CA0DE,8BA1DF,CA2DE,8BA3DF,CA6DE,oFA7DF,CA8DE,8BACE,yDADF,CAEE,gFAFF,CAGE,kFAHF,CA9DF,CAmEE,8BAnEF,CAoEE,8BApEF,CAsEE,2EAtEF,CAuEE,8BACE,2DADF,CAEE,yEAFF,CAvEF,CA2EE,8BA3EF,CA6EE,2BAAK,KAAK,CAAEnB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEoB,OADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA7EF,CAoFE,8BApFF,CAqFE,iVArFF,CAsFE,8BAtFF,CAwFE,wCAxFF,6CA0FE,8BA1FF,CA2FE,8BA3FF,CA4FE,oDA5FF,CA6FE,8BACE,mEADF,CAEE,kFAFF,CAGE,oFAHF,CA7FF,CAkGE,8BAlGF,CAoGE,4CApGF,CAqGE,8BACE,4EADF,CAEE,6FAFF,CAGE,qDAHF,CArGF,CA0GE,8BA1GF,CA2GE,8BA3GF,CA4GE,sFA5GF,CA6GE,8BACE,gGADF,CAEE,wKAFF,CA7GF,CAiHE,8BAjHF,CAkHE,8BAlHF,CAmHE,+DAnHF,CAoHE,8BACE,8BAAI,8CAAJ,gEADF,CAEE,8BAAI,mDAAJ,eAFF,CAGE,8BAAI,kDAAJ,8BAHF,CApHF,CAyHE,8BAzHF,CA2HE,+EA3HF,CA4HE,gQA5HF,CA+HE,8BA/HF,CAgIE,8BAhIF,CAiIE,2BAAK,KAAK,CAAEpB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEqB,WADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CAjIF,CAwIE,8BAxIF,CA0IE,6DA1IF,CA2IE,2BAAK,KAAK,CAAErB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEsB,eADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CA3IF,CAkJE,8BAlJF,CAoJE,6DApJF,CAqJE,2BAAK,KAAK,CAAEtB,MAAZ,EACE,oBAAC,SAAD,EACE,IAAI,CAAEuB,KADR,CAEE,QAAQ,CAAC,IAFX,CAGE,OAAO,CAAE,CAAC,cAAD,CAHX,EADF,CArJF,CADF,CADF,CANF,CADF,CA0KD,C,4BAhL0BhC,S,EAoL7B,cAAgBI,CAAAA,UAAU,CAACY,MAAD,CAAV,CAAmBiB,cAAnB,CAAhB","sourcesContent":["import React, { Component } from 'react';\nimport Prism from \"prismjs\"\nimport { Grid, Paper, withStyles, List } from \"@material-ui/core\";\n\nimport '../../ReactJs/styles.css'\nimport Sidebar from '../sidebar';\nimport PrismCode from '../../ReactJs/prismCode';\n\nimport logsvalues from '../../../assets/AI/convolutinal.png'\n\nconst titles = { backgroundColor: '#F0F8FF', padding: '1px', fontSize: '16px' }\n\nconst redesign = {\n  height: 200,\n  width: 500\n}\n\nconst styles = theme => ({\n  paper: {\n    margin: theme.spacing(1),\n    padding: theme.spacing(1)\n  },\n  smMargin: {\n    margin: theme.spacing(1)\n  },\n  actionDiv: {\n    textAlign: \"center\"\n  }\n})\n\n\nconst childsFile = `\n(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\nX_train.shape\nX_test.shape\ny_train[:5]\n\ny_train = y_train.reshape(-1,)\ny_test = y_test.reshape(-1,)\n`.trim();\n\nconst images = `\ndef plot_sample(X, y, index):\n    plt.figure(figsize = (15,2))\n    plt.imshow(X[index])\n    plt.xlabel(classes[y[index]])\n    \nplot_sample(X_train, y_train, 0)\nplot_sample(X_train, y_train, 1)\n`.trim();\n\nconst normalize = `\nX_train = X_train / 255.0\nX_test = X_test / 255.0\n`.trim();\n\nconst artificial = `\nann = models.Sequential([\n  layers.Flatten(input_shape=(32,32,3)),\n  layers.Dense(3000, activation='relu'),\n  layers.Dense(1000, activation='relu'),\n  layers.Dense(10, activation='sigmoid')    \n])\n\nann.compile(optimizer='SGD',\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy'])\n\nann.fit(X_train, y_train, epochs=5)\n\n\nfrom sklearn.metrics import confusion_matrix , classification_report\nimport numpy as np\ny_pred = ann.predict(X_test)\ny_pred_classes = [np.argmax(element) for element in y_pred]\n\nprint(\"Classification Report: nL\", classification_report(y_test, y_pred_classes))\n`.trim();\n\nconst imagesp = `\ncnn = models.Sequential([\n  layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n  layers.MaxPooling2D((2, 2)),\n  \n  layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n  layers.MaxPooling2D((2, 2)),\n  \n  layers.Flatten(),\n  layers.Dense(64, activation='relu'),\n  layers.Dense(10, activation='softmax')\n])\n\n\ncnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n              \ncnn.fit(X_train, y_train, epochs=10)\ncnn.evaluate(X_test,y_test)\ncnn.evaluate(X_test,y_test)\n\ny_pred = cnn.predict(X_test)\ny_pred[:5]\n\ny_classes = [np.argmax(element) for element in y_pred]\ny_classes[:5]\ny_test[:5]\n\nplot_sample(X_test, y_test,3)\nclasses[y_classes[3]]\nclasses[y_classes[3]]\n`.trim();\n\nconst childsFile2 = `\n(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()\nX_train.shape\nX_train[0].shape\n\nplt.matshow(X_train[0])\nX_train = X_train / 255\n`.trim();\n\nconst classifications = `\nmodel = keras.Sequential([\n  keras.layers.Flatten(input_shape=(28, 28)),\n  keras.layers.Dense(100, activation='relu'),\n  keras.layers.Dense(10, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=10)\nmodel.evaluate(X_test,y_test)\nX_train = X_train.reshape(-1,28,28,1)\nX_train.shape\n\nX_test = X_test.reshape(-1,28,28,1)\nX_test.shape\n`.trim();\n\nconst pipes = `\nmodel = keras.Sequential([\n    \n  layers.Conv2D(30, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  layers.MaxPooling2D((2,2)),\n\n  layers.Flatten(),\n  layers.Dense(100, activation='relu'),\n  keras.layers.Dense(10, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=5)\n\ny_train[:5]\nmodel.evaluate(X_test,y_test)\n`.trim();\n\n// const pipes = ``.trim();\n\n\nclass Convolutionals extends Component {\n  componentDidMount() {\n    setTimeout(() => Prism.highlightAll(), 0)\n  }\n  render() {\n    const { classes } = this.props;\n    return (\n      <Grid container>\n        <Grid item xs={2}>\n          <Paper className={classes.paper}>\n            <h4><Sidebar /></h4>\n          </Paper>\n        </Grid>\n        <Grid item xs={10}>\n          <Paper className={classes.paper}>\n            <List>\n              <h3>1. Small Image Classification Using Convolutional Neural Network (CNN)</h3>\n              In deep learning, CNN/ConvNet is a class of deep neural networks, most commonly applied to analyze visual imagery. In mathematics\n              convolution is a mathematical operation on two functions that produces a third function that expresses how the shape of one is modified by\n              the other.\n              <br />\n              <br />\n              <img src={logsvalues} alt=\"Theata\" className=\"responsive2\" style={redesign} />\n\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Plot some images to see what they are</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={images}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Normalizing the training data</h3>\n              Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel\n              can range from 0 to 255. Hence to normalize in 0--1 range, we need to divide it by 255.\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={normalize}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Build simple artificial neural network for image classification</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={artificial}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Now let us build a convolutional neural network to train our images</h3>\n              To handle variety in digits we use simple artificial Neural network (ANN).\n              <ul>\n                <li>1.Loopy Pattern detector.</li>\n                <li>2.Vertical line detector.</li>\n                <li>3.Diagonal line detector.</li>\n              </ul>\n              <br />\n              <br />\n\n              <b>Disadvantages of using ANN for image classification:</b>\n              <ul>\n                <li> 1.Too much computation.</li>\n                <li>2.Treats local pixels same as pixels far apart.</li>\n                <li>3.Sensitive to location of an object in an image.</li>\n              </ul>\n              <br />\n              <br />\n\n              <b>ReLU helps with making the model nonlinear.</b>\n              <ul>\n                <li>1.Introduces nonlinearity.</li>\n                <li>2.Speeds up training, faster to compute.</li>\n              </ul>\n              <br />\n\n              <div style={titles}>\n                <PrismCode\n                  code={imagesp}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n              <i>With CNN, at the end 5 epochs, accuracy was at around 70.28% which is a significant improvement over ANN. CNN's are best for image classification and gives superb accuracy. Also computation is much less compared to simple ANN as maxpooling reduces the image dimensions while still preserving the features.</i>\n              <br />\n\n              <h3>Pooling</h3>\n              Pooling layer is used to reduce the size.\n              <br />\n              <br />\n              <b>Benifits of Pooling:</b>\n              <ul>\n                <li>1.Reduce dimensions & computation.</li>\n                <li>2.Reduce overfitting as there are less parameter.</li>\n                <li>3.Model is tolerant towards variations, distotions.</li>\n              </ul>\n              <br />\n\n              <h3>Convolution</h3>\n              <ul>\n                <li>1.Connections sparsity reduces overfitting.</li>\n                <li>2.Conv + Pooling gives location invariant feature detection.</li>\n                <li>3.Parameter sharing.</li>\n              </ul>\n              <br />\n              <br />\n              <b>CNN by itself dpesn't take care of Rotation and Scale.</b>\n              <ul>\n                <li>1.You need to have rotated, scaled samples in training dataset.</li>\n                <li>2.If you don't have such samples than data augmentation methods to generate new rotated/ scaled samples from existing training samples.</li>\n              </ul>\n              <br />\n              <br />\n              <b>Convolution padding and stride:</b>\n              <ul>\n                <li><b>Disadvantage: </b>Corner pixels don't contribute as much in feature detection.</li>\n                <li><b>Valid Connections: </b>Np Padding.</li>\n                <li><b>Same Connections: </b>Pad such that o/p is same.</li>\n              </ul>\n              <br />\n\n              <h3>2. Handwritten digits classification using CNN</h3>\n              <i>We will classify handwritten digits using a simple neural network (ANN) first and than repeat same\n                thing with convolutional neural network. We will see how accuracy improves clickly when you use convolutional\n                neural network.</i>\n              <br />\n              <br />\n              <div style={titles}>\n                <PrismCode\n                  code={childsFile2}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Using ANN for classification</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={classifications}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n              <br />\n\n              <h3>Using CNN for classification</h3>\n              <div style={titles}>\n                <PrismCode\n                  code={pipes}\n                  language=\"js\"\n                  plugins={[\"line-numbers\"]}\n                />\n              </div>\n            </List>\n          </Paper>\n        </Grid>\n      </Grid>\n    )\n  }\n}\n\n\nexport default (withStyles(styles)(Convolutionals));\n"]},"metadata":{},"sourceType":"module"}
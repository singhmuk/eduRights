{"map":{"version":3,"sources":["static/js/9.9d95c142.chunk.js"],"names":["this","push","342","module","__webpack_exports__","__webpack_require__","d","Sidebar","react__WEBPACK_IMPORTED_MODULE_0__","react__WEBPACK_IMPORTED_MODULE_0___default","n","react_router_dom__WEBPACK_IMPORTED_MODULE_1__","_material_ui_core_MenuItem__WEBPACK_IMPORTED_MODULE_2__","_material_ui_core_MenuList__WEBPACK_IMPORTED_MODULE_3__","_material_ui_core_styles__WEBPACK_IMPORTED_MODULE_4__","useStyles","Object","theme","root","display","paper","marginRight","spacing","line","textDecoration","classes","a","createElement","className","to","347","exports","p","400","401","402","524","r","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_classCallCheck__WEBPACK_IMPORTED_MODULE_0__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_createClass__WEBPACK_IMPORTED_MODULE_1__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_possibleConstructorReturn__WEBPACK_IMPORTED_MODULE_2__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_getPrototypeOf__WEBPACK_IMPORTED_MODULE_3__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_inherits__WEBPACK_IMPORTED_MODULE_4__","react__WEBPACK_IMPORTED_MODULE_5__","react__WEBPACK_IMPORTED_MODULE_5___default","prismjs__WEBPACK_IMPORTED_MODULE_6__","prismjs__WEBPACK_IMPORTED_MODULE_6___default","_material_ui_core__WEBPACK_IMPORTED_MODULE_7__","_material_ui_core__WEBPACK_IMPORTED_MODULE_8__","_material_ui_core__WEBPACK_IMPORTED_MODULE_9__","_material_ui_core__WEBPACK_IMPORTED_MODULE_10__","_sidebar__WEBPACK_IMPORTED_MODULE_12__","_ReactJs_prismCode__WEBPACK_IMPORTED_MODULE_13__","_assets_ML_perceptrons_png__WEBPACK_IMPORTED_MODULE_14__","_assets_ML_perceptrons_png__WEBPACK_IMPORTED_MODULE_14___default","_assets_ML_perceptrons2_png__WEBPACK_IMPORTED_MODULE_15__","_assets_ML_perceptrons2_png__WEBPACK_IMPORTED_MODULE_15___default","_assets_ML_perceptrons3_png__WEBPACK_IMPORTED_MODULE_16__","_assets_ML_perceptrons3_png__WEBPACK_IMPORTED_MODULE_16___default","_assets_ML_perceptrons4_png__WEBPACK_IMPORTED_MODULE_17__","_assets_ML_perceptrons4_png__WEBPACK_IMPORTED_MODULE_17___default","titles","backgroundColor","padding","fontSize","redesign","height","width","stack","trim","label","testings","Perceptron","_Component","apply","arguments","key","value","setTimeout","highlightAll","props","container","item","xs","src","alt","style","code","language","plugins","margin","smMargin","actionDiv","textAlign"],"mappings":"CAACA,KAAK,iCAAmCA,KAAK,kCAAoC,IAAIC,KAAK,CAAC,CAAC,GAAG,CAE1FC,IACA,SAAUC,EAAQC,EAAqBC,GAE7C,aAC+BA,EAAoBC,EAAEF,EAAqB,KAAK,WAAa,OAAOG,KAC9E,IAAIC,EAAqCH,EAAoB,GACzDI,EAA0DJ,EAAoBK,EAAEF,GAChFG,EAAgDN,EAAoB,IACpEO,EAA0DP,EAAoB,IAC9EQ,EAA0DR,EAAoB,IAC9ES,EAAwDT,EAAoB,IACjGU,EAAUC,OAAOF,EAAuE,EAA9EE,EAAiF,SAASC,GAAO,MAAM,CAACC,KAAK,CAACC,QAAQ,QAAQC,MAAM,CAACC,YAAYJ,EAAMK,QAAQ,IAAIC,KAAK,CAACC,eAAe,YAAY,SAASjB,IAAU,IAAIkB,EAAQV,IAAY,OAAON,EAA2CiB,EAAEC,cAAc,MAAM,CAACC,UAAUH,EAAQP,MAAMT,EAA2CiB,EAAEC,cAAcd,EAAyE,EAAE,KAAKJ,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,UAAUD,UAAUH,EAAQF,MAAM,WAAWd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,oBAAoBD,UAAUH,EAAQF,MAAM,qBAAqBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,YAAYD,UAAUH,EAAQF,MAAM,YAAYd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,mBAAmBD,UAAUH,EAAQF,MAAM,oBAAoBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,eAAeD,UAAUH,EAAQF,MAAM,gBAAgBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,YAAYD,UAAUH,EAAQF,MAAM,aAAad,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,eAAeD,UAAUH,EAAQF,MAAM,iBAAiBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,SAASD,UAAUH,EAAQF,MAAM,QAAQd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,qBAAqBD,UAAUH,EAAQF,MAAM,uBAAuBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,eAAeD,UAAUH,EAAQF,MAAM,wBAAwBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,OAAOD,UAAUH,EAAQF,MAAM,QAAQd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,OAAOD,UAAUH,EAAQF,MAAM,QAAQd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,mBAAmBD,UAAUH,EAAQF,MAAM,WAAWd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,YAAYD,UAAUH,EAAQF,MAAM,gBAAgBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,gBAAgBD,UAAUH,EAAQF,MAAM,kBAAkBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,gBAAgBD,UAAUH,EAAQF,MAAM,kBAAkBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,SAASD,UAAUH,EAAQF,MAAM,QAAQd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,WAAWD,UAAUH,EAAQF,MAAM,UAAUd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,UAAUD,UAAUH,EAAQF,MAAM,WAAWd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,WAAWD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,sBAAsBD,UAAUH,EAAQF,MAAM,iBAAiBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,UAAUd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,aAAaD,UAAUH,EAAQF,MAAM,WAAWd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,WAAWD,UAAUH,EAAQF,MAAM,YAAYd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAc,KAAK,MAAM,gBAAgBlB,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,aAAaD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAc,MAAM,SAIx8RG,IACA,SAAU3B,EAAQ4B,EAAS1B,GAEjCF,EAAO4B,QAAU1B,EAAoB2B,EAAI,yCAInCC,IACA,SAAU9B,EAAQ4B,EAAS1B,GAEjCF,EAAO4B,QAAU1B,EAAoB2B,EAAI,0CAInCE,IACA,SAAU/B,EAAQ4B,EAAS1B,GAEjCF,EAAO4B,QAAU1B,EAAoB2B,EAAI,0CAInCG,IACA,SAAUhC,EAAQ4B,EAAS1B,GAEjCF,EAAO4B,QAAU1B,EAAoB2B,EAAI,0CAInCI,IACA,SAAUjC,EAAQC,EAAqBC,GAE7C,aACAA,EAAoBgC,EAAEjC,GACD,IAAIkC,EAAsHjC,EAAoB,GAC1IkC,EAAmHlC,EAAoB,GACvImC,EAAiInC,EAAoB,GACrJoC,EAAsHpC,EAAoB,GAC1IqC,EAAgHrC,EAAoB,GACpIsC,EAAqCtC,EAAoB,GACzDuC,EAA0DvC,EAAoBK,EAAEiC,GAChFE,EAAuCxC,EAAoB,GAC3DyC,EAA4DzC,EAAoBK,EAAEmC,GAClFE,EAAiD1C,EAAoB,GACrE2C,EAAiD3C,EAAoB,GACrE4C,EAAiD5C,EAAoB,IACrE6C,EAAkD7C,EAAoB,IAGtE8C,GAFoD9C,EAAoB,IAE/BA,EAAoB,MAC7D+C,EAAmD/C,EAAoB,GACvEgD,EAA2DhD,EAAoB,KAC/EiD,EAAgFjD,EAAoBK,EAAE2C,GACtGE,EAA4DlD,EAAoB,KAChFmD,EAAiFnD,EAAoBK,EAAE6C,GACvGE,EAA4DpD,EAAoB,KAChFqD,EAAiFrD,EAAoBK,EAAE+C,GACvGE,EAA4DtD,EAAoB,KAChFuD,EAAiFvD,EAAoBK,EAAEiD,GAC5HE,EAAO,CAACC,gBAAgB,UAAUC,QAAQ,MAAMC,SAAS,QAAYC,EAAS,CAACC,OAAO,IAAIC,MAAM,KAAgLC,EAAM,ipCAAipCC,OAAWC,EAAM,+DAA+DD,OAAWE,EAAS,0tCAAkuCF,OAC7uFG,EAAwB,SAASC,GAA4K,SAASD,IAA6K,OAAhKxD,OAAOsB,EAAqI,EAA5ItB,CAA+IhB,KAAKwE,GAAmBxD,OAAOwB,EAAgJ,EAAvJxB,CAA0JhB,KAAKgB,OAAOyB,EAAqI,EAA5IzB,CAA+IwD,GAAYE,MAAM1E,KAAK2E,YAAo7Q,OAAtlS3D,OAAO0B,EAA+H,EAAtI1B,CAAyIwD,EAAWC,GAA2hBzD,OAAOuB,EAAkI,EAAzIvB,CAA4IwD,EAAW,CAAC,CAACI,IAAI,oBAAoBC,MAAM,WAA6BC,YAAW,WAAW,OAAOhC,EAA6CpB,EAAEqD,iBAAiB,KAAM,CAACH,IAAI,SAASC,MAAM,WAAkB,IAAIpD,EAAQzB,KAAKgF,MAAMvD,QAAQ,OAAOmB,EAA2ClB,EAAEC,cAAcoB,EAAgE,EAAE,CAACkC,WAAU,GAAMrC,EAA2ClB,EAAEC,cAAcoB,EAAgE,EAAE,CAACmC,MAAK,EAAKC,GAAG,GAAGvC,EAA2ClB,EAAEC,cAAcqB,EAAgE,EAAE,CAACpB,UAAUH,EAAQL,OAAOwB,EAA2ClB,EAAEC,cAAc,KAAK,KAAKiB,EAA2ClB,EAAEC,cAAcwB,EAAwD,EAAE,SAASP,EAA2ClB,EAAEC,cAAcoB,EAAgE,EAAE,CAACmC,MAAK,EAAKC,GAAG,IAAIvC,EAA2ClB,EAAEC,cAAcqB,EAAgE,EAAE,CAACpB,UAAUH,EAAQL,OAAOwB,EAA2ClB,EAAEC,cAAcsB,EAAgE,EAAE,KAAKL,EAA2ClB,EAAEC,cAAc,KAAK,KAAK,+CAA+C,sKAAsKiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,IAAI,KAAK,2EAA2EiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,qUAAqUiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAKiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAK,mHAAmHiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAKiB,EAA2ClB,EAAEC,cAAc,IAAI,KAAK,4BAA4B,4BAA4BiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAKiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAK,sBAAsBiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAK,qMAAqMiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAK,sDAAsDiB,EAA2ClB,EAAEC,cAAc,IAAI,KAAK,uBAAuB,oFAAoFiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,MAAM,CAACyD,IAAI9B,EAAiE5B,EAAE2D,IAAI,YAAYzD,UAAU,aAAa0D,MAAMrB,IAAWrB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,gEAAgEiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,IAAI,KAAK,2BAA2B,qCAAqCiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,IAAI,KAAK,0BAA0B,sCAAsCiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,IAAI,KAAK,8BAA8BiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,8HAA8HiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,MAAM,CAACyD,IAAI5B,EAAkE9B,EAAE2D,IAAI,YAAYzD,UAAU,aAAa0D,MAAMrB,IAAWrB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,qHAAqHiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,0KAA0KiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,oCAAoCiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,wCAAwCiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,kBAAkBiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,oBAAoBiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,MAAM,CAACyD,IAAI1B,EAAkEhC,EAAE2D,IAAI,YAAYzD,UAAU,aAAa0D,MAAMrB,IAAWrB,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,yMAAyMiB,EAA2ClB,EAAEC,cAAc,MAAM,CAAC2D,MAAMzB,GAAQjB,EAA2ClB,EAAEC,cAAcyB,EAAkE,EAAE,CAACmC,KAAKjB,EAAMkB,SAAS,KAAKC,QAAQ,CAAC,mBAAmB7C,EAA2ClB,EAAEC,cAAc,KAAK,MAAM,8GAA8GiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,MAAM,CAACyD,IAAIxB,EAAkElC,EAAE2D,IAAI,YAAYzD,UAAU,aAAa0D,MAAMrB,IAAWrB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,IAAI,KAAK,4FAA4FiB,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAK,WAAWiB,EAA2ClB,EAAEC,cAAc,MAAM,CAAC2D,MAAMzB,GAAQjB,EAA2ClB,EAAEC,cAAcyB,EAAkE,EAAE,CAACmC,KAAKnB,EAAMoB,SAAS,KAAKC,QAAQ,CAAC,mBAAmB7C,EAA2ClB,EAAEC,cAAc,KAAK,MAAMiB,EAA2ClB,EAAEC,cAAc,KAAK,KAAK,WAAWiB,EAA2ClB,EAAEC,cAAc,MAAM,CAAC2D,MAAMzB,GAAQjB,EAA2ClB,EAAEC,cAAcyB,EAAkE,EAAE,CAACmC,KAAKhB,EAASiB,SAAS,KAAKC,QAAQ,CAAC,2BAAmCjB,EAAlnS,CAA+nS7B,EAA8C,WAAgCvC,EAA6B,QAAKY,OAAOkC,EAAiE,EAAxElC,EADvpS,SAAgBC,GAAO,MAAM,CAACG,MAAM,CAACsE,OAAOzE,EAAMK,QAAQ,GAAGyC,QAAQ9C,EAAMK,QAAQ,IAAIqE,SAAS,CAACD,OAAOzE,EAAMK,QAAQ,IAAIsE,UAAU,CAACC,UAAU,aACugS,CAAoFrB"},"code":"(this[\"webpackJsonpmern-stack-client\"]=this[\"webpackJsonpmern-stack-client\"]||[]).push([[9],{342:function(e,a,t){\"use strict\";t.d(a,\"a\",(function(){return u}));var n=t(0),l=t.n(n),r=t(12),i=t(14),s=t(50),c=t(49),o=Object(c.a)((function(e){return{root:{display:\"flex\"},paper:{marginRight:e.spacing(2)},line:{textDecoration:\"none\"}}}));function u(){var e=o();return l.a.createElement(\"div\",{className:e.root},l.a.createElement(s.a,null,l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/infoMl\",className:e.line},\"InfoMl\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/gredient_decents\",className:e.line},\"Gredient Decents\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/training\",className:e.line},\"Traning\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/regularizations\",className:e.line},\"Regularizations\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/featuresEng\",className:e.line},\"FeaturesEng\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/adaboost\",className:e.line},\"Adaboots\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/greedSearch\",className:e.line},\"Greed Search\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/perceptron\",className:e.line},\"Perceptron\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/pcaPy\",className:e.line},\"PCA\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/leanearRegression\",className:e.line},\"Leanear Regression\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/logisticReg\",className:e.line},\"Logistic Regression\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/lda\",className:e.line},\"Lda\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/knn\",className:e.line},\"Knn\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/k_meanClustring\",className:e.line},\"K_Mean\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/naiveBar\",className:e.line},\"Naive Bayes\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/randomForest\",className:e.line},\"Random Forest\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/decisiontree\",className:e.line},\"Decision Tree\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/svmPy\",className:e.line},\"SVM\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/numpyPy\",className:e.line},\"Numpy\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/pandas\",className:e.line},\"Pandas\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/bagging\",className:e.line},\"Matplotlib\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/logisticRegrations\",className:e.line},\"Scikit Learn\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/regrations\",className:e.line},\"SciPy\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/libraries\",className:e.line},\"OpenCV\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/capture\",className:e.line},\"Capture\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/joinImages\",className:e.line},\"JoinImages\")),l.a.createElement(\"br\",null),\"Deep Learning\",l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/superwise\",className:e.line},\"Superwise\"))),l.a.createElement(\"div\",null))}},347:function(e,a,t){e.exports=t.p+\"static/media/perceptrons.f6ad4ad3.png\"},400:function(e,a,t){e.exports=t.p+\"static/media/perceptrons2.5c2b5a03.png\"},401:function(e,a,t){e.exports=t.p+\"static/media/perceptrons3.82c24adc.png\"},402:function(e,a,t){e.exports=t.p+\"static/media/perceptrons4.5617a654.png\"},524:function(e,a,t){\"use strict\";t.r(a);var n=t(4),l=t(3),r=t(5),i=t(6),s=t(8),c=t(0),o=t.n(c),u=t(7),m=t.n(u),p=t(2),d=t(9),E=t(13),b=t(11),f=(t(16),t(342)),g=t(1),h=t(347),_=t.n(h),y=t(400),w=t.n(y),x=t(401),N=t.n(x),v=t(402),k=t.n(v),X={backgroundColor:\"#F0F8FF\",padding:\"1px\",fontSize:\"16px\"},P={height:350,width:600},T=\"\\nimport numpy as np\\n\\nclass Perceptron:\\n    def __init__(self, learning_rate=0.01, n_iters=1000):\\n        self.lr = learning_rate\\n        self.n_iters = n_iters\\n        self.activation_func = self._unit_step_func\\n        self.weights = None\\n        self.bias = None\\n\\n    def fit(self, X, y):\\n        n_samples, n_features = X.shape\\n\\n        # init parameters\\n        self.weights = np.zeros(n_features)\\n        self.bias = 0\\n\\n        y_ = np.array([1 if i > 0 else 0 for i in y])\\n\\n        for _ in range(self.n_iters):\\n\\n            for idx, x_i in enumerate(X):\\n\\n                linear_output = np.dot(x_i, self.weights) + self.bias\\n                y_predicted = self.activation_func(linear_output)\\n\\n                # Perceptron update rule\\n                update = self.lr * (y_[idx] - y_predicted)\\n\\n                self.weights += update * x_i\\n                self.bias += update\\n\\n    def predict(self, X):\\n        linear_output = np.dot(X, self.weights) + self.bias\\n        y_predicted = self.activation_func(linear_output)\\n        return y_predicted\\n\\n    def _unit_step_func(self, x):\\n        return np.where(x >= 0, 1, 0)\\n\".trim(),j=\"\\nif 0.5x + 0.5y => 0, then 1\\nif 0.5x + 0.5y < 0, then 0.\\n\".trim(),A='\\nif __name__ == \"__main__\":\\n    # Imports\\n    import matplotlib.pyplot as plt\\n    from sklearn.model_selection import train_test_split\\n    from sklearn import datasets\\n\\n    def accuracy(y_true, y_pred):\\n        accuracy = np.sum(y_true == y_pred) / len(y_true)\\n        return accuracy\\n\\n    X, y = datasets.make_blobs(\\n        n_samples=150, n_features=2, centers=2, cluster_std=1.05, random_state=2\\n    )\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X, y, test_size=0.2, random_state=123\\n    )\\n\\n    p = Perceptron(learning_rate=0.01, n_iters=1000)\\n    p.fit(X_train, y_train)\\n    predictions = p.predict(X_test)\\n\\n    print(\"Perceptron classification accuracy\", accuracy(y_test, predictions))\\n\\n    fig = plt.figure()\\n    ax = fig.add_subplot(1, 1, 1)\\n    plt.scatter(X_train[:, 0], X_train[:, 1], marker=\"o\", c=y_train)\\n\\n    x0_1 = np.amin(X_train[:, 0])\\n    x0_2 = np.amax(X_train[:, 0])\\n\\n    x1_1 = (-p.weights[0] * x0_1 - p.bias) / p.weights[1]\\n    x1_2 = (-p.weights[0] * x0_2 - p.bias) / p.weights[1]\\n\\n    ax.plot([x0_1, x0_2], [x1_1, x1_2], \"k\")\\n\\n    ymin = np.amin(X_train[:, 1])\\n    ymax = np.amax(X_train[:, 1])\\n    ax.set_ylim([ymin - 3, ymax + 3])\\n\\n    plt.show()\\n    '.trim(),F=function(e){function a(){return Object(n.a)(this,a),Object(r.a)(this,Object(i.a)(a).apply(this,arguments))}return Object(s.a)(a,e),Object(l.a)(a,[{key:\"componentDidMount\",value:function(){setTimeout((function(){return m.a.highlightAll()}),0)}},{key:\"render\",value:function(){var e=this.props.classes;return o.a.createElement(p.a,{container:!0},o.a.createElement(p.a,{item:!0,xs:2},o.a.createElement(d.a,{className:e.paper},o.a.createElement(\"h4\",null,o.a.createElement(f.a,null)))),o.a.createElement(p.a,{item:!0,xs:10},o.a.createElement(d.a,{className:e.paper},o.a.createElement(E.a,null,o.a.createElement(\"h3\",null,\"Perceptron \\u2013 Basics of Neural Networks\"),\"A single-layer perceptron is the basic unit of a neural network. A perceptron consists of input values, weights and a bias, a weighted sum and activation function.\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),o.a.createElement(\"i\",null,\"Perceptron consists of one/ more inputs, a processor, and only one o/p.\"),o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"A perceptron works by taking in some numerical i/p along with what is known as weights and a bias. It then multiplies these i/p with the respective weights(weighted sum). These products are then added together along with the bias. The activation function takes the weighted sum and the bias as i/p and returns a final o/p.\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),o.a.createElement(\"ul\",null,o.a.createElement(\"li\",null,\"A perceptron consists of four parts: input values, weights and a bias, a weighted sum, and activation function.\"),o.a.createElement(\"li\",null,o.a.createElement(\"b\",null,\"Function may look like: \"),\"y = xw + x2w2 +...+ xnwn\"),o.a.createElement(\"ul\",null,o.a.createElement(\"li\",null,\"bias  is alwase 1.\"),o.a.createElement(\"li\",null,\"This function is called the weighted sum because it is the sum of the weights and inputs. This looks like a good function, but what if we wanted the outputs to fall into a certain range 0 to 1.\"),o.a.createElement(\"li\",null,\"We can do this by using an activation function. An \",o.a.createElement(\"b\",null,\"activation function\"),\" is a function that converts the i/p into a certain o/p based on a set of rules.\"),o.a.createElement(\"br\",null),o.a.createElement(\"img\",{src:_.a,alt:\"Equations\",className:\"responsive\",style:P}),o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"There are different kinds of activation functions that exist.\",o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"1. Hyperbolic Tangent: \"),\"Used to o/p a number from -1 to 1.\",o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"2. Logistic Function: \"),\"Used to o/p a number from 0 to 1.\")),o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"Why are perceptron's used?\"),o.a.createElement(\"br\",null),\"Perceptrons are the building blocks of neural networks. It is typically used for supervised learning of binary classifiers.\",o.a.createElement(\"br\",null),o.a.createElement(\"img\",{src:w.a,alt:\"Equations\",className:\"responsive\",style:P}),o.a.createElement(\"br\",null),\"Suppose our goal was to separates this data so that there is a distinction between the blue dots and the red dots.\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"A perceptron can create a decision boundary for a binary classification, where a decision boundary is regions of space on a graph that separates different data points.\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"Let wx = -0.5, wy = 0.5 and b = 0\",o.a.createElement(\"br\",null),\"Then the function for the perceptron.\",o.a.createElement(\"br\",null),\"0.5x + 0.5y = 0\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"and the graph is.\",o.a.createElement(\"br\",null),o.a.createElement(\"img\",{src:N.a,alt:\"Equations\",className:\"responsive\",style:P}),o.a.createElement(\"br\",null),\"Let\\u2019s suppose that the activation function, in this case, is a simple step function that outputs either 0 or 1. The perceptron function will then label the blue dots as 1 and the red dots as 0.\",o.a.createElement(\"div\",{style:X},o.a.createElement(g.a,{code:j,language:\"js\",plugins:[\"line-numbers\"]})),o.a.createElement(\"br\",null),\"Therefore, the function 0.5x + 0.5y = 0 creates a decision boundary that separates the red and blue points.\",o.a.createElement(\"br\",null),o.a.createElement(\"img\",{src:k.a,alt:\"Equations\",className:\"responsive\",style:P}),o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"Overall, we see that a perceptron can do basic classification using a decision boundary.\"),o.a.createElement(\"br\",null),o.a.createElement(\"h3\",null,\"Example\"),o.a.createElement(\"div\",{style:X},o.a.createElement(g.a,{code:T,language:\"js\",plugins:[\"line-numbers\"]})),o.a.createElement(\"br\",null),o.a.createElement(\"h3\",null,\"Testing\"),o.a.createElement(\"div\",{style:X},o.a.createElement(g.a,{code:A,language:\"js\",plugins:[\"line-numbers\"]}))))))}}]),a}(c.Component);a.default=Object(b.a)((function(e){return{paper:{margin:e.spacing(1),padding:e.spacing(1)},smMargin:{margin:e.spacing(1)},actionDiv:{textAlign:\"center\"}}}))(F)}}]);","extractedComments":[]}
{"map":{"version":3,"sources":["static/js/14.3c51bd28.chunk.js"],"names":["this","push","140","module","__webpack_exports__","__webpack_require__","d","PrismCode","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_classCallCheck__WEBPACK_IMPORTED_MODULE_0__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_createClass__WEBPACK_IMPORTED_MODULE_1__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_possibleConstructorReturn__WEBPACK_IMPORTED_MODULE_2__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_getPrototypeOf__WEBPACK_IMPORTED_MODULE_3__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_inherits__WEBPACK_IMPORTED_MODULE_4__","react__WEBPACK_IMPORTED_MODULE_5__","react__WEBPACK_IMPORTED_MODULE_5___default","n","prismjs__WEBPACK_IMPORTED_MODULE_6__","prismjs__WEBPACK_IMPORTED_MODULE_6___default","_React$Component","props","_this","Object","call","highlight","ref","current","a","highlightElement","createRef","key","value","_this$props","code","language","plugins","createElement","className","concat","trim","Component","141","exports","146","Sidebar","react__WEBPACK_IMPORTED_MODULE_0__","react__WEBPACK_IMPORTED_MODULE_0___default","react_router_dom__WEBPACK_IMPORTED_MODULE_1__","_material_ui_core_MenuItem__WEBPACK_IMPORTED_MODULE_2__","_material_ui_core_MenuList__WEBPACK_IMPORTED_MODULE_3__","_material_ui_core_styles__WEBPACK_IMPORTED_MODULE_4__","useStyles","theme","root","display","paper","marginRight","spacing","line","textDecoration","classes","to","164","p","247","248","249","520","r","_material_ui_core__WEBPACK_IMPORTED_MODULE_7__","_material_ui_core__WEBPACK_IMPORTED_MODULE_8__","_material_ui_core__WEBPACK_IMPORTED_MODULE_9__","_material_ui_core__WEBPACK_IMPORTED_MODULE_10__","_sidebar__WEBPACK_IMPORTED_MODULE_12__","_ReactJs_prismCode__WEBPACK_IMPORTED_MODULE_13__","_assets_ML_perceptrons_png__WEBPACK_IMPORTED_MODULE_14__","_assets_ML_perceptrons_png__WEBPACK_IMPORTED_MODULE_14___default","_assets_ML_perceptrons2_png__WEBPACK_IMPORTED_MODULE_15__","_assets_ML_perceptrons2_png__WEBPACK_IMPORTED_MODULE_15___default","_assets_ML_perceptrons3_png__WEBPACK_IMPORTED_MODULE_16__","_assets_ML_perceptrons3_png__WEBPACK_IMPORTED_MODULE_16___default","_assets_ML_perceptrons4_png__WEBPACK_IMPORTED_MODULE_17__","_assets_ML_perceptrons4_png__WEBPACK_IMPORTED_MODULE_17___default","titles","backgroundColor","padding","fontSize","redesign","height","width","stack","label","testings","Perceptron","_Component","apply","arguments","setTimeout","highlightAll","container","item","xs","src","alt","style","margin","smMargin","actionDiv","textAlign"],"mappings":"CAACA,KAAK,iCAAmCA,KAAK,kCAAoC,IAAIC,KAAK,CAAC,CAAC,IAAI,CAE3FC,IACA,SAAUC,EAAQC,EAAqBC,GAE7C,aAC+BA,EAAoBC,EAAEF,EAAqB,KAAK,WAAa,OAAOG,KAC9E,IAAIC,EAAsHH,EAAoB,IAC1II,EAAmHJ,EAAoB,IACvIK,EAAiIL,EAAoB,KACrJM,EAAsHN,EAAoB,KAC1IO,EAAgHP,EAAoB,KACpIQ,EAAqCR,EAAoB,GACzDS,EAA0DT,EAAoBU,EAAEF,GAChFG,EAAuCX,EAAoB,KAC3DY,EAA4DZ,EAAoBU,EAAEC,GAGvGT,GAF+EF,EAAoB,IAE5E,SAASa,GAAuL,SAASX,EAAUY,GAAO,IAAIC,EAA2sB,OAArsBC,OAAOb,EAAqI,EAA5Ia,CAA+IrB,KAAKO,IAAWa,EAAMC,OAAOX,EAAgJ,EAAvJW,CAA0JrB,KAAKqB,OAAOV,EAAqI,EAA5IU,CAA+Id,GAAWe,KAAKtB,KAAKmB,KAAcI,UAAU,WAAcH,EAAMI,KAAKJ,EAAMI,IAAIC,SAASR,EAA6CS,EAAEC,iBAAiBP,EAAMI,IAAIC,UAAYL,EAAMI,IAAIV,EAA2CY,EAAEE,YAAmBR,EAA6rB,OAAllDC,OAAOT,EAA+H,EAAtIS,CAAyId,EAAUW,GAAywBG,OAAOZ,EAAkI,EAAzIY,CAA4Id,EAAU,CAAC,CAACsB,IAAI,oBAAoBC,MAAM,WAA6B9B,KAAKuB,cAAe,CAACM,IAAI,qBAAqBC,MAAM,WAA8B9B,KAAKuB,cAAe,CAACM,IAAI,SAASC,MAAM,WAAkB,IAAIC,EAAY/B,KAAKmB,MAAMa,EAAKD,EAAYC,KAAiCC,GAApBF,EAAYG,QAAiBH,EAAYE,UAAS,OAAOnB,EAA2CY,EAAES,cAAc,MAAM,CAACC,UAAU,cAActB,EAA2CY,EAAES,cAAc,OAAO,CAACX,IAAIxB,KAAKwB,IAAIY,UAAU,YAAYC,OAAOJ,IAAWD,EAAKM,aAAqB/B,EAApnD,CAAgoDO,EAA2CY,EAAEa,aAIlsDC,IACA,SAAUrC,EAAQsC,EAASpC,KAM3BqC,IACA,SAAUvC,EAAQC,EAAqBC,GAE7C,aAC+BA,EAAoBC,EAAEF,EAAqB,KAAK,WAAa,OAAOuC,KAC9E,IAAIC,EAAqCvC,EAAoB,GACzDwC,EAA0DxC,EAAoBU,EAAE6B,GAChFE,EAAgDzC,EAAoB,IACpE0C,EAA0D1C,EAAoB,KAC9E2C,EAA0D3C,EAAoB,KAC9E4C,EAAwD5C,EAAoB,KACjG6C,EAAU7B,OAAO4B,EAAuE,EAA9E5B,EAAiF,SAAS8B,GAAO,MAAM,CAACC,KAAK,CAACC,QAAQ,QAAQC,MAAM,CAACC,YAAYJ,EAAMK,QAAQ,IAAIC,KAAK,CAACC,eAAe,YAAY,SAASf,IAAU,IAAIgB,EAAQT,IAAY,OAAOL,EAA2CnB,EAAES,cAAc,MAAM,CAACC,UAAUuB,EAAQP,MAAMP,EAA2CnB,EAAES,cAAca,EAAyE,EAAE,KAAKH,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,UAAUxB,UAAUuB,EAAQF,MAAM,WAAWZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,oBAAoBxB,UAAUuB,EAAQF,MAAM,qBAAqBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,YAAYxB,UAAUuB,EAAQF,MAAM,YAAYZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,mBAAmBxB,UAAUuB,EAAQF,MAAM,oBAAoBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,eAAexB,UAAUuB,EAAQF,MAAM,gBAAgBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,YAAYxB,UAAUuB,EAAQF,MAAM,aAAaZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,eAAexB,UAAUuB,EAAQF,MAAM,iBAAiBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,cAAcxB,UAAUuB,EAAQF,MAAM,eAAeZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,SAASxB,UAAUuB,EAAQF,MAAM,QAAQZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,qBAAqBxB,UAAUuB,EAAQF,MAAM,uBAAuBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,eAAexB,UAAUuB,EAAQF,MAAM,wBAAwBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,OAAOxB,UAAUuB,EAAQF,MAAM,QAAQZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,OAAOxB,UAAUuB,EAAQF,MAAM,QAAQZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,mBAAmBxB,UAAUuB,EAAQF,MAAM,WAAWZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,YAAYxB,UAAUuB,EAAQF,MAAM,gBAAgBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,gBAAgBxB,UAAUuB,EAAQF,MAAM,kBAAkBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,gBAAgBxB,UAAUuB,EAAQF,MAAM,kBAAkBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,SAASxB,UAAUuB,EAAQF,MAAM,QAAQZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,WAAWxB,UAAUuB,EAAQF,MAAM,UAAUZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,UAAUxB,UAAUuB,EAAQF,MAAM,WAAWZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,WAAWxB,UAAUuB,EAAQF,MAAM,eAAeZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,sBAAsBxB,UAAUuB,EAAQF,MAAM,iBAAiBZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,cAAcxB,UAAUuB,EAAQF,MAAM,UAAUZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,aAAaxB,UAAUuB,EAAQF,MAAM,WAAWZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,WAAWxB,UAAUuB,EAAQF,MAAM,YAAYZ,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,cAAcxB,UAAUuB,EAAQF,MAAM,eAAeZ,EAA2CnB,EAAES,cAAc,KAAK,MAAM,gBAAgBU,EAA2CnB,EAAES,cAAcY,EAAyE,EAAE,KAAKF,EAA2CnB,EAAES,cAAcW,EAA4D,EAAE,CAACc,GAAG,aAAaxB,UAAUuB,EAAQF,MAAM,eAAeZ,EAA2CnB,EAAES,cAAc,MAAM,SAIx8R0B,IACA,SAAU1D,EAAQsC,EAASpC,GAEjCF,EAAOsC,QAAUpC,EAAoByD,EAAI,yCAInCC,IACA,SAAU5D,EAAQsC,EAASpC,GAEjCF,EAAOsC,QAAUpC,EAAoByD,EAAI,0CAInCE,IACA,SAAU7D,EAAQsC,EAASpC,GAEjCF,EAAOsC,QAAUpC,EAAoByD,EAAI,0CAInCG,IACA,SAAU9D,EAAQsC,EAASpC,GAEjCF,EAAOsC,QAAUpC,EAAoByD,EAAI,0CAInCI,IACA,SAAU/D,EAAQC,EAAqBC,GAE7C,aACAA,EAAoB8D,EAAE/D,GACD,IAAII,EAAsHH,EAAoB,IAC1II,EAAmHJ,EAAoB,IACvIK,EAAiIL,EAAoB,KACrJM,EAAsHN,EAAoB,KAC1IO,EAAgHP,EAAoB,KACpIQ,EAAqCR,EAAoB,GACzDS,EAA0DT,EAAoBU,EAAEF,GAChFG,EAAuCX,EAAoB,KAC3DY,EAA4DZ,EAAoBU,EAAEC,GAClFoD,EAAiD/D,EAAoB,KACrEgE,EAAiDhE,EAAoB,IACrEiE,EAAiDjE,EAAoB,KACrEkE,EAAkDlE,EAAoB,GAGtEmE,GAFoDnE,EAAoB,KAE/BA,EAAoB,MAC7DoE,EAAmDpE,EAAoB,KACvEqE,EAA2DrE,EAAoB,KAC/EsE,EAAgFtE,EAAoBU,EAAE2D,GACtGE,EAA4DvE,EAAoB,KAChFwE,EAAiFxE,EAAoBU,EAAE6D,GACvGE,EAA4DzE,EAAoB,KAChF0E,EAAiF1E,EAAoBU,EAAE+D,GACvGE,EAA4D3E,EAAoB,KAChF4E,EAAiF5E,EAAoBU,EAAEiE,GAC5HE,EAAO,CAACC,gBAAgB,UAAUC,QAAQ,MAAMC,SAAS,QAAYC,EAAS,CAACC,OAAO,IAAIC,MAAM,KAAgLC,EAAM,ipCAAipCnD,OAAWoD,EAAM,+DAA+DpD,OAAWqD,EAAS,0tCAAkuCrD,OAC7uFsD,EAAwB,SAASC,GAA4K,SAASD,IAA6K,OAAhKvE,OAAOb,EAAqI,EAA5Ia,CAA+IrB,KAAK4F,GAAmBvE,OAAOX,EAAgJ,EAAvJW,CAA0JrB,KAAKqB,OAAOV,EAAqI,EAA5IU,CAA+IuE,GAAYE,MAAM9F,KAAK+F,YAAo7Q,OAAtlS1E,OAAOT,EAA+H,EAAtIS,CAAyIuE,EAAWC,GAA2hBxE,OAAOZ,EAAkI,EAAzIY,CAA4IuE,EAAW,CAAC,CAAC/D,IAAI,oBAAoBC,MAAM,WAA6BkE,YAAW,WAAW,OAAO/E,EAA6CS,EAAEuE,iBAAiB,KAAM,CAACpE,IAAI,SAASC,MAAM,WAAkB,IAAI6B,EAAQ3D,KAAKmB,MAAMwC,QAAQ,OAAO7C,EAA2CY,EAAES,cAAciC,EAAgE,EAAE,CAAC8B,WAAU,GAAMpF,EAA2CY,EAAES,cAAciC,EAAgE,EAAE,CAAC+B,MAAK,EAAKC,GAAG,GAAGtF,EAA2CY,EAAES,cAAckC,EAAgE,EAAE,CAACjC,UAAUuB,EAAQL,OAAOxC,EAA2CY,EAAES,cAAc,KAAK,KAAKrB,EAA2CY,EAAES,cAAcqC,EAAwD,EAAE,SAAS1D,EAA2CY,EAAES,cAAciC,EAAgE,EAAE,CAAC+B,MAAK,EAAKC,GAAG,IAAItF,EAA2CY,EAAES,cAAckC,EAAgE,EAAE,CAACjC,UAAUuB,EAAQL,OAAOxC,EAA2CY,EAAES,cAAcmC,EAAgE,EAAE,KAAKxD,EAA2CY,EAAES,cAAc,KAAK,KAAK,+CAA+C,sKAAsKrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,IAAI,KAAK,2EAA2ErB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,MAAM,qUAAqUrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,KAAKrB,EAA2CY,EAAES,cAAc,KAAK,KAAK,mHAAmHrB,EAA2CY,EAAES,cAAc,KAAK,KAAKrB,EAA2CY,EAAES,cAAc,IAAI,KAAK,4BAA4B,4BAA4BrB,EAA2CY,EAAES,cAAc,KAAK,KAAKrB,EAA2CY,EAAES,cAAc,KAAK,KAAK,sBAAsBrB,EAA2CY,EAAES,cAAc,KAAK,KAAK,qMAAqMrB,EAA2CY,EAAES,cAAc,KAAK,KAAK,sDAAsDrB,EAA2CY,EAAES,cAAc,IAAI,KAAK,uBAAuB,oFAAoFrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,MAAM,CAACkE,IAAI1B,EAAiEjD,EAAE4E,IAAI,YAAYlE,UAAU,aAAamE,MAAMjB,IAAWxE,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,MAAM,gEAAgErB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,IAAI,KAAK,2BAA2B,qCAAqCrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,IAAI,KAAK,0BAA0B,sCAAsCrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,IAAI,KAAK,8BAA8BrB,EAA2CY,EAAES,cAAc,KAAK,MAAM,8HAA8HrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,MAAM,CAACkE,IAAIxB,EAAkEnD,EAAE4E,IAAI,YAAYlE,UAAU,aAAamE,MAAMjB,IAAWxE,EAA2CY,EAAES,cAAc,KAAK,MAAM,qHAAqHrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,MAAM,0KAA0KrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,MAAM,oCAAoCrB,EAA2CY,EAAES,cAAc,KAAK,MAAM,wCAAwCrB,EAA2CY,EAAES,cAAc,KAAK,MAAM,kBAAkBrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,MAAM,oBAAoBrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,MAAM,CAACkE,IAAItB,EAAkErD,EAAE4E,IAAI,YAAYlE,UAAU,aAAamE,MAAMjB,IAAWxE,EAA2CY,EAAES,cAAc,KAAK,MAAM,yMAAyMrB,EAA2CY,EAAES,cAAc,MAAM,CAACoE,MAAMrB,GAAQpE,EAA2CY,EAAES,cAAcsC,EAAkE,EAAE,CAACzC,KAAK0D,EAAMzD,SAAS,KAAKC,QAAQ,CAAC,mBAAmBpB,EAA2CY,EAAES,cAAc,KAAK,MAAM,8GAA8GrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,MAAM,CAACkE,IAAIpB,EAAkEvD,EAAE4E,IAAI,YAAYlE,UAAU,aAAamE,MAAMjB,IAAWxE,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,IAAI,KAAK,4FAA4FrB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,KAAK,WAAWrB,EAA2CY,EAAES,cAAc,MAAM,CAACoE,MAAMrB,GAAQpE,EAA2CY,EAAES,cAAcsC,EAAkE,EAAE,CAACzC,KAAKyD,EAAMxD,SAAS,KAAKC,QAAQ,CAAC,mBAAmBpB,EAA2CY,EAAES,cAAc,KAAK,MAAMrB,EAA2CY,EAAES,cAAc,KAAK,KAAK,WAAWrB,EAA2CY,EAAES,cAAc,MAAM,CAACoE,MAAMrB,GAAQpE,EAA2CY,EAAES,cAAcsC,EAAkE,EAAE,CAACzC,KAAK2D,EAAS1D,SAAS,KAAKC,QAAQ,CAAC,2BAAmC0D,EAAlnS,CAA+nS/E,EAA8C,WAAgCT,EAA6B,QAAKiB,OAAOkD,EAAiE,EAAxElD,EADvpS,SAAgB8B,GAAO,MAAM,CAACG,MAAM,CAACkD,OAAOrD,EAAMK,QAAQ,GAAG4B,QAAQjC,EAAMK,QAAQ,IAAIiD,SAAS,CAACD,OAAOrD,EAAMK,QAAQ,IAAIkD,UAAU,CAACC,UAAU,aACugS,CAAoFf"},"code":"(this[\"webpackJsonpmern-stack-client\"]=this[\"webpackJsonpmern-stack-client\"]||[]).push([[14],{140:function(e,t,n){\"use strict\";n.d(t,\"a\",(function(){return p}));var a=n(45),l=n(28),r=n(136),i=n(137),s=n(139),c=n(0),o=n.n(c),u=n(138),m=n.n(u),p=(n(59),function(e){function t(e){var n;return Object(a.a)(this,t),(n=Object(r.a)(this,Object(i.a)(t).call(this,e))).highlight=function(){n.ref&&n.ref.current&&m.a.highlightElement(n.ref.current)},n.ref=o.a.createRef(),n}return Object(s.a)(t,e),Object(l.a)(t,[{key:\"componentDidMount\",value:function(){this.highlight()}},{key:\"componentDidUpdate\",value:function(){this.highlight()}},{key:\"render\",value:function(){var e=this.props,t=e.code,n=(e.plugins,e.language);return o.a.createElement(\"pre\",{className:\"code-prism\"},o.a.createElement(\"code\",{ref:this.ref,className:\"language-\".concat(n)},t.trim()))}}]),t}(o.a.Component))},141:function(e,t,n){},146:function(e,t,n){\"use strict\";n.d(t,\"a\",(function(){return u}));var a=n(0),l=n.n(a),r=n(26),i=n(297),s=n(295),c=n(114),o=Object(c.a)((function(e){return{root:{display:\"flex\"},paper:{marginRight:e.spacing(2)},line:{textDecoration:\"none\"}}}));function u(){var e=o();return l.a.createElement(\"div\",{className:e.root},l.a.createElement(s.a,null,l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/infoMl\",className:e.line},\"InfoMl\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/gredient_decents\",className:e.line},\"Gredient Decents\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/training\",className:e.line},\"Traning\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/regularizations\",className:e.line},\"Regularizations\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/featuresEng\",className:e.line},\"FeaturesEng\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/adaboost\",className:e.line},\"Adaboots\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/greedSearch\",className:e.line},\"Greed Search\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/perceptron\",className:e.line},\"Perceptron\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/pcaPy\",className:e.line},\"PCA\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/leanearRegression\",className:e.line},\"Leanear Regression\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/logisticReg\",className:e.line},\"Logistic Regression\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/lda\",className:e.line},\"Lda\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/knn\",className:e.line},\"Knn\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/k_meanClustring\",className:e.line},\"K_Mean\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/naiveBar\",className:e.line},\"Naive Bayes\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/randomForest\",className:e.line},\"Random Forest\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/decisiontree\",className:e.line},\"Decision Tree\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/svmPy\",className:e.line},\"SVM\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/numpyPy\",className:e.line},\"Numpy\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/pandas\",className:e.line},\"Pandas\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/bagging\",className:e.line},\"Matplotlib\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/logisticRegrations\",className:e.line},\"Scikit Learn\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/regrations\",className:e.line},\"SciPy\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/libraries\",className:e.line},\"OpenCV\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/capture\",className:e.line},\"Capture\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/joinImages\",className:e.line},\"JoinImages\")),l.a.createElement(\"br\",null),\"Deep Learning\",l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/superwise\",className:e.line},\"Superwise\"))),l.a.createElement(\"div\",null))}},164:function(e,t,n){e.exports=n.p+\"static/media/perceptrons.f6ad4ad3.png\"},247:function(e,t,n){e.exports=n.p+\"static/media/perceptrons2.5c2b5a03.png\"},248:function(e,t,n){e.exports=n.p+\"static/media/perceptrons3.82c24adc.png\"},249:function(e,t,n){e.exports=n.p+\"static/media/perceptrons4.5617a654.png\"},520:function(e,t,n){\"use strict\";n.r(t);var a=n(45),l=n(28),r=n(136),i=n(137),s=n(139),c=n(0),o=n.n(c),u=n(138),m=n.n(u),p=n(120),d=n(57),E=n(296),f=n(5),b=(n(141),n(146)),h=n(140),g=n(164),_=n.n(g),y=n(247),w=n.n(y),x=n(248),N=n.n(x),v=n(249),k=n.n(v),X={backgroundColor:\"#F0F8FF\",padding:\"1px\",fontSize:\"16px\"},j={height:350,width:600},O=\"\\nimport numpy as np\\n\\nclass Perceptron:\\n    def __init__(self, learning_rate=0.01, n_iters=1000):\\n        self.lr = learning_rate\\n        self.n_iters = n_iters\\n        self.activation_func = self._unit_step_func\\n        self.weights = None\\n        self.bias = None\\n\\n    def fit(self, X, y):\\n        n_samples, n_features = X.shape\\n\\n        # init parameters\\n        self.weights = np.zeros(n_features)\\n        self.bias = 0\\n\\n        y_ = np.array([1 if i > 0 else 0 for i in y])\\n\\n        for _ in range(self.n_iters):\\n\\n            for idx, x_i in enumerate(X):\\n\\n                linear_output = np.dot(x_i, self.weights) + self.bias\\n                y_predicted = self.activation_func(linear_output)\\n\\n                # Perceptron update rule\\n                update = self.lr * (y_[idx] - y_predicted)\\n\\n                self.weights += update * x_i\\n                self.bias += update\\n\\n    def predict(self, X):\\n        linear_output = np.dot(X, self.weights) + self.bias\\n        y_predicted = self.activation_func(linear_output)\\n        return y_predicted\\n\\n    def _unit_step_func(self, x):\\n        return np.where(x >= 0, 1, 0)\\n\".trim(),P=\"\\nif 0.5x + 0.5y => 0, then 1\\nif 0.5x + 0.5y < 0, then 0.\\n\".trim(),T='\\nif __name__ == \"__main__\":\\n    # Imports\\n    import matplotlib.pyplot as plt\\n    from sklearn.model_selection import train_test_split\\n    from sklearn import datasets\\n\\n    def accuracy(y_true, y_pred):\\n        accuracy = np.sum(y_true == y_pred) / len(y_true)\\n        return accuracy\\n\\n    X, y = datasets.make_blobs(\\n        n_samples=150, n_features=2, centers=2, cluster_std=1.05, random_state=2\\n    )\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X, y, test_size=0.2, random_state=123\\n    )\\n\\n    p = Perceptron(learning_rate=0.01, n_iters=1000)\\n    p.fit(X_train, y_train)\\n    predictions = p.predict(X_test)\\n\\n    print(\"Perceptron classification accuracy\", accuracy(y_test, predictions))\\n\\n    fig = plt.figure()\\n    ax = fig.add_subplot(1, 1, 1)\\n    plt.scatter(X_train[:, 0], X_train[:, 1], marker=\"o\", c=y_train)\\n\\n    x0_1 = np.amin(X_train[:, 0])\\n    x0_2 = np.amax(X_train[:, 0])\\n\\n    x1_1 = (-p.weights[0] * x0_1 - p.bias) / p.weights[1]\\n    x1_2 = (-p.weights[0] * x0_2 - p.bias) / p.weights[1]\\n\\n    ax.plot([x0_1, x0_2], [x1_1, x1_2], \"k\")\\n\\n    ymin = np.amin(X_train[:, 1])\\n    ymax = np.amax(X_train[:, 1])\\n    ax.set_ylim([ymin - 3, ymax + 3])\\n\\n    plt.show()\\n    '.trim(),A=function(e){function t(){return Object(a.a)(this,t),Object(r.a)(this,Object(i.a)(t).apply(this,arguments))}return Object(s.a)(t,e),Object(l.a)(t,[{key:\"componentDidMount\",value:function(){setTimeout((function(){return m.a.highlightAll()}),0)}},{key:\"render\",value:function(){var e=this.props.classes;return o.a.createElement(p.a,{container:!0},o.a.createElement(p.a,{item:!0,xs:2},o.a.createElement(d.a,{className:e.paper},o.a.createElement(\"h4\",null,o.a.createElement(b.a,null)))),o.a.createElement(p.a,{item:!0,xs:10},o.a.createElement(d.a,{className:e.paper},o.a.createElement(E.a,null,o.a.createElement(\"h3\",null,\"Perceptron \\u2013 Basics of Neural Networks\"),\"A single-layer perceptron is the basic unit of a neural network. A perceptron consists of input values, weights and a bias, a weighted sum and activation function.\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),o.a.createElement(\"i\",null,\"Perceptron consists of one/ more inputs, a processor, and only one o/p.\"),o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"A perceptron works by taking in some numerical i/p along with what is known as weights and a bias. It then multiplies these i/p with the respective weights(weighted sum). These products are then added together along with the bias. The activation function takes the weighted sum and the bias as i/p and returns a final o/p.\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),o.a.createElement(\"ul\",null,o.a.createElement(\"li\",null,\"A perceptron consists of four parts: input values, weights and a bias, a weighted sum, and activation function.\"),o.a.createElement(\"li\",null,o.a.createElement(\"b\",null,\"Function may look like: \"),\"y = xw + x2w2 +...+ xnwn\"),o.a.createElement(\"ul\",null,o.a.createElement(\"li\",null,\"bias  is alwase 1.\"),o.a.createElement(\"li\",null,\"This function is called the weighted sum because it is the sum of the weights and inputs. This looks like a good function, but what if we wanted the outputs to fall into a certain range 0 to 1.\"),o.a.createElement(\"li\",null,\"We can do this by using an activation function. An \",o.a.createElement(\"b\",null,\"activation function\"),\" is a function that converts the i/p into a certain o/p based on a set of rules.\"),o.a.createElement(\"br\",null),o.a.createElement(\"img\",{src:_.a,alt:\"Equations\",className:\"responsive\",style:j}),o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"There are different kinds of activation functions that exist.\",o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"1. Hyperbolic Tangent: \"),\"Used to o/p a number from -1 to 1.\",o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"2. Logistic Function: \"),\"Used to o/p a number from 0 to 1.\")),o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"Why are perceptron's used?\"),o.a.createElement(\"br\",null),\"Perceptrons are the building blocks of neural networks. It is typically used for supervised learning of binary classifiers.\",o.a.createElement(\"br\",null),o.a.createElement(\"img\",{src:w.a,alt:\"Equations\",className:\"responsive\",style:j}),o.a.createElement(\"br\",null),\"Suppose our goal was to separates this data so that there is a distinction between the blue dots and the red dots.\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"A perceptron can create a decision boundary for a binary classification, where a decision boundary is regions of space on a graph that separates different data points.\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"Let wx = -0.5, wy = 0.5 and b = 0\",o.a.createElement(\"br\",null),\"Then the function for the perceptron.\",o.a.createElement(\"br\",null),\"0.5x + 0.5y = 0\",o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),\"and the graph is.\",o.a.createElement(\"br\",null),o.a.createElement(\"img\",{src:N.a,alt:\"Equations\",className:\"responsive\",style:j}),o.a.createElement(\"br\",null),\"Let\\u2019s suppose that the activation function, in this case, is a simple step function that outputs either 0 or 1. The perceptron function will then label the blue dots as 1 and the red dots as 0.\",o.a.createElement(\"div\",{style:X},o.a.createElement(h.a,{code:P,language:\"js\",plugins:[\"line-numbers\"]})),o.a.createElement(\"br\",null),\"Therefore, the function 0.5x + 0.5y = 0 creates a decision boundary that separates the red and blue points.\",o.a.createElement(\"br\",null),o.a.createElement(\"img\",{src:k.a,alt:\"Equations\",className:\"responsive\",style:j}),o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"Overall, we see that a perceptron can do basic classification using a decision boundary.\"),o.a.createElement(\"br\",null),o.a.createElement(\"h3\",null,\"Example\"),o.a.createElement(\"div\",{style:X},o.a.createElement(h.a,{code:O,language:\"js\",plugins:[\"line-numbers\"]})),o.a.createElement(\"br\",null),o.a.createElement(\"h3\",null,\"Testing\"),o.a.createElement(\"div\",{style:X},o.a.createElement(h.a,{code:T,language:\"js\",plugins:[\"line-numbers\"]}))))))}}]),t}(c.Component);t.default=Object(f.a)((function(e){return{paper:{margin:e.spacing(1),padding:e.spacing(1)},smMargin:{margin:e.spacing(1)},actionDiv:{textAlign:\"center\"}}}))(A)}}]);","extractedComments":[]}
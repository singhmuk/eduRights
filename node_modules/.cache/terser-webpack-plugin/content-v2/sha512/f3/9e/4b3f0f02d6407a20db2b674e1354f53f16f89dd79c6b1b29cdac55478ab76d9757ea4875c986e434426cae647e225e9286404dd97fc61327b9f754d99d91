{"map":{"version":3,"sources":["static/js/46.f353f6fd.chunk.js"],"names":["this","push","344","module","__webpack_exports__","__webpack_require__","d","Sidebar","react__WEBPACK_IMPORTED_MODULE_0__","react__WEBPACK_IMPORTED_MODULE_0___default","n","react_router_dom__WEBPACK_IMPORTED_MODULE_1__","_material_ui_core_MenuItem__WEBPACK_IMPORTED_MODULE_2__","_material_ui_core_MenuList__WEBPACK_IMPORTED_MODULE_3__","_material_ui_core_styles__WEBPACK_IMPORTED_MODULE_4__","useStyles","Object","theme","root","display","paper","marginRight","spacing","line","textDecoration","classes","a","createElement","className","to","472","r","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_classCallCheck__WEBPACK_IMPORTED_MODULE_0__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_createClass__WEBPACK_IMPORTED_MODULE_1__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_possibleConstructorReturn__WEBPACK_IMPORTED_MODULE_2__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_getPrototypeOf__WEBPACK_IMPORTED_MODULE_3__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_inherits__WEBPACK_IMPORTED_MODULE_4__","react__WEBPACK_IMPORTED_MODULE_5__","react__WEBPACK_IMPORTED_MODULE_5___default","prismjs__WEBPACK_IMPORTED_MODULE_6__","prismjs__WEBPACK_IMPORTED_MODULE_6___default","_material_ui_core__WEBPACK_IMPORTED_MODULE_7__","_material_ui_core__WEBPACK_IMPORTED_MODULE_8__","_material_ui_core__WEBPACK_IMPORTED_MODULE_9__","_material_ui_core__WEBPACK_IMPORTED_MODULE_10__","_sidebar__WEBPACK_IMPORTED_MODULE_12__","_ReactJs_prismCode__WEBPACK_IMPORTED_MODULE_13__","titles","backgroundColor","padding","fontSize","childsFile","trim","customerID","visualization","service","encoding","split","regression","skewdness","applying","logistic","Imbalanced","_Component","apply","arguments","key","value","setTimeout","highlightAll","props","container","item","xs","style","code","language","plugins","margin","smMargin","actionDiv","textAlign"],"mappings":"CAACA,KAAK,iCAAmCA,KAAK,kCAAoC,IAAIC,KAAK,CAAC,CAAC,IAAI,CAE3FC,IACA,SAAUC,EAAQC,EAAqBC,GAE7C,aAC+BA,EAAoBC,EAAEF,EAAqB,KAAK,WAAa,OAAOG,KAC9E,IAAIC,EAAqCH,EAAoB,GACzDI,EAA0DJ,EAAoBK,EAAEF,GAChFG,EAAgDN,EAAoB,IACpEO,EAA0DP,EAAoB,IAC9EQ,EAA0DR,EAAoB,IAC9ES,EAAwDT,EAAoB,IACjGU,EAAUC,OAAOF,EAAuE,EAA9EE,EAAiF,SAASC,GAAO,MAAM,CAACC,KAAK,CAACC,QAAQ,QAAQC,MAAM,CAACC,YAAYJ,EAAMK,QAAQ,IAAIC,KAAK,CAACC,eAAe,YAAY,SAASjB,IAAU,IAAIkB,EAAQV,IAAY,OAAON,EAA2CiB,EAAEC,cAAc,MAAM,CAACC,UAAUH,EAAQP,MAAMT,EAA2CiB,EAAEC,cAAcd,EAAyE,EAAE,KAAKJ,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,gBAAgBD,UAAUH,EAAQF,MAAM,OAAOd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,WAAWD,UAAUH,EAAQF,MAAM,iBAAiBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,eAAeD,UAAUH,EAAQF,MAAM,aAAad,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,UAAUD,UAAUH,EAAQF,MAAM,gBAAgBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,uBAAuBD,UAAUH,EAAQF,MAAM,oBAAoBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,QAAQD,UAAUH,EAAQF,MAAM,SAASd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,kBAAkBD,UAAUH,EAAQF,MAAM,mBAAmBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,gBAAgBD,UAAUH,EAAQF,MAAM,iBAAiBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,YAAYD,UAAUH,EAAQF,MAAM,aAAad,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,sBAAsBD,UAAUH,EAAQF,MAAM,wBAAwBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,eAAeD,UAAUH,EAAQF,MAAM,gBAAgBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,kBAAkBD,UAAUH,EAAQF,MAAM,mBAAmBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,qBAAqBD,UAAUH,EAAQF,MAAM,sBAAsBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,YAAYD,UAAUH,EAAQF,MAAM,aAAad,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,kBAAkBD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAc,MAAM,SAItpMG,IACA,SAAU3B,EAAQC,EAAqBC,GAE7C,aACAA,EAAoB0B,EAAE3B,GACD,IAAI4B,EAAsH3B,EAAoB,GAC1I4B,EAAmH5B,EAAoB,GACvI6B,EAAiI7B,EAAoB,GACrJ8B,EAAsH9B,EAAoB,GAC1I+B,EAAgH/B,EAAoB,GACpIgC,EAAqChC,EAAoB,GACzDiC,EAA0DjC,EAAoBK,EAAE2B,GAChFE,EAAuClC,EAAoB,GAC3DmC,EAA4DnC,EAAoBK,EAAE6B,GAClFE,EAAiDpC,EAAoB,GACrEqC,EAAiDrC,EAAoB,GACrEsC,EAAiDtC,EAAoB,IACrEuC,EAAkDvC,EAAoB,IAGtEwC,GAFoDxC,EAAoB,IAE/BA,EAAoB,MAC7DyC,EAAmDzC,EAAoB,GAC5F0C,EAAO,CAACC,gBAAgB,UAAUC,QAAQ,MAAMC,SAAS,QAAmLC,EAAW,wPAAwPC,OAAWC,EAAW,0YAA0YD,OAAWE,EAAc,8zCAA8zCF,OAAWG,EAAQ,2nBAA2nBH,OAAWI,EAAS,+WAA+WJ,OAAWK,EAAM,iSAAiSL,OAAWM,EAAW,q5BAAy5BN,OAAWO,EAAU,q0BAAq0BP,OAAWQ,EAAS,yzBAAyzBR,OAAWS,EAAS,83EAA83ET,OAAWU,EAAwB,SAASC,GAA4K,SAASD,IAA6K,OAAhK9C,OAAOgB,EAAqI,EAA5IhB,CAA+IhB,KAAK8D,GAAmB9C,OAAOkB,EAAgJ,EAAvJlB,CAA0JhB,KAAKgB,OAAOmB,EAAqI,EAA5InB,CAA+I8C,GAAYE,MAAMhE,KAAKiE,YAAqsM,OAAv2NjD,OAAOoB,EAA+H,EAAtIpB,CAAyI8C,EAAWC,GAA2hB/C,OAAOiB,EAAkI,EAAzIjB,CAA4I8C,EAAW,CAAC,CAACI,IAAI,oBAAoBC,MAAM,WAA6BC,YAAW,WAAW,OAAO5B,EAA6Cd,EAAE2C,iBAAiB,KAAM,CAACH,IAAI,SAASC,MAAM,WAAkB,IAAI1C,EAAQzB,KAAKsE,MAAM7C,QAAQ,OAAOa,EAA2CZ,EAAEC,cAAcc,EAAgE,EAAE,CAAC8B,WAAU,GAAMjC,EAA2CZ,EAAEC,cAAcc,EAAgE,EAAE,CAAC+B,MAAK,EAAKC,GAAG,GAAGnC,EAA2CZ,EAAEC,cAAce,EAAgE,EAAE,CAACd,UAAUH,EAAQL,OAAOkB,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAckB,EAAwD,EAAE,SAASP,EAA2CZ,EAAEC,cAAcc,EAAgE,EAAE,CAAC+B,MAAK,EAAKC,GAAG,IAAInC,EAA2CZ,EAAEC,cAAce,EAAgE,EAAE,CAACd,UAAUH,EAAQL,OAAOkB,EAA2CZ,EAAEC,cAAcgB,EAAgE,EAAE,KAAKL,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,mEAAmEW,EAA2CZ,EAAEC,cAAc,IAAI,KAAK,iQAAiQW,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKxB,EAAWyB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,2DAA2DW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKtB,EAAWuB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,sBAAsBW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKrB,EAAcsB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,4GAA4GW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKpB,EAAQqB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,4CAA4CW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKnB,EAASoB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,oBAAoBW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKlB,EAAMmB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,sCAAsCW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKjB,EAAWkB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,gCAAgCW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKhB,EAAUiB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,gCAAgCW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKf,EAASgB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBvC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,uBAAuBW,EAA2CZ,EAAEC,cAAc,MAAM,CAAC+C,MAAM3B,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAAC6B,KAAKd,EAASe,SAAS,KAAKC,QAAQ,CAAC,2BAAmCf,EAAn4N,CAAg5NzB,EAA8C,WAAgCjC,EAA6B,QAAKY,OAAO4B,EAAiE,EAAxE5B,EAAx+e,SAAgBC,GAAO,MAAM,CAACG,MAAM,CAAC0D,OAAO7D,EAAMK,QAAQ,GAAG2B,QAAQhC,EAAMK,QAAQ,IAAIyD,SAAS,CAACD,OAAO7D,EAAMK,QAAQ,IAAI0D,UAAU,CAACC,UAAU,aAAw1e,CAAoFnB"},"code":"(this[\"webpackJsonpmern-stack-client\"]=this[\"webpackJsonpmern-stack-client\"]||[]).push([[46],{344:function(e,n,t){\"use strict\";t.d(n,\"a\",(function(){return u}));var a=t(0),r=t.n(a),s=t(12),l=t(14),i=t(50),o=t(49),c=Object(o.a)((function(e){return{root:{display:\"flex\"},paper:{marginRight:e.spacing(2)},line:{textDecoration:\"none\"}}}));function u(){var e=c();return r.a.createElement(\"div\",{className:e.root},r.a.createElement(i.a,null,r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/introAngular\",className:e.line},\"AI\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/tensorflow\",className:e.line},\"Tensorflow\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/tensors\",className:e.line},\"Tensorboards\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/angCompiler\",className:e.line},\"Compiler\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/neural\",className:e.line},\"NeuralKeras\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/activationFunctions\",className:e.line},\"activationFuncs\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/loss\",className:e.line},\"Loss\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/gradientNeural\",className:e.line},\"GradientNeural\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/stochastic\",className:e.line},\"Stochastic\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/benchmarking\",className:e.line},\"Benchmarking\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/customer\",className:e.line},\"Customer\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/regularizationDeep\",className:e.line},\"Regularization Deep\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/imbalanced\",className:e.line},\"Imbalanced\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/imbalanced2\",className:e.line},\"Imbalanced2\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/convolutionals\",className:e.line},\"Convolutionals\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/data_augmentation\",className:e.line},\"data Augmentation\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/transfer\",className:e.line},\"Transfer\")),r.a.createElement(l.a,null,r.a.createElement(s.b,{to:\"/word_embedding\",className:e.line},\"Embedding\"))),r.a.createElement(\"div\",null))}},472:function(e,n,t){\"use strict\";t.r(n);var a=t(4),r=t(3),s=t(5),l=t(6),i=t(8),o=t(0),c=t.n(o),u=t(7),m=t.n(u),_=t(2),d=t(9),p=t(13),g=t(11),f=(t(16),t(344)),h=t(1),y={backgroundColor:\"#F0F8FF\",padding:\"1px\",fontSize:\"16px\"},E=\"\\nimport pandas as pd\\nfrom matplotlib import pyplot as plt\\nimport numpy as np\\n%matplotlib inline\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n\\ndf = pd.read_csv(\\\"customer_churn.csv\\\")\\n\\ndf.Churn.value_counts()\\n517400/ df.shape[0]\\n\".trim(),b=\"\\ndf.drop('customerID',axis='columns',inplace=True)\\ndf.TotalCharges.values\\n\\npd.to_numeric(df.TotalCharges,errors='coerce').isnull()\\ndf[pd.to_numeric(df.TotalCharges,errors='coerce').isnull()]\\n\\ndf.iloc[488].TotalCharges\\ndf[df.TotalCharges!=' '].shape\\ndf1 = df[df.TotalCharges!=' ']\\n\\ndf1.TotalCharges = pd.to_numeric(df1.TotalCharges)\\ndf1.TotalCharges.values\\ndf1[df1.Churn=='No']\\n\".trim(),v=\"\\ntenure_churn_no = df1[df1.Churn=='No'].tenure\\ntenure_churn_yes = df1[df1.Churn=='Yes'].tenure\\n\\nplt.xlabel(\\\"tenure\\\")\\nplt.ylabel(\\\"Number Of Customers\\\")\\nplt.title(\\\"Customer Churn Prediction Visualiztion\\\")\\n\\nblood_sugar_men = [113, 85, 90, 150, 149, 88, 93, 115, 135, 80, 77, 82, 129]\\nblood_sugar_women = [67, 98, 89, 120, 133, 150, 84, 69, 89, 79, 120, 112, 100]\\n\\nplt.hist([tenure_churn_yes, tenure_churn_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])\\nplt.legend()\\n\\n\\nmc_churn_no = df1[df1.Churn=='No'].MonthlyCharges      \\nmc_churn_yes = df1[df1.Churn=='Yes'].MonthlyCharges      \\n\\nplt.xlabel(\\\"Monthly Charges\\\")\\nplt.ylabel(\\\"Number Of Customers\\\")\\nplt.title(\\\"Customer Churn Prediction Visualiztion\\\")\\n\\nblood_sugar_men = [113, 85, 90, 150, 149, 88, 93, 115, 135, 80, 77, 82, 129]\\nblood_sugar_women = [67, 98, 89, 120, 133, 150, 84, 69, 89, 79, 120, 112, 100]\\n\\nplt.hist([mc_churn_yes, mc_churn_no], rwidth=0.95, color=['green','red'],label=['Churn=Yes','Churn=No'])\\nplt.legend()\\n\\ndef print_unique_col_values(df):                                                        #Many of the columns are yes, no.\\n       for column in df:\\n            if df[column].dtypes=='object':\\n                print(f'{column}: {df[column].unique()}') \\n                \\nprint_unique_col_values(df1)\\n\".trim(),C=\"\\ndf1.replace('No internet service','No',inplace=True)\\ndf1.replace('No phone service','No',inplace=True)\\n\\nprint_unique_col_values(df1)\\n\\n#Convert Yes and No to 1 or 0.\\nyes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines','OnlineSecurity','OnlineBackup',\\n                  'DeviceProtection','TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']\\nfor col in yes_no_columns:\\n    df1[col].replace({'Yes': 1,'No': 0},inplace=True)\\n    \\n    \\nfor col in df1:\\n    print(f'{col}: {df1[col].unique()}') \\n    \\ndf1['gender'].replace({'Female':1,'Male':0},inplace=True)\\ndf1.gender.unique()\\n\".trim(),X=\"\\ndf2 = pd.get_dummies(data=df1, columns=['InternetService','Contract','PaymentMethod'])\\ndf2.columns\\n\\ncols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\\n\\nfrom sklearn.preprocessing import MinMaxScaler\\nscaler = MinMaxScaler()\\ndf2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])\\n\\nfor col in df2:\\n    print(f'{col}: {df2[col].unique()}')\\n\".trim(),w=\"\\nX = df2.drop('Churn',axis='columns')\\ny = testLabels = df2.Churn.astype(np.float32)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\\n\\ny_train.value_counts()\\ny.value_counts()\\n5163/1869\\n\\nX_train.shape\\nlen(X_train.columns)\\n\".trim(),N='\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import classification_report\\n\\ndef log_reg(X_train, y_train, X_test, y_test, weights):\\n    if weights==-1:\\n        model = LogisticRegression()\\n    else:\\n        model = LogisticRegression(class_weight={0:weights[0], 1:weights[1]})\\n\\n    model.fit(X_train, y_train)\\n    acc = model.score(X_test, y_test)\\n    print(\"Accuracy\", acc)\\n\\n    y_pred = model.predict(X_test)\\n    print(\"preds\", y_pred[:5])\\n\\n    cl_rep = classification_report(y_test,y_pred)\\n    print(cl_rep)\\n    \\nweights = -1                                                      # pass -1 to use Logistics Regression without weights.\\nlog_reg(X_train, y_train, X_test, y_test, weights)\\n\\nweights = [1, 1.5]                                                # pass -1 to use Logistics Regression without weights.\\nlog_reg(X_train, y_train, X_test, y_test, weights)\\n'.trim(),T=\"\\n# Method1: Undersampling\\ncount_class_0, count_class_1 = df1.Churn.value_counts()\\n\\ndf_class_0 = df2[df2['Churn'] == 0]                               # Divide by class.\\ndf_class_1 = df2[df2['Churn'] == 1]\\n\\n\\n# Undersample 0-class and concat the DataFrames of both class.\\ndf_class_0_under = df_class_0.sample(count_class_1)\\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\\n\\nprint('Random under-sampling:')\\nprint(df_test_under.Churn.value_counts())\\n\\nX = df_test_under.drop('Churn',axis='columns')\\ny = df_test_under['Churn']\\n\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\\n\\n\\ny_train.value_counts()                                                        # Number of classes in training Data.\\n\".trim(),M=\"\\nweights = -1                                                    # pass -1 to use Logistics Regression without weights\\nlog_reg(X_train, y_train, X_test, y_test, weights)\\n\\n\\n# Method2: Oversampling\\n# Oversample 1-class and concat the DataFrames of both classes\\ndf_class_1_over = df_class_1.sample(count_class_0, replace=True)\\ndf_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\\n\\nprint('Random over-sampling:', df_test_over.Churn.value_counts())\\n\\nX = df_test_over.drop('Churn',axis='columns')\\ny = df_test_over['Churn']\\n\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\\n\\n\\ny_train.value_counts()                                                        # Number of classes in training Data.\\n\".trim(),x=\"\\nweights = -1                                                # pass -1 to use Logistics Regression without weights.\\nlog_reg(X_train, y_train, X_test, y_test, weights)\\n\\n# Method3: SMOTE\\nX = df2.drop('Churn',axis='columns')\\ny = df2['Churn']\\n\\nfrom imblearn.over_sampling import SMOTE\\nsmote = SMOTE(sampling_strategy='minority')\\nX_sm, y_sm = smote.fit_sample(X, y)\\n\\ny_sm.value_counts()\\n\\n\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)\\n\\ny_train.value_counts()\\n\\n\\n# Logistic Regression\\nweights = -1                                                 # pass -1 to use Logistics Regression without weights.\\nlog_reg(X_train, y_train, X_test, y_test, weights)\\n\\n\\ndf2.Churn.value_counts()                                    # Method4: Use of Ensemble with undersampling.\\n\\nX = df2.drop('Churn',axis='columns')                        # Regain Original features and labels.\\ny = df2['Churn']\\n\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\\n\\ny_train.value_counts()\\nmodel = LogisticRegression()\\n\\ndf3 = X_train.copy()\\ndf3['Churn'] = y_train\\ndf3.head()\\n\\ndf3_class0 = df3[df3.Churn==0]\\ndf3_class1 = df3[df3.Churn==1]\\n\\ndef get_train_batch(df_majority, df_minority, start, end):\\n    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\\n    X_train = df_train.drop('Churn', axis='columns')\\n    y_train = df_train.Churn\\n    return X_train, y_train    \\n    \\nX_train, y_train = get_train_batch(df3_class0, df3_class1, 0, 1495)\\nmodel1 = LogisticRegression()\\nmodel1.fit(X_train, y_train)\\ny_pred1 = model1.predict(X_test)\\n\\nX_train, y_train = get_train_batch(df3_class0, df3_class1, 1495, 2990)\\nmodel2 = LogisticRegression()\\nmodel2.fit(X_train, y_train)\\ny_pred2 = model2.predict(X_test)\\n\\nX_train, y_train = get_train_batch(df3_class0, df3_class1, 2990, 4130)\\nmodel3 = LogisticRegression()\\nmodel3.fit(X_train, y_train)\\ny_pred3 = model3.predict(X_test)\\n\\nlen(y_pred1)\\n\\ny_pred_final = y_pred1.copy()\\nfor i in range(len(y_pred1)):\\n    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i]\\n    if n_ones>1:\\n        y_pred_final[i] = 1\\n    else:\\n        y_pred_final[i] = 0\\n        \\n        \\ncl_rep = classification_report(y_test, y_pred_final)\\nprint(cl_rep)\\n\".trim(),R=function(e){function n(){return Object(a.a)(this,n),Object(s.a)(this,Object(l.a)(n).apply(this,arguments))}return Object(i.a)(n,e),Object(r.a)(n,[{key:\"componentDidMount\",value:function(){setTimeout((function(){return m.a.highlightAll()}),0)}},{key:\"render\",value:function(){var e=this.props.classes;return c.a.createElement(_.a,{container:!0},c.a.createElement(_.a,{item:!0,xs:2},c.a.createElement(d.a,{className:e.paper},c.a.createElement(\"h4\",null,c.a.createElement(f.a,null)))),c.a.createElement(_.a,{item:!0,xs:10},c.a.createElement(d.a,{className:e.paper},c.a.createElement(p.a,null,c.a.createElement(\"h3\",null,\"Handle imbalanced data in churn prediction. Logistic Regression\"),c.a.createElement(\"i\",null,\"Customer churn prediction is to measure why customers are leaving a business. Looking at customer churn in telecom business. We will build a deep learning model to predict the churn and use precision,recall, f1-score to measure performance of our model.\"),c.a.createElement(\"br\",null),c.a.createElement(\"br\",null),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:E,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"First of all, drop customerID column as it is of no use\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:b,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"Data Visualization\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:v,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"Some of the columns have no internet service or no phone service, that can be replaced with a simple No.\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:C,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"One hot encoding for categorical columns\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:X,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"Train test split\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:w,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"Use logistic regression classifier\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:N,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"Mitigating Skewdness of Data\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:T,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"Applying Logistic Regression\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:M,language:\"js\",plugins:[\"line-numbers\"]})),c.a.createElement(\"br\",null),c.a.createElement(\"h3\",null,\"Logistic Regression\"),c.a.createElement(\"div\",{style:y},c.a.createElement(h.a,{code:x,language:\"js\",plugins:[\"line-numbers\"]}))))))}}]),n}(o.Component);n.default=Object(g.a)((function(e){return{paper:{margin:e.spacing(1),padding:e.spacing(1)},smMargin:{margin:e.spacing(1)},actionDiv:{textAlign:\"center\"}}}))(R)}}]);","extractedComments":[]}
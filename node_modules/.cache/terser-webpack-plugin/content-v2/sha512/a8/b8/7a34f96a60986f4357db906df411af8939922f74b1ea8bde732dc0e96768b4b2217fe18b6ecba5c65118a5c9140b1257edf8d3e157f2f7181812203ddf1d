{"map":{"version":3,"sources":["static/js/81.cfffacb9.chunk.js"],"names":["this","push","342","module","__webpack_exports__","__webpack_require__","d","Sidebar","react__WEBPACK_IMPORTED_MODULE_0__","react__WEBPACK_IMPORTED_MODULE_0___default","n","react_router_dom__WEBPACK_IMPORTED_MODULE_1__","_material_ui_core_MenuItem__WEBPACK_IMPORTED_MODULE_2__","_material_ui_core_MenuList__WEBPACK_IMPORTED_MODULE_3__","_material_ui_core_styles__WEBPACK_IMPORTED_MODULE_4__","useStyles","Object","theme","root","display","paper","marginRight","spacing","line","textDecoration","classes","a","createElement","className","to","516","r","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_classCallCheck__WEBPACK_IMPORTED_MODULE_0__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_createClass__WEBPACK_IMPORTED_MODULE_1__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_possibleConstructorReturn__WEBPACK_IMPORTED_MODULE_2__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_getPrototypeOf__WEBPACK_IMPORTED_MODULE_3__","_home_mukeshs_Projects_edurights_node_modules_babel_runtime_helpers_esm_inherits__WEBPACK_IMPORTED_MODULE_4__","react__WEBPACK_IMPORTED_MODULE_5__","react__WEBPACK_IMPORTED_MODULE_5___default","prismjs__WEBPACK_IMPORTED_MODULE_6__","prismjs__WEBPACK_IMPORTED_MODULE_6___default","_material_ui_core__WEBPACK_IMPORTED_MODULE_7__","_material_ui_core__WEBPACK_IMPORTED_MODULE_8__","_material_ui_core__WEBPACK_IMPORTED_MODULE_9__","_material_ui_core__WEBPACK_IMPORTED_MODULE_10__","_sidebar__WEBPACK_IMPORTED_MODULE_12__","_ReactJs_prismCode__WEBPACK_IMPORTED_MODULE_13__","titles","backgroundColor","padding","fontSize","stack","trim","testings","performance","Adaboots","_Component","apply","arguments","key","value","setTimeout","highlightAll","props","container","item","xs","style","code","language","plugins","margin","smMargin","actionDiv","textAlign"],"mappings":"CAACA,KAAK,iCAAmCA,KAAK,kCAAoC,IAAIC,KAAK,CAAC,CAAC,IAAI,CAE3FC,IACA,SAAUC,EAAQC,EAAqBC,GAE7C,aAC+BA,EAAoBC,EAAEF,EAAqB,KAAK,WAAa,OAAOG,KAC9E,IAAIC,EAAqCH,EAAoB,GACzDI,EAA0DJ,EAAoBK,EAAEF,GAChFG,EAAgDN,EAAoB,IACpEO,EAA0DP,EAAoB,IAC9EQ,EAA0DR,EAAoB,IAC9ES,EAAwDT,EAAoB,IACjGU,EAAUC,OAAOF,EAAuE,EAA9EE,EAAiF,SAASC,GAAO,MAAM,CAACC,KAAK,CAACC,QAAQ,QAAQC,MAAM,CAACC,YAAYJ,EAAMK,QAAQ,IAAIC,KAAK,CAACC,eAAe,YAAY,SAASjB,IAAU,IAAIkB,EAAQV,IAAY,OAAON,EAA2CiB,EAAEC,cAAc,MAAM,CAACC,UAAUH,EAAQP,MAAMT,EAA2CiB,EAAEC,cAAcd,EAAyE,EAAE,KAAKJ,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,UAAUD,UAAUH,EAAQF,MAAM,WAAWd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,oBAAoBD,UAAUH,EAAQF,MAAM,qBAAqBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,YAAYD,UAAUH,EAAQF,MAAM,YAAYd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,mBAAmBD,UAAUH,EAAQF,MAAM,oBAAoBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,eAAeD,UAAUH,EAAQF,MAAM,gBAAgBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,YAAYD,UAAUH,EAAQF,MAAM,aAAad,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,eAAeD,UAAUH,EAAQF,MAAM,iBAAiBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,SAASD,UAAUH,EAAQF,MAAM,QAAQd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,qBAAqBD,UAAUH,EAAQF,MAAM,uBAAuBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,eAAeD,UAAUH,EAAQF,MAAM,wBAAwBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,OAAOD,UAAUH,EAAQF,MAAM,QAAQd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,OAAOD,UAAUH,EAAQF,MAAM,QAAQd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,mBAAmBD,UAAUH,EAAQF,MAAM,WAAWd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,YAAYD,UAAUH,EAAQF,MAAM,gBAAgBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,gBAAgBD,UAAUH,EAAQF,MAAM,kBAAkBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,gBAAgBD,UAAUH,EAAQF,MAAM,kBAAkBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,SAASD,UAAUH,EAAQF,MAAM,QAAQd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,WAAWD,UAAUH,EAAQF,MAAM,UAAUd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,UAAUD,UAAUH,EAAQF,MAAM,WAAWd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,WAAWD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,sBAAsBD,UAAUH,EAAQF,MAAM,iBAAiBd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,UAAUd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,aAAaD,UAAUH,EAAQF,MAAM,WAAWd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,WAAWD,UAAUH,EAAQF,MAAM,YAAYd,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,cAAcD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAc,KAAK,MAAM,gBAAgBlB,EAA2CiB,EAAEC,cAAcf,EAAyE,EAAE,KAAKH,EAA2CiB,EAAEC,cAAchB,EAA4D,EAAE,CAACkB,GAAG,aAAaD,UAAUH,EAAQF,MAAM,eAAed,EAA2CiB,EAAEC,cAAc,MAAM,SAIx8RG,IACA,SAAU3B,EAAQC,EAAqBC,GAE7C,aACAA,EAAoB0B,EAAE3B,GACD,IAAI4B,EAAsH3B,EAAoB,GAC1I4B,EAAmH5B,EAAoB,GACvI6B,EAAiI7B,EAAoB,GACrJ8B,EAAsH9B,EAAoB,GAC1I+B,EAAgH/B,EAAoB,GACpIgC,EAAqChC,EAAoB,GACzDiC,EAA0DjC,EAAoBK,EAAE2B,GAChFE,EAAuClC,EAAoB,GAC3DmC,EAA4DnC,EAAoBK,EAAE6B,GAClFE,EAAiDpC,EAAoB,GACrEqC,EAAiDrC,EAAoB,GACrEsC,EAAiDtC,EAAoB,IACrEuC,EAAkDvC,EAAoB,IAGtEwC,GAFoDxC,EAAoB,IAE/BA,EAAoB,MAC7DyC,EAAmDzC,EAAoB,GAC5F0C,EAAO,CAACC,gBAAgB,UAAUC,QAAQ,MAAMC,SAAS,QAAmLC,EAAM,mwFAAqwFC,OAAWC,EAAS,4pBAAgqBD,OAAWE,EAAY,8LAA8LF,OACh4HG,EAAsB,SAASC,GAA0K,SAASD,IAAyK,OAA9JvC,OAAOgB,EAAqI,EAA5IhB,CAA+IhB,KAAKuD,GAAiBvC,OAAOkB,EAAgJ,EAAvJlB,CAA0JhB,KAAKgB,OAAOmB,EAAqI,EAA5InB,CAA+IuC,GAAUE,MAAMzD,KAAK0D,YAA2rO,OAAr1P1C,OAAOoB,EAA+H,EAAtIpB,CAAyIuC,EAASC,GAAqhBxC,OAAOiB,EAAkI,EAAzIjB,CAA4IuC,EAAS,CAAC,CAACI,IAAI,oBAAoBC,MAAM,WAA6BC,YAAW,WAAW,OAAOrB,EAA6Cd,EAAEoC,iBAAiB,KAAM,CAACH,IAAI,SAASC,MAAM,WAAkB,IAAInC,EAAQzB,KAAK+D,MAAMtC,QAAQ,OAAOa,EAA2CZ,EAAEC,cAAcc,EAAgE,EAAE,CAACuB,WAAU,GAAM1B,EAA2CZ,EAAEC,cAAcc,EAAgE,EAAE,CAACwB,MAAK,EAAKC,GAAG,GAAG5B,EAA2CZ,EAAEC,cAAce,EAAgE,EAAE,CAACd,UAAUH,EAAQL,OAAOkB,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAckB,EAAwD,EAAE,SAASP,EAA2CZ,EAAEC,cAAcc,EAAgE,EAAE,CAACwB,MAAK,EAAKC,GAAG,IAAI5B,EAA2CZ,EAAEC,cAAce,EAAgE,EAAE,CAACd,UAAUH,EAAQL,OAAOkB,EAA2CZ,EAAEC,cAAcgB,EAAgE,EAAE,KAAKL,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,kBAAkBW,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAc,IAAI,KAAK,kBAAkBW,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAc,IAAI,KAAK,0BAA0B,yFAAyFW,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAc,IAAI,KAAK,mCAAmCW,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,uBAAuBW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,2CAA2CW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,qBAAqBW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,kBAAkBW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,4CAA4CW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,8CAA8CW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,6BAA6BW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,sBAAsBW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,yDAAyDW,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,gCAAgCW,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,2CAA2CW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,wBAAwBW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,sMAAsMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,gFAAgFW,EAA2CZ,EAAEC,cAAc,IAAI,KAAK,mBAAmB,KAAKW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,oHAAoHW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,wFAAwFW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,8CAA8CW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,gFAAgFW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,2CAA2CW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,uEAAuEW,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,IAAI,KAAK,kCAAkCW,EAA2CZ,EAAEC,cAAc,KAAK,KAAKW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,6DAA6DW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,4GAA4GW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,8CAA8CW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,yGAAyGW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,4DAA4DW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,kGAAkGW,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,MAAM,CAACwC,MAAMpB,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAACsB,KAAKd,EAAYe,SAAS,KAAKC,QAAQ,CAAC,mBAAmBhC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,MAAM,CAACwC,MAAMpB,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAACsB,KAAKjB,EAAMkB,SAAS,KAAKC,QAAQ,CAAC,mBAAmBhC,EAA2CZ,EAAEC,cAAc,KAAK,MAAMW,EAA2CZ,EAAEC,cAAc,KAAK,KAAK,WAAWW,EAA2CZ,EAAEC,cAAc,MAAM,CAACwC,MAAMpB,GAAQT,EAA2CZ,EAAEC,cAAcmB,EAAkE,EAAE,CAACsB,KAAKf,EAASgB,SAAS,KAAKC,QAAQ,CAAC,2BAAmCf,EAAj3P,CAA43PlB,EAA8C,WAAgCjC,EAA6B,QAAKY,OAAO4B,EAAiE,EAAxE5B,EADt7P,SAAgBC,GAAO,MAAM,CAACG,MAAM,CAACmD,OAAOtD,EAAMK,QAAQ,GAAG2B,QAAQhC,EAAMK,QAAQ,IAAIkD,SAAS,CAACD,OAAOtD,EAAMK,QAAQ,IAAImD,UAAU,CAACC,UAAU,aACsyP,CAAoFnB"},"code":"(this[\"webpackJsonpmern-stack-client\"]=this[\"webpackJsonpmern-stack-client\"]||[]).push([[81],{342:function(e,a,n){\"use strict\";n.d(a,\"a\",(function(){return m}));var t=n(0),l=n.n(t),r=n(12),i=n(14),s=n(50),c=n(49),o=Object(c.a)((function(e){return{root:{display:\"flex\"},paper:{marginRight:e.spacing(2)},line:{textDecoration:\"none\"}}}));function m(){var e=o();return l.a.createElement(\"div\",{className:e.root},l.a.createElement(s.a,null,l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/infoMl\",className:e.line},\"InfoMl\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/gredient_decents\",className:e.line},\"Gredient Decents\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/training\",className:e.line},\"Traning\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/regularizations\",className:e.line},\"Regularizations\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/featuresEng\",className:e.line},\"FeaturesEng\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/adaboost\",className:e.line},\"Adaboots\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/greedSearch\",className:e.line},\"Greed Search\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/perceptron\",className:e.line},\"Perceptron\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/pcaPy\",className:e.line},\"PCA\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/leanearRegression\",className:e.line},\"Leanear Regression\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/logisticReg\",className:e.line},\"Logistic Regression\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/lda\",className:e.line},\"Lda\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/knn\",className:e.line},\"Knn\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/k_meanClustring\",className:e.line},\"K_Mean\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/naiveBar\",className:e.line},\"Naive Bayes\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/randomForest\",className:e.line},\"Random Forest\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/decisiontree\",className:e.line},\"Decision Tree\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/svmPy\",className:e.line},\"SVM\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/numpyPy\",className:e.line},\"Numpy\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/pandas\",className:e.line},\"Pandas\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/bagging\",className:e.line},\"Matplotlib\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/logisticRegrations\",className:e.line},\"Scikit Learn\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/regrations\",className:e.line},\"SciPy\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/libraries\",className:e.line},\"OpenCV\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/capture\",className:e.line},\"Capture\")),l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/joinImages\",className:e.line},\"JoinImages\")),l.a.createElement(\"br\",null),\"Deep Learning\",l.a.createElement(i.a,null,l.a.createElement(r.b,{to:\"/superwise\",className:e.line},\"Superwise\"))),l.a.createElement(\"div\",null))}},516:function(e,a,n){\"use strict\";n.r(a);var t=n(4),l=n(3),r=n(5),i=n(6),s=n(8),c=n(0),o=n.n(c),m=n(7),u=n.n(m),d=n(2),p=n(9),f=n(13),E=n(11),g=(n(16),n(342)),h=n(1),_={backgroundColor:\"#F0F8FF\",padding:\"1px\",fontSize:\"16px\"},b='\\nimport numpy as np\\n\\n# Decision stump used as weak classifier\\nclass DecisionStump:\\n    def __init__(self):\\n        self.polarity = 1\\n        self.feature_idx = None\\n        self.threshold = None\\n        self.alpha = None\\n\\n    def predict(self, X):\\n        n_samples = X.shape[0]\\n        X_column = X[:, self.feature_idx]\\n        predictions = np.ones(n_samples)\\n        if self.polarity == 1:\\n            predictions[X_column < self.threshold] = -1\\n        else:\\n            predictions[X_column > self.threshold] = -1\\n\\n        return predictions\\n\\n\\nclass Adaboost:\\n    def __init__(self, n_clf=5):\\n        self.n_clf = n_clf\\n        self.clfs = []\\n\\n    def fit(self, X, y):\\n        n_samples, n_features = X.shape\\n\\n        w = np.full(n_samples, (1 / n_samples))                          # Initialize weights to 1/N\\n\\n        self.clfs = []\\n        \\n        for _ in range(self.n_clf):                                      # Iterate through classifiers\\n            clf = DecisionStump()\\n            min_error = float(\"inf\")\\n\\n            for feature_i in range(n_features):                          # greedy search to find best threshold and feature\\n                X_column = X[:, feature_i]\\n                thresholds = np.unique(X_column)\\n\\n                for threshold in thresholds:\\n                    p = 1                                                # predict with polarity 1\\n                    predictions = np.ones(n_samples)\\n                    predictions[X_column < threshold] = -1\\n\\n                    misclassified = w[y != predictions]                  # Error = sum of weights of misclassified samples\\n                    error = sum(misclassified)\\n\\n                    if error > 0.5:\\n                        error = 1 - error\\n                        p = -1\\n\\n                    if error < min_error:                               # store the best configuration\\n                        clf.polarity = p\\n                        clf.threshold = threshold\\n                        clf.feature_idx = feature_i\\n                        min_error = error\\n\\n            # calculate alpha\\n            EPS = 1e-10\\n            clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS))\\n\\n            predictions = clf.predict(X)                                         # calculate predictions and update weights\\n\\n            w *= np.exp(-clf.alpha * y * predictions)\\n            # Normalize to one\\n            w /= np.sum(w)\\n\\n            self.clfs.append(clf)                                               # Save classifier\\n\\n    def predict(self, X):\\n        clf_preds = [clf.alpha * clf.predict(X) for clf in self.clfs]\\n        y_pred = np.sum(clf_preds, axis=0)\\n        y_pred = np.sign(y_pred)\\n\\n        return y_pred\\n'.trim(),y='\\nif __name__ == \"__main__\":\\n    from sklearn import datasets\\n    from sklearn.model_selection import train_test_split\\n\\n    def accuracy(y_true, y_pred):\\n        accuracy = np.sum(y_true == y_pred) / len(y_true)   \\n        return accuracy\\n\\n    data = datasets.load_breast_cancer()\\n    X, y = data.data, data.target\\n\\n    y[y == 0] = -1\\n\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\\n\\n    # Adaboost classification with 5 weak classifiers\\n    clf = Adaboost(n_clf=5)\\n    clf.fit(X_train, y_train)\\n    y_pred = clf.predict(X_test)\\n\\n    acc = accuracy(y_test, y_pred)\\n    print(\"Accuracy:\", acc)\\n    '.trim(),N=\"\\nPerformance of stump = 1/2 * log(1-Total Error) / Total Error\\n\\nNew weights = old weight * e(+-Performanse)\\n    where, + for Misclassification\\n           - for Right classification\\n\".trim(),w=function(e){function a(){return Object(t.a)(this,a),Object(r.a)(this,Object(i.a)(a).apply(this,arguments))}return Object(s.a)(a,e),Object(l.a)(a,[{key:\"componentDidMount\",value:function(){setTimeout((function(){return u.a.highlightAll()}),0)}},{key:\"render\",value:function(){var e=this.props.classes;return o.a.createElement(d.a,{container:!0},o.a.createElement(d.a,{item:!0,xs:2},o.a.createElement(p.a,{className:e.paper},o.a.createElement(\"h4\",null,o.a.createElement(g.a,null)))),o.a.createElement(d.a,{item:!0,xs:10},o.a.createElement(p.a,{className:e.paper},o.a.createElement(f.a,null,o.a.createElement(\"h3\",null,\"Boosting Types\"),o.a.createElement(\"ul\",null,o.a.createElement(\"li\",null,o.a.createElement(\"b\",null,\"1. Adaboost: \")),o.a.createElement(\"li\",null,o.a.createElement(\"b\",null,\"2. Gradient Boosting: \"),\"Instead of Weights updation, here gradient (residuals, loss) is passed in next model.\"),o.a.createElement(\"br\",null),o.a.createElement(\"li\",null,o.a.createElement(\"b\",null,\"3. Extream Gradient Boosting: \")),o.a.createElement(\"ul\",null,o.a.createElement(\"li\",null,\"Much similar to GB.\"),o.a.createElement(\"li\",null,\"2nd order Derivatives of Loss function.\"),o.a.createElement(\"li\",null,\"High Performance.\"),o.a.createElement(\"li\",null,\"Fast training.\"),o.a.createElement(\"li\",null,\"Advanced L1 and L2 Loass Regularization.\"),o.a.createElement(\"li\",null,\"Parallel and Distributed computing (DMLC).\"),o.a.createElement(\"li\",null,\"It handle missing values.\"),o.a.createElement(\"li\",null,\"Cache Optimisation\"),o.a.createElement(\"li\",null,\"It has many hyperparameters. reg_alpha, reg_lambda.\"))),o.a.createElement(\"br\",null),o.a.createElement(\"h3\",null,\"Adaboost (Adaptive boosting)\"),o.a.createElement(\"ul\",null,o.a.createElement(\"li\",null,\"Used for Classification and Regression.\"),o.a.createElement(\"li\",null,\"Sequencial boosting.\"),o.a.createElement(\"li\",null,\"AdaBoost is one of the first boosting algorithms to be adapted in solving practices. Adaboost helps you combine multiple \\u201cweak classifiers\\u201d into a single \\u201cstrong classifier\\u201d.\"),o.a.createElement(\"li\",null,\"The weak learners in AdaBoost are decision trees with a single split, called \",o.a.createElement(\"b\",null,\"decision stumps\"),\".\"),o.a.createElement(\"li\",null,\"AdaBoost works by putting more weight on difficult to classify instances and less on those already handled well.\"),o.a.createElement(\"li\",null,\"Weight increase for misclassification and weight decreses for right classifications.\"),o.a.createElement(\"li\",null,\"Used to exploit dependency between models.\"),o.a.createElement(\"li\",null,\"Stagewise additive MultiModeling using Multiclass Exponential Loss Function.\"),o.a.createElement(\"li\",null,\"Can handle missing values and outliner.\"),o.a.createElement(\"li\",null,\"Can handles mixed predictors as well (Quantitive and Qualitative).\")),o.a.createElement(\"br\",null),o.a.createElement(\"br\",null),o.a.createElement(\"b\",null,\"Steps for Adaboost Algoritham:\"),o.a.createElement(\"ul\",null,o.a.createElement(\"li\",null,\"1. Initialize the weights as 1/n to every n observations.\"),o.a.createElement(\"li\",null,\"2. Select the 1 Feature according to Lowest Gini/Highest information Gain and calculate the total error.\"),o.a.createElement(\"li\",null,\"3. Calculate the Performance of the stump.\"),o.a.createElement(\"li\",null,\"4. Calculate the new weights for each misclassification(increase) and right classification(decrease).\"),o.a.createElement(\"li\",null,\"5. Normalize the new weights so that sum of weight is 1.\"),o.a.createElement(\"li\",null,\"6. Repeat from step 2 to till configured number of estimators reacfied the accuracy achieved.\")),o.a.createElement(\"br\",null),o.a.createElement(\"div\",{style:_},o.a.createElement(h.a,{code:N,language:\"js\",plugins:[\"line-numbers\"]})),o.a.createElement(\"br\",null),o.a.createElement(\"div\",{style:_},o.a.createElement(h.a,{code:b,language:\"js\",plugins:[\"line-numbers\"]})),o.a.createElement(\"br\",null),o.a.createElement(\"h3\",null,\"Testing\"),o.a.createElement(\"div\",{style:_},o.a.createElement(h.a,{code:y,language:\"js\",plugins:[\"line-numbers\"]}))))))}}]),a}(c.Component);a.default=Object(E.a)((function(e){return{paper:{margin:e.spacing(1),padding:e.spacing(1)},smMargin:{margin:e.spacing(1)},actionDiv:{textAlign:\"center\"}}}))(w)}}]);","extractedComments":[]}